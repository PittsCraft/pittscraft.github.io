[{"categories":null,"content":"","description":"","tags":null,"title":"Android","uri":"/tags/android/"},{"categories":null,"content":"","description":"","tags":null,"title":"Application mobile","uri":"/categories/application-mobile/"},{"categories":null,"content":"","description":"","tags":null,"title":"Architecture","uri":"/tags/architecture/"},{"categories":null,"content":"","description":"","tags":null,"title":"Categories","uri":"/categories/"},{"categories":null,"content":"","description":"","tags":null,"title":"iOS","uri":"/tags/ios/"},{"categories":null,"content":"","description":"","tags":null,"title":"Kotlin","uri":"/tags/kotlin/"},{"categories":null,"content":"","description":"","tags":null,"title":"Pitt’s Craft","uri":"/"},{"categories":null,"content":"","description":"","tags":null,"title":"Posts","uri":"/posts/"},{"categories":["Application mobile"],"content":"Over the dozen mobile missions I worked on, the main caveats of codebases I faced were that the Model is unclear and disseminated, and data paths and behaviors are hardly readable.\nThis article digs into these problems and offers concrete directions on the architectural level, as well as some advices on the implementation level.\nIt’s not supposed to create a new shiny big-brained architecture abstraction, but it rather aims to explicit practical design advices that should bring clarity and reliability to your app’s business.\nThis article’s scope is wide but I tried to make it concise enough. It’s addressed to developers and architects of intermediary to expert level. It’s also deeply anchored in my own experience, including all the biases it can carry.\nTL;DR ⚠️ The diagram below can look like a new annoying architecture claiming to be the state of the art.\nWell it’s not.\nFurther you’ll see multiple mitigations, for example about the need of some Repositories. Also, I do not introduce new layers or too strict data paths (like VIPER does) that lock you in a specific paradigm.\nThis article is about practice and pragmatism, and the balance to avoid both spaghetti code and over-engineering.\nStill, this is a “TL;DR” so here you go!\nI. Model and Repositories concepts in architecture patterns Mobile devs often mistake Model for “data model”.\nHere is the Wikipedia’s schematic of MVVM:\nFrom https://en.wikipedia.org/wiki/Model–view–viewmodel\nWell, “Business Logic and Data” seems to be much more than “data model”.\nWhen you’re searching about mobiles architectures online, it’s in fact one of the most precise descriptions of the Model you can get.\nFrom https://www.techyourchance.com/mvc-android-1/\nSometimes, the Model is just assimilated to Repositories.\nFrom https://medium.com/swlh/mvi-architecture-with-android-fcde123e3c4a\nAnd sometimes there’s something between the ViewModel and the Repositories.\nNamely UseCases:\nFrom https://dev.to/kaleidot725/implementaing-jetpack-compose-orbit-mvi-3gea\nOr Interactors:\nFrom https://medium.com/@thereallukesimpson/clean-architecture-with-mvvmi-architecture-components-rxjava-8c5093337b43\nOf course you can find infinite minor variations of such schematics, with local models for example like above, or ViewModel’s model.\nBut in most cases the terminology is:\nModel: Business Logic and Data\nRepository: API with a backend, a local storage, a SDK…\nII. The Problem MVC, MVP, MVI, MVVM… There are many paradigms helping you bind your business logic to your actual UI implementation. But in the end, none of them is meant to help your with your actual business logic implementation. Well there’s VIPER and friends, but I’m trying to avoid over-engineering here.\nThe first step in dealing with this issue is usually to identify the model to the repositories. What you get when your apps starts growing, is often ViewModels reuse: ViewModels are not always tight to one specific View because you need some business logic that it implements in some other part of your app. And then you start carrying extra business logic to many Views because you needed a piece of it, and your architecture becomes fuzzy.\nThe second step is to look at clean architecture principles and its applications in the mobile context, and introduce UseCases or Interactors (couldn’t get the difference in implementations I actually saw). And in fact, that’s a nice step: now you’ve got identified entities that carry your business logic.\nThe third step is to get overwhelmed with instabilities or maintainability problems even though you were very thorough in your intermediary layer implementation.\nThe final step is to switch to a new project, hoping your problems were intrinsic to some other part of the app - typically the backend - and you may not find them in this whole new shiny project.\nIII. The solution: materialize the Model First things first: you need that extra layer between your UI (Views and ViewModels) and the Repositories. If I were to define terms again, I would call this the Model. And I do in the scope of this article.\nUI should be dumb as hell. It changes often, and you don’t want to embed any business logic in it.\nRepositories should be dumb as well. They are only interfaces to CRUD systems, SDKs or a backend, all the related complex work is done inside them.\nShift all complexity you can to this business layer. And organize it.\nIsn’t that what UseCases and Interactors are supposed to do? Well it really depends how you implement them. The usual caveat is that these terms imply unitary implementations: each one is focused on one specific task (getting some data or executing a command).\nYou just atomized your Model.\nReusing common code inside a feature brings more files and code navigation becomes harder and harder. Some build a graph of UseCases and in the end, the issue is that it’s just not readable. New needs will be implemented poorly if done by a dev that doesn’t know the graph on its fingertips.\nSo let’s call the entities of this business layer something else. Arbitrarily I’ll call them ✨Services✨, but feel free to choose your own terminology. And let’s make these Services more consistent.\nIV. Model’s theory From my experience, apps that have the least bugs have a Model that is:\ncompact thorough split in enough and not too many Services actually depicting the app’s domain And one of the best way to achieve that is to conceive it.\nTake your hands off the code and draw your Model.\nI must insist because too many devs are focusing on UI first, then try to bind it to the repositories while considering that 99% of the work already done, and don’t bring enough care to this step.\nIn fact, my favorite approach is to conceive and implement the Model first, before even writing the first line of UI code.\nA good model implements the app’s domain while accounting for practical constraints.\n1. App’s domain representation a. Your Model has Entities Not only backend’s one (and often not all of them): your mobile app is not just an externality, it has its own business to mind!\nb. Services contracts should be exposed The inputs (commands) and outputs (values, events) of each feature (the Service’s responsibility) should be gathered and have a place to stand.\nc. But what IS the app’s domain? It’s how you represent the world knowing:\nwhat interface you need to provide to the UI for it to perform its job how the Repositories behave and what actual work should be achieved in between. It’s not what the repositories do or what the UI does, but it’s the abstraction of what the “bindings” manipulate and do.\n2. Practical constraints Our domain describes the business that happens between the UI and the Repositories. As such, it must account for input and output abilities and needs on both sides.\nTo put it another way: as the app’s domain stands for the Model’s design, the constraints of the Model’s I/Os should be considered in the domain.\nConcretely, what can these constraints be then?\na. The UI navigation The Model should not take care of the navigation, but it should definitely drive most of it in the sense that UI components (like VMs, or Coordinators for UIKit veterans) should be able to perform very direct navigation flows while staying dumb enough.\nb. The UI SDK There aren’t many alternatives in the mobile world anyway, but mainly if your UI SDK is declarative or imperative (SwiftUI vs UIKit, Jetpack Compose vs legacy Jetpack) can make a great difference.\nc. The UI architecture Should you decide to use MVVM, MVI or TCA, all of them don’t define your model. But they might shape your model output: Do you better store a global reactive state or divide it by feature, by flow?\nd. The repositories natures A RESTFul API, a reactive NoSQL storage (like Firestore), a local relational DB with an ORM, an IoT SDK… Each kind of repository has specific constraints: it may be asynchronous or not, online or not, and expose specific paradigms that may impact greatly how the entire app should work.\nI’m not saying we shouldn’t abstract many specificities of the repositories, but that some of them sometimes shape at least a bit their abstraction anyway.\n3. What your Model feels like I think that there are three great criteria to judge if your Model is well written.\nIf you take a look at your Services interfaces / protocols and your entities, you should see a satisfying representation of your domain. Don’t think about the implementation, don’t think about UI details: do you see your domain while reading your Model? If you think about binding your Model to the UI you’re supposed to build, are the bindings obvious? If you think about using your Repositories to create these Services, does it make sense? V. Quick parenthesis: Clean Architecture In Android especially (I guess because it’s a child of Java culture), there is a great influence of Clean Architecture theory. Sometimes, layers separation concerns come at the point that you may have the same entity duplicated 3 times for theoretical reasons, but bringing literally nothing in practice - worse, sometimes introducing weaknesses. That’s just not pragmatic and I would advise you against these kinds of maniac satisfaction.\nThere can be good reasons to follow unproductive rules, and the limit is thin between good design principles and a blind worship.\nSo a couple of advices you can go with is to read a lot about clean architecture (it’s a very nice theoretical basis) and to adapt theory to what actually works, in practice and for your team.\nMy proposal should mostly fit in Clean Architecture paradigm, but I don’t consider it necessary.\nAbout that, let’s take a step backward.\nVI. Pragmatic Mobile Architecture I drawn a concise representation of the architecture I use in all my mobile jobs and missions. Don’t ignore the text in it, it’s not decorative but really part of the architecture. Else it’s just totally similar to UseCase/Interactor architectures (except for the naming).\nFirst, you will find that this architecture is compatible with MVVM, MVI, MVP… Of course, as I focus on the (green) Model part, you can tune the details of the UI layer as you wish.\nThen you can see that my graph is kinda oriented (well navigation is a strange beast), and that’s a quality that I kept from Clean Architecture. It’s really a key point to make things clean.\nAnother point hidden in the text, is that Services form an oriented graph. To explicit things a bit, it means that this Services graph:\nis totally valid. I know it can be tempting to have explicit Service layers and to apply isolation rules between them, but in practice I’m convinced it’s terribly counter-productive. I’d say we’re stepping in the overengineering area.\nNote that an obvious golden rule is to never-ever let UI use Repositories directly. If you do so, you’re missing modeling. Also, even if it can be a local reasonable shortcut, it will make precedence and you’ll soon be back in the spaghetti hell we’re trying to escape from.\nOn the opposite, sometimes it does not make sense to create some Repositories.\nI also just materialized what I wrote earlier about entities: I happily let them flow from Repositories to UI when it’s relevant.\nFinally, what’s not described in this diagram is how to design your Services.\nVII. Service design and beyond I gave you a few directions on what the app’s domain and its Model are. This should lead the theoretical conception of your Services. Then I briefly presented my favorite shape of Model architecture. Now I want to share how I actually implement all of this with a simple list of practices. It’ll be a lot less structured, more opinionated, but you can see that as pointillism. Crossing all of these should define a relevant frame to write a good Model with nice intrinsic qualities, and still with a good performance.\n1. CQRS everywhere CQRS stands for Command and Query Responsibility Segregation.\nIn our context, it translates to:\nA function can either query data or execute a command, but never both.\nIt can seem dumb and/or impractical, but just applying this rule will enhance your data flow and your commands flow readability more than you’d expect.\nI admit, there are high value exceptions sometimes, beginning with the result of a command (that is actually data). But in many cases, the data that a command would return is either:\na success / error flag that can be ignored by the caller and taken into account by the Service, making potentially this event flow in a query channel if needed updated data that is already bound via a query channel A specific mention here for reactive programming: it’s even more important in this paradigm to avoid side effects and not mix query streams and command streams (as it’s easier to confuse them).\n2. Reactive, async, imperative… My personal balancing lead me to use reactive programming in a very limited scope. The main reason for that (putting aside my personal taste) is that most devs are used to imperative programming, and reactive programming adds a big overhead to their project onboarding. Readability for junior devs and staffing ease are actual concerns. It also brings intrinsic qualities to your Model.\nThus I advise to use reactive programming:\nonly for queries relative to reactive data exposed by services. By reactive data, I’m speaking about values that can change over time. A counter-example is an HTTP request as it encapsulates an execution returning a single result: an asynchronous function will be way more explicit for this purpose. On the contrary, a service exposing data that may be fetched or not, or updated at any point should expose a reactive stream. by using streams that always provide a value as soon as you subscribe to them, except for events of course. Use nullables, enums with associated values (Swift) or sealed class (Kotlin) to represent initial values if needed. by publishing only values and make your streams error proof. Manage errors ASAP, and turn them to Model states or values (or ignore them if it’s relevant), before even emitting through reactive streams: it’s simpler for consumers, there’s only one linear stream to handle. Else many will just consider them as an unwanted consequence of Services business implementation and in many case wrongfully ignore them. it forces you to make errors management explicit and in the right place. One Service’s model can be designed to expose its errors explicitly, and another one’s consuming it can handle their side effects and expose an errorless Model to UI. by not exposing completing streams. Handling the end of a stream is another difficulty that should be handled ASAP, for the same reasons as errors. It makes a lot of sense if you use reactive streams only for reactive data queries (first point). So flatMap internally as much as needed, or use relays that won’t complete, and if you still want to let a stream complete (it can make sense), just don’t expect consumers to handle it. still allowing direct values exposure when it’s needed from consumers. A plain old var is straightforward and explicit, and sometimes a one time value is needed. Don’t make things complicated for consumers when they should be exposed simply. This way, most of the unknowns and difficulties of reactive paradigm go away.\nNote that we can do this because Swift Concurrency and Kotlin Coroutines have made their holes.\nThe reactive hell trying to fix the callback hell is no longer a thing: what is asynchronous should be asynchronous (using either async functions in Swift or suspend ones in Kotlin).\nStill, I suggest to make asynchronous functions private in most cases. If the result of an asynchronous command is not needed or can flow through a query channel without adding complexity, the consumers will bless you. Also, checking which function is called in an asynchronous context will be much easier.\nBut of course, if your ViewModel needs to perform a single remote command and it’s relevant that it’s it that locally manages the loading state of its View, then don’t overthink and make your asynchronous function public.\n3. Main Thread is the place to be In mobile apps, you know that when any event or data triggers the UI, it should happen on the main thread. So let’s try to do everything here!\nIf there’s a sensible performance issue, identify what should be done in the background and encapsulate with clear boundaries what code will run in the background. But don’t do it by default. If you’ve got 1000+ entities to process and map, don’t be frightened by big numbers and just check the execution time if you have any doubt.\nSometimes, your performance issue is caused only by bad code. Manually finding relationships between huge lists of entities with nested loops can be unnecessarily long to execute: optimize it and use caches, Sets or HashMaps (Dict for Swifters) instead of moving your process to the background in the first place.\nIf you still implement a background task and it should trigger anything else (publish on a reactive stream for example at any point of some heavy process), do it on the main thread.\nSome would rather try to always make ViewModels consume what Services provide on the main thread. But it’s not enough. Not knowing by default if any Service output will happen on the main or a background thread is too risky. It can also lead to concurrency issues and unexpected race conditions in the business code. Monothread paradigm is simple, comfortable and safe.\n4. Avoid inheritance OOP is no more the center of the world, and its nice principles are no more the state of art. The issue with inheritance is that it’s a bit hard to design properly, implement and read, especially for juniors. In simple case it’s not of course. But in general it can easily be split down to interfaces (protocols), composition, value types and concrete utilities. Your Model’s quality will increase while doing so.\nAs usual, stay pragmatic. If you see a real benefit to inheritance and the alternatives are overkill, then use inheritance.\n5. Do you really need this Repository? Don’t be systematic in your architectural approach on this point. A great example is user preferences (UserDefaults in iOS, SharedPreferences in Android). If you have a simple utility function that takes a key and allows to build a get / set / reactive-stream property from it, using it inside your Service directly is way simpler than grouping unrelated explicit properties in some store.\nIn this case, ideally, don’t write a store interface and implementation.\nSometimes the store is needed. Well in that case, make it expose generic accesses and declare your actual properties in your Service. After all, each preference property is part of your domain and the best place to expose it is inside the Service responsible for its feature.\nOpportunistic ad: for iOS I engage you to try my neat reactive PDefaults property wrapper 😁\n6. Split your Model You can read many advices about files and function lengths, and you should absolutely apply them to your Services. Your Model should evolve as the implementation clarifies the technical constraints. The business layer is the layer where you shouldn’t make compromises and let technical debt settle. As soon as a Service is too big or its responsibility seems a bit fuzzy, take a step back and draw a variation of your Model. It should often lead to splitting a Service, but sometimes you can also centralize in a new Service responsibility dispatched in multiple others.\nStill remember: don’t atomize your Model!\n7. Services naming Name interfaces, not implementations. Don’t implement a Service named MyService and name its interface MyServiceItf. Because the default representation of your Service across the app should be its interface (and you should try to write it first!). If you don’t have any clever name for your implementation, then just use a suffix: MyServiceImpl.\nThere are many advices around the importance of naming worth reading. A great advice is to avoid generic suffixes like Manager. Indeed it can lead to classes like BookManager whose responsibility is to manage everything about books, and that’s clearly a bad scope definition. So we should find the right words to describe this class’s responsibility. BookOrderValidator, BookLendingMonitor…\nBut thinking about newcomers, flagging your interfaces with their nature as a suffix has value as it increases architecture’s readability. So here’s my unpopular opinion: enforce your classes (or interfaces) nature readability at least by using Service suffixes. The layers of the architecture and its shape will be quicker to grasp.\nAlso, if your Model is not well defined at some time (because specs are fuzzy, as it happens like always), allow yourself to temporarily have vague responsibility services. BookService is ok as long as you take care of splitting it to properly scoped Services as it grows. And if it doesn’t grow or evolve enough to be worth splitting, then no big deal. It’s readable and takes care of everything related to books: that’s a good enough name and Model!\n8. Untested proposal: name Services that are exposed to UI differently I know I wrote the opposite earlier (don’t split the Model into multiple layers). But identifying by name Services that UI devs are supposed to use or not may prove itself useful. Indeed, even if they don’t bypass the golden rule and use repositories directly, I already saw confusion between well defined Services. This happens because developers that focus mainly on the UI just don’t know the Model on their fingertips, and we shouldn’t expect them to do so.\nI think this distinction could also bring some overall clarity. I would suggest to name “UX Services” using the UXServicesuffix, simply keeping Service suffix for “Business Only Services”.\nVIII. Conclusion As you saw, above are pretty general considerations and no sample code. I still have doubts about the very wide ambition of this article. But in the end, everything I wanted to write down is. And I skipped many crucial topics that are directly related: Dependencies Injection, Testing (UTs, UI Tests, previews), Declarative UI practices… This would have been too much for sure.\nI hope some of you will reach this conclusion and benefit from what I wrote.\nAnd as always, I’m eager for your comments and critics, being them mean or off the point.\nDo not hesitate!\n","description":"","tags":["iOS","Android","Architecture","Swift","Kotlin"],"title":"Pragmatic Mobile Architecture","uri":"/posts/pragmatic-mobile-architecture/"},{"categories":null,"content":"","description":"","tags":null,"title":"Swift","uri":"/tags/swift/"},{"categories":null,"content":"","description":"","tags":null,"title":"Tags","uri":"/tags/"},{"categories":null,"content":"","description":"","tags":null,"title":"AI","uri":"/tags/ai/"},{"categories":null,"content":"","description":"","tags":null,"title":"C++","uri":"/tags/c-/"},{"categories":null,"content":"","description":"","tags":null,"title":"Deep Learning","uri":"/tags/deep-learning/"},{"categories":null,"content":"","description":"","tags":null,"title":"Game Theory","uri":"/tags/game-theory/"},{"categories":null,"content":"","description":"","tags":null,"title":"Game Theory","uri":"/categories/game-theory/"},{"categories":null,"content":"","description":"","tags":null,"title":"ICM","uri":"/tags/icm/"},{"categories":null,"content":"","description":"","tags":null,"title":"ML","uri":"/tags/ml/"},{"categories":null,"content":"","description":"","tags":null,"title":"Monte Carlo","uri":"/tags/monte-carlo/"},{"categories":null,"content":"","description":"","tags":null,"title":"MTT","uri":"/tags/mtt/"},{"categories":null,"content":"","description":"","tags":null,"title":"Poker","uri":"/tags/poker/"},{"categories":["Game Theory"],"content":"Un micro-post pour vous indiquer que le code C++ de calcul d’ICM est disponible sur mon Github sous licence CC NC SA (pas d’utilisation commerciale et propagation de la license obligatoire).\n","description":"Nouvelles cassantes","tags":["Poker","AI","ICM","MTT","Game Theory","ML","Deep Learning","Monte Carlo","C++"],"title":"Poker : MTT et ICM #4.1 - Publication du code C++","uri":"/posts/poker_mtt_icm_cpp_code/"},{"categories":["Game Theory"],"content":"Rappelons-nous une des conclusion du dernier épisode :\n(…) le calcul prend 27ms pour une moyenne sur 15500 échantillons. C’est très raisonnable en soi, mais si j’envisage de simuler quelques milliers de tournois comportant des milliers de mains elles-mêmes incluant plusieurs calculs d’ICM, ce ne sera pas suffisant. Damned.\nDu coup©™ peut-on obtenir des valeurs tout aussi satisfaisantes mais beaucoup plus rapidement ?\nPour ceux qui nous rejoignent seulement, je vous conseille de parcourir les articles précédents :\n#1 : La problématique exposée sur les fonctions d’évaluation en tournoi de poker #2 : L’implémentation d’un calcul exact de l’ICM #3 : Un calcul pour un plus grand nombre de joeurs par la méthode de Monte-Carlo Neural-Networks—Deep—Machine-Learning-Artificial-Intelligence-MotherF****r Quelques définitions au doigt mouillé :\nle machine learning c’est l’approche pour laquelle la machine n’a pas été programmée pour résoudre un problème explicitement (ce n’est donc pas une heuristique). Elle apprend à le résoudre. les réseaux de neurones sont une technique antique (ils datent de 1943) qui convient particulièrement bien au machine learning. On n’a juste pas pu les exploiter pleinement jusqu’à récemment, lorsque les machines ont commencer à envoyer suffisamment de pâté (le fameux point Pâté Hénaff pour nos amis franglophones). Une minute de silence pour cette vanne, merci.\nles réseaux de neurones ont une couche de neurones d’entrée qui acceptent un signal (des données) et une couche de neurones de sortie qui donne un résultat associé à ce signal. Entre les deux, on peut avoir plusieurs autres couches de neurones, auquel cas le réseau devient profond. Et on commence à parler de deep learning. Ce que permet le deep learning c’est surtout d’extraire des caractéristiques des données d’entrée brutes grâce au seul bourrinage d’un nombre gigantesque de données, au lieu d’essayer de traiter les données en amont pour les rendres assimilables par un réseau de neurones plus modeste, et ce n’est pas rien. Tout ceci est une sous-partie du domaine de l’intelligence artificielle qui consiste à coder disons… des trucs un peu compliqués. Ici on se fiche un peu de ces distinctions, on va utiliser un réseau de neurones pour faire un calcul qui comprend des additions et des multiplications, et non pas des trucs révolutionnaires qui changent la société comme faire chanter nos dictateurs favoris.\nObjectif et paramètres Depuis la dernière fois, on sait générer des valeurs d’ICM pour une cinquantaine de joueurs avec une précision et une probabilité abitraires. Cependant s’assurer de cette précision probable a un coût. Comme je le proposais précédemment, on peut simplement observer le nombre de tirages nécessaires pour l’atteindre sur pas mal de cas, prendre le maximum, et on ne sera pas bien loin de la garantie initiale pour des valeurs similaires.\nOn peut donc se dédouaner des checks coûteux de convergence, mais ce qu’on voudrait vraiment pour le solstice c’est un temps de calcul bien plus faible. Genre maximum une milliseconde.\nAlors pour ça on va fixer quelques paramètres, parce que si je m’intéresse à 10, 50 ou 1000 joueurs c’est pas le même topo. De même, si seul le premier du classement est payé ou si la distribution des prix est exponentielle, c’est pas bien pareil. Et enfin si tous les joueurs ont le même stack ça diffère franchement de la situation où on a quelques Bezos et des dizaines d’ultra-pauvres.\nMe, showing off with my monster stack on the final table.\nJe vais rester sur 50 joueurs maximum parce que ça représente quelque chose pour lequel le calcul ICM classique est incapable de finir dans un temps raisonnable, et Monte-Carlo a du mal à être super rapide mais peut quand même me fournir des valeurs. Pour les prix (le prizepool, les payouts), on va copier sur un tournoi d’une cinquantaine de joueurs que j’ai trouvé sur Winamax au pif. Car oui, on va fixer le prizepool, je ne vois pas pourquoi on se mettrait des bâtons dans les roues, puisqu’on va par contre faire varier à fond la distribution des stacks. L’idée est de correspondre au cas d’usage pour lequel on fait tourner plein de simulations de tournoi sur une configuration donnée : 50 joueurs et prizepool déterminé.\nÉtape #1 : Générer les données Pour entraîner mon réseau je vais avoir besoin de couples (input, output) = (distribution de stacks, icm). Je sais calculer l’ICM, j’ai donc juste besoin de listes de stacks variées. Comme je vais avoir du mal à extraire ces données de leurs milieux naturels (les plateformes de poker en ligne), je vais les générer en mimant les processus de mère Nature, c’est à dire en organisant des petits simili-tournois. Ca tombe bien, j’en aurai besoin plus tard pour évaluer des concurrents à l’ICM !\nLa conception de ces tournois est un large sujet, mais ce qui va compter ici c’est surtout de générer une variété de situations assez grande. J’ai donc pris un petit test avec des joueurs omniscients que j’ai codé et dont on va ignorer les défauts pour le moment :\npour chaque main on va tirer un certain nombre de couples de joueurs qui vont s’affronter à chaque affrontement, une équité va être tirée qui va donner la probabilité que le premier joueur gagne au showdown (si les joueurs payent les relances des adversaires) les jeu est un simple push/call/fold : le premier joueur peut se coucher et perd sa blinde, ou relancer à tapis. S’il relance, le second joueur peut suivre et aller au showdown ou se coucher et perdre sa blinde. les joueurs vont jouer en connaissance de leur équité. Le second joueur va d’abord décider s’il suivra au cas où le premier joueur relance, et le premier joueur sachant tout ça (son équité et la future décision du second joueur car il est omniscient), va décider de relancer ou pas. pour estimer les situations futures les joueurs se servent de fonctions d’EV qui pourraient être l’ICM mais seront en l’occurence une estimation proportionnelle aux jetons (Chips EV) On fait donc prendre leurs décisions à tous les couples de joueurs en même temps, puis on résoud en faisant les tirages aléatoires nécessaires pour les affrontements et redistribuant les jetons selon les issues de toutes les mains.\nOn va insérer une sonde au niveau de l’évaluation d’EV pour répertorier toutes les situations qui sont évaluées dans un bon vieux Set[Tuple] histoire de ne pas avoir de doublons, et hop on peut jouer des tournois pour générer des distributions de stacks crédibles.\nAujourd’hui je ne vous colle pas le code : on est prooches de la fin de cette petite épopée, et je mettrai simplement mon code à disposition sur Github une fois que tout sera fini.\nÉtape #2 : Calculer l’ICM On a joué autant de simili-tournois que nécessaire pour avoir assez (N) de situations différentes, et nous allons maintenant calculer l’ICM de chaque :\nprenons en échantillon toutes les situations générées par un tournoi supplémentaire observons la convergence des caculs d’ICM méthode Monte-Carlo pour récupérer le nombre de tirages nécessaires à une bonne précision probable pour chaque situation prenons le maximum de ces nombres, ce qui est bien pessimiste pour toutes les N situations générées précédemment, calculons l’ICM avec ce nombre de tirages Grâce à notre pessimisme, on ne doit pas s’éloigner beaucoup (en fréquence et en distance) des garanties statistiques de notre échantillon et on va prendre le raccourci de considérer qu’on a les mêmes garanties.\nÉtape #3 : Définition du NN (Neural Network) Comment construit-on un NN ? À tâtons. Sisi. Enfin on peut quand même trouver de bons conseils pour orienter ses tâtonnements de manière pertinente. À ce sujet et après avoir bien compris de quoi il retourne, je ne peux que vous conseiller le blog de Jason Brownlee qui couvre énormément de cas et de questions que les data scientists se posent en pratique.\nPour le détail, on va normaliser en peu nos données :\nen input on va considérer uniquement des stacks triés par ordre décroissants (on a fait ça au moment même de la génération des stacks et avant de calculer l’ICM) et divisés par la somme des stacks en output on va diviser l’ICM par la somme des payouts (qui est la somme des valeurs d’ICM) Si vous vous rappelez du calcul de l’ICM, on est dans des combinaisons de multiplications et de sommes et les couches de neurones denses - chaque neurone est connecté à chaque neurone de la couche suivante - se prêtent particulièrement bien à ce ce genre de calculs. Après quelques essais, j’ai trouvé que cette forme de réseau marchait pas mal :\n[Input layer] : nb_players neurons (stacks) | | | | | | | | | | | | | | | | | | | | | | [Hidden layer 1] : 3 * nb_players neurons | | | | | | | | | | | | | | | | | | | | | | [Hidden layer 2] : 3 * nb_players neurons | | | | | | | | | | | | | | | | | | | | | | [Output layer] : nb_players neurons (ICM) On utilise de traditionnelles fonctions d’activation relu, une fonction de perte mean_squared_error et un optimizer RMS ce qui correspond bien à un problème de régression.\nÇa nous donne pour du Keras :\nnn = Sequential() nn.add(Dense(nb_players, activation='relu')) nn.add(Dense(nb_players * 3, activation='relu')) nn.add(Dense(nb_players * 3, activation='relu')) nn.add(Dense(nb_players, activation='relu')) nn.compile( loss='mean_squared_error', optimizer=keras.optimizers.RMSprop(), metrics=[keras.metrics.RootMeanSquaredError()] ) Entrainement et résultats 9k situations d’entraînement 1k situations de validation 1k situations de test une configuration de tournoi avec 50 joueurs 100 blindes de stack initial les blindes qui sont multipliées toutes les 10 mains par 1,3 30% des joueurs qui participent à chaque main (comme sur une table de 6 joueurs en gros) le prizepool : 4650. 3450. 2325. 1650. 1200. 825. 600 0 0 0 ... donc un buy-in de 294 milliards de dollars (pourquoi pas) une précision pour les évaluation ICM en Monte-Carlo de un demi buy-in avec 90% de confiance J’obtiens un nombre de tirages nécessaires pour chaque évaluation ICM de 3100.\nJe fais tourner mes calculs en multithread pendant une minute environ pour une moyenne de 6ms par évaluation ICM (mais le multithread n’est pas facilement réalisable au sein d’un tournoi, on est plutôt autour de 15ms en monothread).\nMaintenant que j’ai toutes mes situations et les estimations ICM associées, j’entraîne mon NN pour 10 epochs avec un batch-size de 30 - pour ceux à qui ça parle - ce qui me prend environ 5 secondes.\nUn petit plot pour la convergence du NN :\net sur les tests finaux une RMSE (root means squared error) moyenne de 100.62 (milliards de dollars).\nCe que ça veut dire, c’est qu’en une minute j’ai entraîné un réseau de neurones dont les erreurs par rapport aux évaluations de Monte-Carlo sont de l’ordre de la précision de ces évaluations. Et ça, c’est déjà pas mal !\nMais l’objectif était d’aller plus vite que les quelques millisecondes de calculs de Monte-Carlo, et ça se confirme en effet.\nTemps de calcul d’une évaluation ICM en utilisant le modèle Keras : 19 microsecondes ! Objectif atteint : on a divisé par 316 le temps de calcul par rapport à l’évaluation de Monte-Carlo.\nAllez, une dernière optimisation pour la route : Keras étant utilisé tant pour l’entraînement tant que l’évaluation, il est possible de dégraisser un peu tout ça en utilisant TensorFlow lite (un bon guide ici). Et dans ce cas, on obtient moins de 10 microsecondes par évaluation.\nConcluons Je vous ai caché quelques technicités, notamment l’exposition des fonctions de calcul d’ICM codées en C++ à du code Python grâce à Boost qui fut une aventure déplaisante mais relativement efficace. Ceci-dit, voilà, on peut calculer l’ICM avec une bonne précision en quelques micro-secondes moyennant une étape préliminaire d’environ une minute. On peut augmenter cette précision ce qui gonflera le temps de préparation, mais si on travaille à configuration de tournoi fixe et pour un nombre important de tournois, on passera très certainement énormément moins de temps au total.\nLa suite ? On va enfin faire des simulations marrantes avec de l’ICM et tenter de comprendre quels sont son domaine d’application, ses limites, et si on a le temps on cherchera à créer de meilleures évaluations.\nMalgré les milliards de mails par secondes que je reçois concernant ces expériences, n’hésitez pas à m’écrire pour me dire ce que vous en pensez ou me poser toute question - ou me proposer une mission autour de l’IA ;)\n","description":"Jusqu’au-boutisme de l’extrême qui envoie du pâté.","tags":["Poker","AI","ICM","MTT","Game Theory","ML","Deep Learning","Monte Carlo"],"title":"Poker : MTT et ICM #4 - Perf Tuning avec du Deep Learning","uri":"/posts/poker_mtt_icm_deep_learning/"},{"categories":["Game Theory"],"content":"Résumé des épisodes précédents:\nEn théorie des jeux, les fonctions d’évaluation permettent d’évaluer des situations, de les comparer, et donc de faire des choix renseignés l’Independent Chip Model (ICM) est la fonction d’évaluation de référence pour les tournois de poker, et on cherche à trouver mieux, notamment pour un grand nombre de joueurs l’ICM est long à calculer pour un grand nombre de joueurs. Après pas mal d’optimisations, on a des temps humainement raisonnables pour une vingtaine de joueurs payés maximum. Si on veut utiliser l’ICM de manière intensive comme dans une simulation de tournoi, il faudra viser plutôt autour de dix joueurs payés. Du coup©™ peut-on obtenir des valeurs correctes pour un plus grand nombre de joueurs ?\nMonte-Carlo : le tâtonnement convergent Une méthode commune d’approximation de valeur est la méthode de Monte-Carlo (MC). On va évaluer différents points d’une fonction complexe choisis aléatoirement pour déduire une approximation probabiliste de sa moyenne. En l’occurence pour l’ICM on peut typiquement essayer de tirer aléatoirement le classement des joueurs selon les hypothèses de l’ICM ce qui n’est somme-toute pas évident.\nNaïvement on devrait tirer le premier joueur classé selon une probabilité proportionnelle à son stack, puis le second parmi les joueurs restants et les stacks restants et ainsi de suite. Autant vous dire qu’on ne va pas bien loin avec ça car la complexité est alors assez violente : pour chaque tirage on doit calculer la distribution de probabilité et effectuer un tirage, ce qui au minimum va nous mener sur du O(n2) pour un tirage, et il en faut pas mal.\nHeureusement des gens ont réfléchi, et notamment le développeur d’IA Tysen Streib qui a beaucoup contribué à l’analyse stratégique au poker (il a co-écrit Kill everyone notamment). Il a donc très justement analysé en 2011 qu’il était possible d’effectuer un tirage de la sorte en tirant aléatoirement la durée de vie de chaque joueur selon uniform_random[O:1]1/stack, puis en ordonnant les durées de vie pour obtenir l’ordre de classement des joueurs.\nJe vous recommande fortement la lecture de son post original ici et du thread qui suit, où l’algorithme tant que les raisons de la convergence sont bien expliqués, à un niveau intuitif, avec une interprétation théorique et même des optimisations.\nImplémentation Les gros points de consommation de CPU sont :\nle tirage aléatoire le calcul de puissance le tri Comme suggéré dans le fil du post, on obtient de meilleures performance en utilisant le logarithme de la formule de tirage, log est strictement croissant donc l’ordre reste le même.\nPour le tirage aléatoire, on a besoin d’un aléatoire statistique correct mais sans qualité cryptographique particulière. On gagne pas mal en utilisant SFMT, une variante de l’algorithme de Mersenne-Twister plus rapide sur les microprocesseurs modernes.\nEnfin pour le tri il faut noter que selon la distribution des prix, on peut éventuellement chercher à classer les premiers joueurs pour les places ayant un prix non-nul. Ce n’est pas une optimisation systématique mais lorsqu’elle est pertinente il serait dommage de l’ignorer.\nVoici une version directe, sans autre optimisation.\n#include \"monte-carlo-icm.hpp\" #include \u003crandom\u003e #include \u003cunordered_map\u003e #include \u003csfmt.hpp\u003e /** * Compute a permutation according to the sorting of random values put to the power of given weights. * In fact, logarithm is used for performance, and logarithm tables could certainly be used to fasten the * computation. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param dist random distribution * @param mt SFMT (fast Mersenne-Twister algorithm) */ void monteCarloPermutation(const double *weights, int *destination, const int size, uniform_real_distribution\u003cdouble\u003e \u0026dist, wtl::sfmt19937 \u0026mt) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(dist(mt)) * weights[i]; destination[i] = i; } sort(destination, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); } ); } /** * Same as `monteCarloPermutation` except the sorting process stops for performance * after the first values are sorted. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param nbRelevant number of top values that should be strictly sorted. The other ones may not be sorted * according to the random draw. * @param dist random distribution * @param mt SFMT (fast Mersenne-Twister algorithm) */ void monteCarloPermutationPartial(const double *weights, int *destination, const int size, const int nbRelevant, uniform_real_distribution\u003cdouble\u003e \u0026dist, wtl::sfmt19937 \u0026mt) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(dist(mt)) * weights[i]; destination[i] = i; } partial_sort(destination, destination + nbRelevant, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); } ); } int firstZeroPayout(vector\u003cdouble\u003e payouts) { const int size = payouts.size(); int firstZeroPayout = -1; for (int i = 0; i \u003c size; ++i) { if (firstZeroPayout \u003c 0) { if (payouts[i] == 0) { firstZeroPayout = i; } } else if (payouts[i] != 0) { firstZeroPayout = -1; } } return firstZeroPayout; } /** * Monte-Carlo ICM Ranking algorithm. * * @param stacks * @param payouts * @param trials * @param relevantRanksCount * @param results array of ICM EV */ void monteCarloIcm(const double *stacks, const double *payouts, const int nbPlayers, const long trials, const int relevantRanksCount, double *results) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/ // Initialize random distribution // https://stackoverflow.com/questions/19665818/generate-random-numbers-using-c11-random-library // SFMT variant random_device rd; wtl::sfmt19937 mt(rd()); uniform_real_distribution\u003cdouble\u003e dist(0, 1); int permutation[nbPlayers]; const double stacksAvg = accumulate(stacks, stacks + nbPlayers, 0.) / (double) nbPlayers; double weights[nbPlayers]; double contrib[nbPlayers]; // - Normalize stacks (not really necessary but cheap) and invert to weights // - Prepare each trial ranking contribution to the total for (int i = 0; i \u003c nbPlayers; i++) { weights[i] = stacksAvg / stacks[i]; contrib[i] = payouts[i] / trials; } // Partial sort vs sort : interesting only if we have many zero payouts at the end const float partialSortThreshold = 0.2; // Magic number \u003c3 const bool partialSort = relevantRanksCount \u003e= 1 \u0026\u0026 ((float) relevantRanksCount / (float) nbPlayers \u003c= partialSortThreshold); for (long i = 0; i \u003c trials; i++) { // Draw a permutation if (partialSort) { monteCarloPermutationPartial(weights, permutation, nbPlayers, relevantRanksCount, dist, mt); } else { monteCarloPermutation(weights, permutation, nbPlayers, dist, mt); } // Cumulate payouts according to the random permutation for (int j = 0; j \u003c nbPlayers; j++) { results[permutation[j]] += contrib[j]; } } } /** * Vector wrapper of MC ICM * @param stacks * @param payouts * @param trials * @return ICM EV */ vector\u003cdouble\u003e monteCarloIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts, const long trials) { const int nbPlayers = stacks.size(); const int relevantRanksCount = firstZeroPayout(payouts); vector\u003cdouble\u003e results(nbPlayers); double stacksArray[nbPlayers]; double payoutsArray[nbPlayers]; double resultsArray[nbPlayers]; for (int i = 0; i \u003c nbPlayers; ++i) { stacksArray[i] = stacks[i]; payoutsArray[i] = payouts[i]; resultsArray[i] = 0; } monteCarloIcm(stacksArray, payoutsArray, nbPlayers, trials, relevantRanksCount, resultsArray); for (int i = 0; i \u003c nbPlayers; i++) { results[i] = resultsArray[i]; } return results; } Autres pistes d’optimisation Voici quelques optimisations que j’imagine pertinentes :\nl’échantillonnage préférentiel : plus d’échantillons pour les cas les plus probables. On pourrait par exemple fixer successivement chaque joueur premier du classement, et estimer ce cas avec plus ou moins de précision par exemple avec un nombre d’échantillon proportionnel à sa probabilité au carré (la contribution de chaque cas restant proportionnelle au stack du joueur bien sûr). Pourquoi pas aller un ou plusieurs crans plus loin en envisageant toutes les combinaisons des k premiers joueurs. le quasi-Monte-Carlo, une répartition plus homogène peut apporter une convergence plus rapide pour le tri et pour les très grands nombre de joueurs, comme les payouts sont souvent par palliers, utiliser quand c’est pertinent une succession de tris partiels par palier (plus précisément des algorithmes de sélection). Si vous explorez ces optimisations (ou d’autres), faites-m’en part, je suis curieux !\nConvergence On sait qu’on a une convergence en O(1/sqrt(n)) (note : ajouter une extension LateX à mon site builder). Mais ça ne nous dit pas quand il faut arrêter l’échantillonnage ! Par le passé j’utilisais de petits algos observant la variation sur des lots de puissances de deux d’échantillons, ce qui n’est pas fiable : on peut avoir une convergence très lente, et un fort ralentissement ne permet pas de conclure en une précision donnée. “En pratique, ça marche” oui, enfin peut-être, mais ce n’est pas forcément beaucoup plus dur d’implémenter des garanties statistiques sûres.\nAprès quelques recherches j’ai trouvé une méthode assez générique dans ce (vieux) papier1. Le calcul se base sur un plafond en dessous duquel la variance d’un échantillon satisfait une garantie statistique : avec une probabilité α, la moyenne de l’échantillon est dans l’intervalle de confiance de taille d autour de la moyenne à la limite.\nJ’ai donc réorganisé un peu mon code pour l’implémenter. Le coût du calcul étant assez élevé, il convient de ne pas l’appliquer à chaque étape de l’échantillonage, mais plutôt régulièrement, tous les 100 échantillons par exemple. De plus, j’ai extrait les définitions du RNG (pour un futur quasi-Monte-Carlo) et du tri (pour un futur tri partiel par palliers) histoire de pouvoir plus facilement implémenter d’autres versions de l’algorithme - voir le code en fin d’article.\nUn point important à considérer est que la variance d’un calcul d’ICM par la méthode de Monte-Carlo dépend fortement de la distribution des stacks des joueurs et de celle des prix. En effet, pour prendre un extrême, si tous les prix sont égaux la variance est simplement nulle. On va évidemment souhaiter éviter le coût de calcul de cette stopping rule si on en opère en nombre, mais il faudra être prudent pour garder des garanties correctes. De plus, la taille d de l’intervalle de confiance est liée linéairement aux prix. Si on distribue deux fois plus de prix aux joueurs, pour une même précision relative on devra multiplier d par deux. L’idéal est alors d’exprimer d en fonction d’une grandeur pertinente comme la somme des prix distribués et d’en tenir compte lors du traitement d’échantillons variés pour au moins connaître la précision des résultats calculés.\nSi les échantillons sont assez homogènes, on pourra par exemple faire une petite tambouille comme calculer le nombre d’itérations nécessaires sur un petit ensemble de situations extraites du paquet à traiter, prendre le maximum et le multiplier par deux pour traiter tout le paquet (à vue de nez, “en pratique, ça marche”).\nPerformance Je me suis intéressé au cas de 50 joueurs, les 40 premiers étant payés. Pour construire la structure de prix, j’ai notamment lu cette présentation qui m’a encouragé à utiliser une power law fall-off (une chute de loi de puissance..?) telle que le joueur au rang i obtienne un prix proportionnel à 1 / pow(i, a). J’ai négligé les étapes d’humanisation car je suspecte qu’au mieux elles font baisser la variance en créant des plateaux. Soyons-donc joyeusement pessimistes !\nJ’ai ensuite pris une distribution de stacks aléatoires selon une loi normale tronquée. Je ne pense pas que c’est vraiment représentatif d’une situation particulière, les distributions de stack sont assez difficiles à modéliser. Enfin pour le moment ça suffira, on cherche juste à connaître la performance de notre algorithme.\nDans ces circonstances, l’évaluation de la stopping rule pour une probabilité de 0.9 avec un intervalle de confiance de taille 1 (sachant que la somme des prix vaut 1000) me donne de manière assez stable une taille d’échantillon de 15500.\nEt une fois débarrassés de cette évaluation, le calcul prend 27ms pour une moyenne sur 15500 échantillons. C’est très raisonnable en soi, mais si j’envisage de simuler quelques milliers de tournois comportant des milliers de mains elles-mêmes incluant plusieurs calculs d’ICM, ce ne sera pas suffisant. Damned.\nMais j’ai une idée un peu taquine pour résoudre ça…\nNext step Tout ça pour… pour quoi déjà ? Pour défier l’ICM, parce qu’on se demande s’il n’y a pas mieux, et sinon pour se convaincre que c’est une bonne approximation.\nJe pense qu’on pourrait déjà aller vers des simulations intéressantes avec un nombre réduit de joueurs pour mettre en évidence certains comportements. Mais je suis sur une bonne lancée, on va pas s’arrêter en si bon chemin !\nCe sera donc pour mon prochain article, en attendant n’hésitez pas à me contacter pour toute critique ou discussion via mon email en pied de page !\nBonus : le code Tout d’abord on a besoin d’une fonction qui n’existe pas dans les bibliothèques standard : norminv qui permet de déterminer pour quelle abscisse on obtient à gauche une certaine fraction de la population d’une distribution normale unitaire centrée en 0.\nUn certain John D. Cook l’a fait pour nous, on va donc utiliser son code.\nutil/math.cpp\nCollez le code de cette page https://www.johndcook.com/blog/cpp_phi_inverse/\nutil/math.hpp\n#ifndef MTT_EXPERIMENTS_C_MATH_HPP #define MTT_EXPERIMENTS_C_MATH_HPP double NormalCDFInverse(double p); #endif //MTT_EXPERIMENTS_C_MATH_HPP monte-carlo-icm.cpp\n#include \"monte-carlo-icm.hpp\" #include \u003crandom\u003e #include \u003csfmt.hpp\u003e #include \u003cutil/math.hpp\u003e using namespace std; namespace icm { /** * The Random Number Generator type : functions denoted by this alias are expected to draw doubles between 0 and 1. * Abstracted in order to plug a proper RNG for quasi-Monte-Carlo in the future. */ using RNG = std::function\u003cdouble()\u003e; /** * The sorter functions are expected to sort the indexes of the draw array in reverse order according to the values * of the array. */ using Sorter = std::function\u003cvoid(double *draw, int *destination, int size)\u003e; /** * Private section */ namespace { /** * Compute a permutation according to the sorting of random values put to the power of given weights. * In fact, logarithm is used for performance, and logarithm tables could certainly be used to fasten the * computation. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param rng random number generator * @param sorter function to sort the permutation */ void monteCarloPermutation(const double *weights, int *destination, const int size, const RNG \u0026rng, const Sorter \u0026sorter) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(rng()) * weights[i]; destination[i] = i; } sorter(draw, destination, size); } /** * Get the index of the first zero payout after which all payouts are zero as well * @param payouts the payouts array * @param size the size of the array * @return the index of the first zero payout */ int firstZeroPayout(const double *payouts, int size) { int firstZeroPayout = -1; for (int i = 0; i \u003c size; ++i) { if (firstZeroPayout \u003c 0) { if (payouts[i] == 0) { firstZeroPayout = i; } } else if (payouts[i] != 0) { firstZeroPayout = -1; } } return firstZeroPayout; } /** * Compute the mean of a batch of samples * @param samples the samples * @param nbPlayers the size of each sample aka the number of players * @return a vector containing the mean of the samples */ vector\u003cdouble\u003e mean(vector\u003cdouble *\u003e samples, const int nbPlayers) { const long long nbSamples = samples.size(); vector\u003cdouble\u003e result(nbPlayers, 0); for (int i = 0; i \u003c nbSamples; i++) { double *sample = samples[i]; for (int j = 0; j \u003c nbPlayers; ++j) { result[j] += sample[j]; } } for (int i = 0; i \u003c nbPlayers; ++i) { result[i] /= (double) nbSamples; } return result; } /** * Compute the variance of samples * @param samples the samples * @param nbPlayers the size of each sample aka the number of players * @return the variance */ double variance(vector\u003cdouble *\u003e samples, const int nbPlayers) { const long long nbSamples = samples.size(); vector\u003cdouble\u003e meanSample = mean(samples, nbPlayers); double result = 0; for (int i = 0; i \u003c nbSamples; i++) { double *sample = samples[i]; for (int j = 0; j \u003c nbPlayers; ++j) { double diff = sample[j] - meanSample[j]; result += diff * diff; } } // Not sure about nbSamples - 1, should be nbSamples but the paper about the stopping rule states n-1... return result / (double) (nbSamples - 1); } /** * Compute the threshold for the variance under which the stopping limit is considered reached * @param alphaProbability confidence probability * @param confidenceIntervalLength confidence interval length (root mean square) * @param nbSamples number of samples * @return the variance threshold */ double stoppingRuleLimit(double alphaProbability, double confidenceIntervalLength, long long nbSamples) { double zAlpha = NormalCDFInverse(alphaProbability + (1 - alphaProbability) / 2); // Symmetrical distribution return (double)nbSamples * confidenceIntervalLength * confidenceIntervalLength / zAlpha; } /** * Pick the appropriate sorter depending on payouts. We can use a partial sort if most of the payouts are zero * @param payouts the payouts * @param nbPlayers the size of the payouts array aka the number of players * @return a sorter */ Sorter chooseSorter(const double *payouts, int nbPlayers) { // Partial sort vs sort : interesting only if we have many zero payouts at the end const int relevantRanksCount = firstZeroPayout(payouts, nbPlayers); const float partialSortThreshold = 0.2; // Magic number \u003c3 const bool partialSort = (float) relevantRanksCount / (float) nbPlayers \u003c= partialSortThreshold; if (partialSort) { return [=](const double *draw, int *destination, int size) { partial_sort(destination, destination + relevantRanksCount, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); } ); }; } return [](const double *draw, int *destination, int size) { sort(destination, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); }); }; } /** * Create a RNG instance (using SFMT) * @return a RNG instance */ RNG defaultRng() { // Initialize random distribution // https://stackoverflow.com/questions/19665818/generate-random-numbers-using-c11-random-library // SFMT variant random_device rd; wtl::sfmt19937 mt(rd()); shared_ptr\u003cwtl::sfmt19937\u003e mtPtr = std::make_shared\u003cwtl::sfmt19937\u003e(mt); uniform_real_distribution\u003cdouble\u003e dist(0, 1); return [mtPtr = make_shared\u003cwtl::sfmt19937\u003e(mt), distPtr = make_shared\u003cuniform_real_distribution\u003cdouble\u003e\u003e(dist)]() -\u003e double { return (*distPtr)((*mtPtr)); }; } /** * Check if we can stop the trials according to the confidence probability and interval * @param alphaProbability the confidence probability * @param confidenceIntervalLength confidence interval length (root mean square) * @param samples the samples * @param nbPlayers the number of players * @return true if the stopping rule criteria are met */ bool canStop(const double alphaProbability, const double confidenceIntervalLength, const vector\u003cdouble *\u003e \u0026samples, const int nbPlayers) { const long long nbSamples = samples.size(); if (nbSamples \u003c 2) { return false; } double limit = stoppingRuleLimit(alphaProbability, confidenceIntervalLength, nbSamples); return variance(samples, nbPlayers) \u003c= limit; } /** * Normalize stacks (not really necessary but cheap) and invert to weights * @param stacks the stacks * @param nbPlayers the number of players * @param weights the destination array */ void fillWeights(const double *stacks, int nbPlayers, double *weights) { const double stacksAvg = accumulate(stacks, stacks + nbPlayers, 0.) / (double) nbPlayers; for (int i = 0; i \u003c nbPlayers; i++) { weights[i] = stacksAvg / stacks[i]; } } } /** * Perform one MC trial * * @param results destination array to add trial contribution into * @param payouts the contribution to add to the results per rank * @param weights something proportional to the inverse of the stacks of the players * @param permutation an array that will be used to store the permutation (permutation[i] = player that reaches rank i) * @param nbPlayers the number of players * @param rng random number generator * @param sorter function to sort the permutation */ void monteCarloIcmTrial(double *results, const double *payouts, double *weights, int *permutation, int nbPlayers, const RNG \u0026rng, const Sorter \u0026sorter) { monteCarloPermutation(weights, permutation, nbPlayers, rng, sorter); // Cumulate payouts according to the random permutation for (int j = 0; j \u003c nbPlayers; j++) { results[permutation[j]] += payouts[j]; } } /** * Monte-Carlo ICM Ranking algorithm. * * @param stacks the stacks * @param payouts the payouts * @param nbPlayers the number of players * @param trials the number of trials to perform * @param results destination array for ICM EV */ void monteCarloIcm(const double *stacks, const double *payouts, const int nbPlayers, const long long trials, double *results) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/ RNG rng = defaultRng(); int permutation[nbPlayers]; double weights[nbPlayers]; fillWeights(stacks, nbPlayers, weights); double contrib[nbPlayers]; // Prepare each trial ranking contribution to the total for (int i = 0; i \u003c nbPlayers; i++) { contrib[i] = payouts[i] / (double) trials; } const Sorter sorter = chooseSorter(payouts, nbPlayers); for (long i = 0; i \u003c trials; i++) { monteCarloIcmTrial(results, contrib, weights, permutation, nbPlayers, rng, sorter); } } /** * Monte-Carlo ICM Ranking algorithm with stopping rule. * * @param stacks the stacks * @param payouts the payouts * @param nbPlayers the number of players * @param results destination array for ICM EV * @param stoppingAlphaProbability the confidence probability * @param stoppingConfidenceIntervalLength confidence interval length (root mean square) * @param stoppingEvalLag the number of trials that are performed before each evaluation of the stopping rule */ long long monteCarloIcmWithStoppingRule(const double *stacks, const double *payouts, const int nbPlayers, double *results, const double stoppingAlphaProbability, const double stoppingConfidenceIntervalLength, long long stoppingEvalLag) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/ // Stopping rule : http://www.lib.ncsu.edu/resolver/1840.4/5244 (first method for independent samples) RNG rng = defaultRng(); int permutation[nbPlayers]; double weights[nbPlayers]; fillWeights(stacks, nbPlayers, weights); // For each trial we'll contribute the real payouts because we want to use them for the stopping rule // computation const Sorter sorter = chooseSorter(payouts, nbPlayers); vector\u003cdouble *\u003e samples; vector\u003cdouble *\u003e allocated; long long count = 0; while (true) { // While we don't stop according to the stopping rule, we create a batch of samples auto *memory = (double *) calloc(nbPlayers * stoppingEvalLag, sizeof(double)); // Store the allocated memory area pointer allocated.push_back(memory); for (long i = 0; i \u003c stoppingEvalLag; i++) { double *sampleMemory = memory + i * nbPlayers; monteCarloIcmTrial(sampleMemory, const_cast\u003cdouble *\u003e(payouts), weights, permutation, nbPlayers, rng, sorter); // Store the pointer to the sample samples.push_back(sampleMemory); } count += stoppingEvalLag; // Break if the stopping rule says it's enough if (canStop(stoppingAlphaProbability, stoppingConfidenceIntervalLength, samples, nbPlayers)) { break; } } // Sum the samples for (double *sample : samples) { for (int i = 0; i \u003c nbPlayers; i++) { results[i] += sample[i]; } } // Divide the sum to get the mean for (int i = 0; i \u003c nbPlayers; i++) { results[i] /= (double) count; } // Free the allocated memory areas for (double *memory : allocated) { free(memory); } // Return the number of samples that were generated return count; } } monte-carlo-icm.hpp Déclarez les fonctions qu’il vous intéresse d’exposer !\nA Brief Survey of Stopping Rules in Monte Carlo Simulations, 1968, Gilman - https://repository.lib.ncsu.edu/handle/1840.4/5244 ↩︎\n","description":"Un Monaco-Picon s’il vous plaît. En pinte.","tags":["Poker","AI","ICM","MTT","Game Theory","Monte Carlo"],"title":"Poker : MTT et ICM #3 - Méthode de Monte-Carlo","uri":"/posts/poker_mtt_icm_monte_carlo/"},{"categories":["Game Theory"],"content":"Dans mon précédent billet, je vous parlais des fonctions d’évaluation en théorie des jeux, plus particulièrement dans les tournois de poker No-Limit Hold’Em (NLHE), et spécifiquement de l’Independent Chip Model (ICM).\nPour rappel une fonction d’évaluation donne une estimation probabiliste des gains de chaque joueur en fonction de l’état du jeu. L’ICM utilise la taille des stacks des joueurs pour évaluer leurs chances d’atteindre chaque rang dans le classement final du tournoi. Ces probabilités multipliées par les prix de chaque rangs donnent une espérance de gain en monnaie sonnante et trébuchante qui permettra aux joueurs de prendre des décisions selon les issues possibles de ses actions.\nCalcul de l’ICM L’ICM suppose que la probabilité pour chaque joueur d’accéder à la première place est égale à la proportion représentée par son stack sur la totalité des jetons en jeu (la somme des stacks). Récursivement la probabilité pour un joueur A d’accéder à la seconde place va être une somme pour chaque autre joueur B en première place.\nSA = stack du joueur A SB = stack du joueur B P2A = probabilité du joueur A d'accéder à la seconde place, initialisé à 0 Pour chaque autre joueur B: P1B = probabilité du joueur B d'être premier = SB / Somme des stacks P2A_sachant_1B = probabilité du joueur considéré d'accéder à la seconde place quand le joueur B accède à la première place P2A_sachant_1B = SA / (Somme des stacks - SB) P2A = P2A + P1B x P2A_sachant_1B Pour calculer le tableau de valeurs de l’ICM en fonction des stacks et des prix (payouts) on pourrait écrire un algorithme de ce type :\npayouts = [Q1, Q2, Q3, ...] : prix pour la première, deuxième, troisième.. place. résultat = [RA, RB, RC, ...] : tableau des résultats, avec chaque valeur initialisée à 0 pour tout classement possible des joueurs : (prenons le classement (A, B, C...) pour l'exemple) p = probabilité de ce classement = P1A x P2B_sachant_1A x P3C_sachant_1A_et_2B x ... RA = RA + p x Q1 RB = RB + p x Q2 RC = RC + p x Q3 ... Voici un bout de code python naïf qui fait ça :\nfrom itertools import permutations import numpy as np def icm_proba(permutation, stacks: np.ndarray, stacks_sum: int): result = 1 for rank, player in enumerate(permutation): stack = stacks[player] result *= stack / stacks_sum stacks_sum -= stack return result def icm(stacks: np.ndarray, payouts: np.ndarray) -\u003e np.ndarray: if len(stacks) == 0: return np.array([]) nb_stacks = len(stacks) stacks_sum = sum(stacks) result = np.zeros((nb_stacks,)) for permutation in permutations(range(nb_stacks)): probability = icm_proba(permutation, stacks, stacks_sum) for rank, player in enumerate(permutation): result[player] += probability * payouts[rank] return result if __name__ == '__main__': val = icm(np.array([500, 300, 200]), np.array([600, 400, 0])) print(val) Output :\n[435.71428571 330. 234.28571429] On note la finesse du formattage\nComplexité Prendre tout classement possible de N joueurs, c’est ce qu’on appelle une permutation ou encore un arrangement. Et on calcule très facilement combien il existe d’arrangement pour un nombre donné de joueurs :\n1 : 1 (ben oui) 2 : 2 x 1 = 2 (juré ça change après) 3 : 3 x 2 x 1 = 6 4 : 4 x 3 x 2 x 1 = 24 5 : 5 x 4 x 3 x 2 x 1 = 120 C’est la factorielle, et on peut voir que ça croit très rapidement (plus vite qu’une exponentielle). Si on code ça comme ça on obtient une complexité tellement violente qu’il est difficile de calculer l’ICM au delà de 10 joueurs dans un temps raisonnable.\nPar exemple avec le code ci-dessus j’ai obtenu ces temps :\n3.695487976074219e-05 seconds for 2 players 2.8848648071289062e-05 seconds for 3 players 8.177757263183594e-05 seconds for 4 players 0.0006070137023925781 seconds for 5 players 0.0037360191345214844 seconds for 6 players 0.027889013290405273 seconds for 7 players 0.24523401260375977 seconds for 8 players 2.2415449619293213 seconds for 9 players 23.641671180725098 seconds for 10 players Je vous rappelle qu’à l’origine, je m’intéresse à l’ICM en tournoi multi-table. C’est à dire dans des tournois où le nombre de joueur est entre dix et… quelques milliers.\nDe plus, quand je regarde par exemple sur HoldemRessources, leur calculateur me répond en environ 200ms pour une vingtaine de joueurs. Même si ils ont mis un serveur très performant, on est dans des ordres de grandeur très lointains. On peut faire beaucoup mieux.\nPremière optimisation : passer en récursif et en C++ Eh oui car le Python n’est rapide que quand il appelle des bibliothèques compilées. Faisons-donc la notre ! Et j’en profite pour faire une version récursive de l’algorithme qui va nous économiser pas mal de multiplications pour le calcul de probabilité. En effet, on regroupe toutes les permutations pour lesquelles le premier joueur dans le classement est le joueur d’index 0 dans les stacks par exemple, mais voyez plutôt ci-dessous.\nAu premier appel, la fonction recursiveNaiveIcm va énumérer tous les joueurs possibles en première place. Pour chacun, elle va s’appeler elle-même pour la seconde place, etc.\nvoid recursiveNaiveIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts, vector\u003cdouble\u003e \u0026result, vector\u003cbool\u003e \u0026usedPlayers, const int rank, const int size, const double factor, const double stacksSum) { if (rank == size) { // No player to rank left return; } for (int i = 0; i \u003c size; i++) { if (usedPlayers[i]) { continue; } // ith player has already been considered // The probability to have this ith player at this rank knowing the previous ranking is stacks[i] / stacksSum // The total probability of this ranking chain is thus : const double newFactor = factor * stacks[i] / stacksSum; // Let's remember this player is ranked usedPlayers[i] = true; // Add his pondered payout to the result result[i] += newFactor * payouts[rank]; // Rank all possible next players recursiveNaiveIcm(stacks, payouts, result, usedPlayers, rank + 1, size, newFactor, stacksSum - stacks[i]); // Reset the flag usedPlayers[i] = false; } } // Entry point vector\u003cdouble\u003e naiveIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts) { // Number of players const int size = stacks.size(); vector\u003cdouble\u003e result(size); // Flags to note down players that were already considered vector\u003cbool\u003e usedPlayers(size); double stacksSum = accumulate(stacks.begin(), stacks.end(), 0.); recursiveNaiveIcm(stacks, payouts, result, usedPlayers, 0, size, 1, stacksSum); return result; } Je n’avais pas fait de C++ depuis plus de 10 ans alors on ne se moque pas. De mon temps on codait en C++98, on avait une orange à Noël, et on était content !\nVoyons ce qu’on gagne en temps d’exécution :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 2ms for 8 players Duration 18ms for 9 players Duration 177ms for 10 players Duration 2087ms for 11 players Duration 25924ms for 12 players Pas mal, on peut ajouter un onzième et un douzième joueurs pour presque le même temps de calcul. En gros, on a une accélération de 11 x 12, donc de l’ordre de la centaine !\nMais ça ne nous emmène pas si loin. Continuons de gratter !\nDeuxième optimisation : cache et C-moins-moins Supposons que nous avons n joueurs. À un moment du calcul où on a défini les rangs des k premiers joueurs, il reste n - k joueurs dont on va énumérer les différentes classements possibles.\nSi on prend ces mêmes k premiers joueurs mais dans un autre ordre, l’énumération des différents classements des n - k joueurs restants va être presque identique :\nsize, stacks et payouts ne bougent pas result est la destination, ce n’est pas un paramètre du calcul usedPlayers a les mêmes indexes à true (correspondant aux k joueurs classés) rank = k, c’est le même stacksSum correspond à la somme des stacks des n - k joueurs restants et a la même valeur En fait, seul le paramètre factor varie, car la probabilité d’avoir les k premiers joueurs classés dans un ordre ou un autre n’est pas la même.\nCependant, ce facteur est finalement appliqué à toutes les contributions des appels imbriqués. Mais on peut donc l’extraire et l’appliquer a posteriori.\nCe-faisant, on va calculer une seule fois cette sous-partie pour n - k joueurs au lieu de la calculer pour chaque classement des mêmes k premiers joueurs.\nSi en plus on applique ça pour tous les k entre 0 et n - 1, on n’a en fait à calculer la sous partie que pour toutes les combinaisons (de taille 1 à n) de joueurs.\nHors on sait très bien dénombrer également le nombre de combinaisons possible de joueurs parmis n, et c’est 2n. J’évoquais tout à l’heure la complexité factorielle de l’algorithme naïf, la réduire à une complexité exponentielle semble prometteur !\nOn va indexer les sous-calculs à mettre en cache selon la liste non-ordonnée des joueurs déjà classés, qui implicitement définit le rang actuel et la somme des stacks restants. Pour ce faire, on va choisir un vecteur de bits représenté par un entier, avec à 1 les bits des joueurs déjà classés, et on a une indexation parfaite (et on retombe d’ailleurs sur la complexité en 2n). En bonus, on peut se servir de ce bitmask pour remplacer l’ancien tableau de booléens, ce qui va nous économiser quelques cycles de CPU.\nPour ajouter encore un peu de perf, je vous mets avec ça des pointeurs old-sChool plutôt que des vectors, car oui, ça fait une vraie différence.\nEntendons-nous bien, le niveau d’optimisation dépend fortement de la nature du problème. Si on bosse sur une app de TODO list, le nombre d’opérations est tellement faible qu’il n’y a en général1 aucune raison de chercher à économiser des cycles de CPU. Mais quand on multiplie un nombre d’opérations par 220 c’est à dire environ un million, on s’approche dangereusement de la seconde d’exécution.\net voici ce que ça donne :\nvoid recursiveIcm(const double *stacks, const double *payouts, double *result, long long usedPlayers, int rank, int size, double factor, double stacksSum, double *cacheValues, bool *cacheFlags) { if (rank == size || payouts[rank] == 0) { return; } // Point subResult to the cache entry double *subResult = cacheValues + usedPlayers * size; // If the subResult wasn't computed previously, let's do it if (!*(cacheFlags + usedPlayers)) { for (int i = 0; i \u003c size; i++) { const long long iMask = 0x1ll \u003c\u003c i; if (usedPlayers \u0026 iMask) { continue; } // Probability of ith player to have this rank *among remaining players* // (ignoring previously ranked ones) const double newFactor = stacks[i] / stacksSum; // Fill the EV of this subresult for this player subResult[i] += newFactor * payouts[rank]; recursiveIcm(stacks, payouts, subResult, usedPlayers | iMask, rank + 1, size, newFactor, stacksSum - stacks[i], cacheValues, cacheFlags); } // Mark the cache entry as filled *(cacheFlags + usedPlayers) = true; } // Apply the factor accounting for previously ranked players and add to the destination array for (int i = 0; i \u003c size; ++i) { result[i] += factor * subResult[i]; } } vector\u003cdouble\u003e icm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts) { const int size = stacks.size(); // Prepare the array that will receive the results from the recursive function double result[size]; fill_n(result, size, 0); // Just translate vectors to C arrays double stacksArray[size]; double payoutsArray[size]; for (int i = 0; i \u003c size; ++i) { stacksArray[i] = stacks[i]; payoutsArray[i] = payouts[i]; } // Compute the total stack sum const double stacksSum = accumulate(stacks.begin(), stacks.end(), 0.); // ## Cache ## const auto cacheEntrySize = size * sizeof(double); // One double for each player // We'll store all cached subresult in this memory area. auto cacheValues = (double *) calloc(pow(2, size), cacheEntrySize); // And we'll store the information of whether each one is filled or not. auto cacheFlags = (bool *) calloc(pow(2, size), sizeof(bool)); // Ok let's go recursiveIcm(stacksArray, payoutsArray, result, 0, 0, size, 1, stacksSum, cacheValues, cacheFlags); // Just translate back to vector vector\u003cdouble\u003e toReturn(size); for (int i = 0; i \u003c size; ++i) { toReturn[i] = result[i]; } // And free the allocated memory free(cacheValues); free(cacheFlags); return toReturn; } Mais surtout le résultat en termes de performance :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 0ms for 8 players Duration 0ms for 9 players Duration 0ms for 10 players Duration 0ms for 11 players Duration 1ms for 12 players Duration 1ms for 13 players Duration 3ms for 14 players Duration 7ms for 15 players Duration 19ms for 16 players Duration 51ms for 17 players Duration 130ms for 18 players Duration 321ms for 19 players Duration 737ms for 20 players Vous aurez peut-être remarqué une optimisation supplémentaire : si le prix du rang concerné est nul on sort immédiatement. Sous l’hypothèse fort raisonnable que les prix sont décroissants, les calculs subséquents auraient en effet un effet nul. C’n’est peut-être qu’un détail pour vous mais c’est loin d’être anodin. On va ainsi réduire les combinaisons de joueurs à un classement uniquement pour les kclasses payées, ce qui nous donne en complexité une combinaison potentiellement réduite à Ckn après application du cache.\nLes chiffres ci-dessus valent lorsqu’aucun prix n’est nul, voici l’effet quand la moitié des places sont payées :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 0ms for 8 players Duration 0ms for 9 players Duration 0ms for 10 players Duration 0ms for 11 players Duration 0ms for 12 players Duration 1ms for 13 players Duration 1ms for 14 players Duration 4ms for 15 players Duration 9ms for 16 players Duration 17ms for 17 players Duration 47ms for 18 players Duration 90ms for 19 players Duration 276ms for 20 players On a donc deux facteurs qui vont déterminer le temps d’exécution :\nle nombre de joueurs le nombre de places payées Chemin d’optimisation Je vous passe bien sûr le cheminement détaillé, car j’ai pris le temps d’appréhender tout ce que j’avais raté ou oublié en termes de gestion de mémoire et des bibliothèques standards en C++20. En bref, disons que je suis passé par des versions bien plus moderne et haut niveau de cet algorithme avec notamment une std::map puis std::unordered_map puis robinhood::unordered_map pour le cache, des std::vector (qui se copiaient à chaque affectation ofc) puis des std::vector\u0026 et ensuite des std::shared_ptr\u003cstd::vector\u003e super hype pour finalement revenir à des pointeurs et calloc pour des questions de performance évidentes.\nComme disait Sam Waters : “Le profiling, c’est ma vie”.\nConclusion et quoi-est-après J’ai toujours en tête de comparer et de titiller les fonctions d’évaluation en MTT. J’ai maintenant une bibliothèque de calcul de l’ICM de qualité professionnelle, qui m’autorise des simulations de tournois pour un petit nombre de joueur. Ça peut être suffisant pour faire des tests qualitatifs sur quelques joueurs, mais j’ai envie de voir si je peux aller plus loin.\nComment calculer efficacement l’ICM pour 50 joueurs ? Ce sera très probablement le sujet de mon prochain billet !\nIl-y-a pas mal d’écoles différentes sur ce sujet bien sûr, et cette question prend de plus en plus d’importance avec la montée en puissance de l’éco-conception. D’un côté on risque de produire du code plus complexe, moins maintenable et moins fiable en cherchant l’optimisation, ce qu’on traduit par l’injonction “early optimization is the root of all evil” qui nous somme de garder le code simple à moins qu’il ne soit constaté nécessaire de l’optimiser -, de l’autre on assiste facilement à un phénomène d’encrassement à mesure que le code grossit : si des opérations suboptimales sont disséminées partout, l’optimisation consiste alors à tout réécrire et on regrette de ne pas avoir anticipé. Comme disait Bouddha : “La voie du milieu c’est bien, enfin rarement en voiture quand même”. ↩︎\n","description":"Où on calcule avec brutalité les espérances des joueurs selon un modèle indépendantiste.","tags":["Poker","AI","ICM","MTT","Game Theory"],"title":"Poker : MTT et ICM #2 - Le Calcul Brutal","uri":"/posts/poker_mtt_icm_calcul/"},{"categories":null,"content":"","description":"","tags":null,"title":"Gambler’s Ruin","uri":"/tags/gamblers-ruin/"},{"categories":["Game Theory"],"content":"Comme beaucoup, j’ai eu ma période “poker”. Elle s’est très vite traduite chez moi par la conception d’outils divers d’aide et d’analyse de jeu (parce que je suis trop mauvais), et a donné naissance à cette petite bibliothèque Java. J’ai tiré beaucoup de cette expérience, que ce soit en théorie des jeux, en algorithmique théorique et pratique, en intelligence artificielle ou même en architecture logicielle. Alors bon, je n’assume pas tout à fait cette vieille lib, “si je devais la recoder je le ferais différemment”™ - pas en Java notamment - mais ça fait partie de ces projets tentaculaires qui vous portent pendant des années et vous font monter en compétence sur un large front dans l’allégresse.\nÇa me titillait depuis longtemps de trouver un sujet dans le domaine et de bonnes raisons de m’y recoller. Quand soudain, je tombai sur le paradoxe de Saint-Pétersbourg qui relança avec un ami une vieille conversation sur l’évaluation de l’EV (expected value) en MTT (multi-table tournament).\nIl se trouve que la question “Faut-il jouer toutes les mains EV+ ICM en tournoi?” impliquait un long périple avec dedans du machine-learning, des simulations de jeu et des modélisations intéressantes - tout ce que j’adore.\nMais revenons au début, je vais commencer dans ce billet par tenter de vous expliquer la question.\nThéorie des jeux Au poker, on cherche souvent à jouer GTO (Game Theory Optimal). Derrière ce terme, beaucoup d’implicite. La théorie des jeux étudie les interactions stratégiques d’agents à cheval entre les mathématiques et les sciences sociales, avec de très intéressantes questions qu’on va oublier bien vite : Comment définit-on la rationalité des agents ? Est-elle normative ou prescriptive ? Quelles qualités descriptives a-t-elle ?\nVoilà, on oublie, et maintenant on constate que dans la plupart des cas, tout le monde cherche à trouver la meilleure manière de jouer pour gagner - que ce soit aux échecs, au poker, au go ou à Starcraft1.\nDans des jeux comme les échecs, les algorithmes n’explorent pas l’ensemble de l’arbre de jeu mais évaluent un certain nombre de coups à l’avance. Si je regarde les 5 prochains coups possibles et que sur cette base je dois faire un choix, il me faut évaluer la valeur de chaque situation future résultant de chaque combinaison possible de 5 actions. On appelle fonction d’évaluation cette estimation de la valeur d’une situation qui n’est pas une situation finale. Dans des jeux faisant intervenir la chance (l’aléatoire), on la confond souvent avec la valeur statistique d’espérance (EV, Expected Value : l’espérance), car on va prendre les décisions en fonction de l’EV calculé grâce la fonction d’évaluation. EV+ signifie ainsi “d’espérance positive”.\nPoker Le poker est un jeu de taille considérable du fait du nombre de combinaisons de cartes multiplié par le nombre de séquences d’action (mises) de jeu possibles. Je parle ici uniquement du No-Limit Hold’Em (NLHE) qui est la variante la plus commune.\nDans le cas du cash-game où les jetons misés valent une somme déterminée d’argent, le problème de l’optimisation de la stratégie est circonscrit à une main. Cela reste énorme en complexité mais permet aux explorations algorithmiques de ne pas recourir à des fonctions d’évaluation intermédiaire, et d’interpréter directement les gains et pertes futurs résultant des actions en terme d’argent.\nEn effet, lorsqu’on va chercher à évaluer si telle action est préférable à telle autre, on va faire ce genre de calcul :\nSi je me couche, à la fin de la main j’ai un stack (un tapis) de 900 jetons. Si je suis la mise, selon les cartes qui vont être révélées : j’ai 40% de chances de finir avec un stack de 1300 jetons j’ai 60% de chances de finir avec un stack de 500 jetons Je peux donc calculer mon espérance :\nMe coucher : 900 jetons Suivre : 0,4 x 1300 + 0,6 x 500 = 820 jetons Ok, je dois donc rationnellement me coucher, car plus (+) de jetons, c’est mieux.\nTournoi Dans un tournoi cependant, les prix sont attribuées selon la place finale d’un joueur. Prenons le cas de trois joueurs qui doivent partager 1000€ de prix et disposent en tout de 1000 jetons. Nous ne connaissons rien des joueurs, si bien qu’on les considère aveuglément à égalité stratégique.\nSi seul le premier joueur remporte les 1000€ il paraît raisonnable d’estimer leurs chances de gagner proportionnellement à leurs stacks. On peut d’ailleurs vérifier ça très facilement en leur faisant échanger des jetons aléatoirement (ce qui simule bien l’égalité stratégique). Si les stacks sont 500, 300 et 200, alors en moyenne le premier joueur remportera la mise 50% du temps, le second 30% et le dernier 20%. Leurs espérances de gain sont donc 500€, 300€ et 200€ respectivement.\nPetite simulation pour vérifier ça :\nimport numpy as np import random nb_simulations = 100000 players_stacks = [5, 3, 2] # We'll exchange chips one by one, so let's speed-up by setting smaller stacks payouts = [1000, 0, 0] nb_players = len(players_stacks) podiums = [] for i in range(nb_simulations): game_stacks = players_stacks.copy() podium = [] while True: in_game_players = [i for i, stack in enumerate(game_stacks) if stack \u003e 0] if len(in_game_players) == 1: # We have a winner podium = in_game_players + podium break # Exchange chips until one player is broke while True: # Randomly select two players random.shuffle(in_game_players) p1 = in_game_players[0] p2 = in_game_players[1] # And make them exchange one chip game_stacks[p1] += 1 game_stacks[p2] -= 1 # Is the losing player broke ? if game_stacks[p2] == 0: podium = [p2] + podium break # Recompute in_game_players podiums.append(podium) result = [0.0] * nb_players for podium in podiums: for i in range(nb_players): player = podium[i] result[player] += payouts[i] result = np.divide(result, nb_simulations) print(result) Output :\n\u003e [499.611 299.829 200.56 ] Ce qui m’a bien l’air de converger vers le résultat attendu.\nPetite note sur la taille des stacks allègrement divisée par 100 : il se trouve que ça n’a aucune influence, je l’ai vérifié expérimentalement. Cependant comme j’aimerais bien savoir pourquoi et que je n’ai pas le temps de creuser, j’ai posé la question à l’Internet.\n[EDIT] Au temps pour moi, la proportionalité n’est pas la seule à compter. La taille des stacks a bien une influence dans le cas suivant où le second joueur a un prix ! Ceci-dit, même si mes chiffres sont légèrement biaisés ça n’invalide en rien le propos.\nMaintenant, si le premier joueur remporte 600€ et le second 400€, a-t-on les mêmes espérances de gain ? Faisons donc tourner cette simulation avec ces payouts :\npayouts = [600, 400, 0] Output :\n\u003e [445.71 330.83 223.46] Il est tout de suite moins intuitif d’estimer ça à vue de nez.\nICM Le jeu simulé ci-dessus est le Gambler’s Ruin (qui est en soi plus un problème théorique qu’un jeu).\nLa performance de cette simulation est très faible pour de nombreux joueurs avec de nombreux jetons. Il existe des techniques de calcul avancées que je n’ai pas encore explorées, car en pratique les joueurs de poker préfèrent modéliser leur espérance de classement grâce à l’Independent Chip Model (ICM) dont le calcul est bien plus simple.\nL’ICM est un modèle qui statue que la contribution à l’accès à la première place du tournoi est la même pour chaque jeton, puis récursivement pour les places suivantes. On retrouve donc la proportionnalité entre les jetons et l’espérance lorsque seul le premier joueur remporte le prix.\nAttention cependant, l’ICM n’est pas une solution du classement du problème du N-players Gambler’s Ruin. C’est par contre une approximation commune.\nPour la situation ci-dessus, l’ICM nous donnera donc avec les stacks [500, 300, 200]:\nEn notant X_Y = le joueur X finit en Yième position.\nP1_1 = 500 / 1000 = 0.5 P2_1 = 300 / 1000 = 0.3 P3_1 = 200 / 1000 = 0.2 Puis récursivement, en appliquant la formule des probabilités totales, on calcule la probabilité que le joueur 1 soit deuxième :\nP1_2 = P2_1 * P(1_2 | 2_1) + P3_1 * P(1_3 | 3_1) P1_2 = 0.3 * (500 / 700) + 0.2 * (500 / 800) = 0,339 De même pour les autres joueurs et ainsi de suite pour la troisième place. Pour vous éviter les calculs à la main, il existe des calculateurs en ligne. Celui d’HoldemResources et celui d’ICMIzer.\nPour notre situation, l’ICM nous donne les valeurs :\n\u003e [435.71 330.00 234.29] Pour comparer les résultats, la simulation de Gambler’s Ruin nous donnait :\n\u003e [445.71 330.83 223.46] On retrouve un biais classique de l’ICM qui est de sous-estimer la valeur des plus gros stack et de surestimer les plus petits, tout en restant très correct pour les autres.\nRécapitulatif Prenons un tout petit peu de recul. Pourquoi a-t-on besoin de cet ICM déjà ?\nParce que lorsqu’on cherche une stratégie optimale, on doit estimer la valeur des situations vers lesquelles nous mènent nos actions potentielles. Dans le cas du cash-game, la valeur est immédiatement disponible en fin de main car elle est directement proportionnelle à la quantité de jetons. Mais pour un tournoi, il faudrait aller jusqu’à la résolution du tournoi entier pour observer le gain obtenu. Et autant dire que lorsqu’on doit dérouler toutes les possibilités de tirages et d’actions futures, on préfère circonscrire le problème à la main en cours pour avoir un résultat avant la fin des temps dans le cas d’un calcul informatique.\nOn préfèrerait savoir calculer les espérances de classement selon le modèle du Gambler’s Ruin, hélas il est beaucoup plus compliqué d’avoir une performance correcte dans ce calcul (ceci dit à ce sujet, j’ai dans ma pile de lectures quelques papiers que j’explorerai je l’espère un de ces jours2).\nLa fonction d’évaluation est un outil sur lequel on va soit entrainer des IA, soit faire des analyses stratégiques avec des joueurs réels, mais elle ne représente pas l’espérance concrète des joueurs la plupart du temps. Et c’est d’ailleurs en général ce qu’on souhaite, car essayer de se rapprocher des valeurs concrète c’est essayer de revenir à la résolution du tournoi entier en utilisant stratégies calculées sur la base de la fonction d’évaluation… Et c’est l’Ouroboros.\nPourtant on pourrait faire tendre vers plus de réalisme. Si on sait par exemple qu’un tournoi typique regroupe des joueurs de différents niveaux distribués d’une manière assez régulière, modéliser ce fait statistique peut produire une fonction d’évaluation plus adaptée à l’entraînement pour ce contexte de jeu. Car pour une IA, le jeu sur laquelle on l’entraîne inclut la fonction d’évaluation. Sa confrontation au jeu réel sera lourdement affectée par le choix de cette fonction. On peut d’ailleurs arbitrairement considérer que le niveau des joueurs fait partie des données d’entrée de la fonction. Cependant on préfère reporter ce genre de données contextuelles vers les algorithmes stratégiques pour garder une fonction d’évaluation générique et stable : l’appréciation du niveau des joueurs est une donnée stratégique et contextuelle, elle sera donc intégrée comme une donnée d’entrée des mécanismes stratégiques.\nConclusion La question “Faut-il jouer toutes les mains EV+ ICM en tournoi?” prise littéralement a une réponse immédiate : non, il-y-a même des ajustements que l’on sait bénéfiques. Tout d’abord il est fort probable qu’une meilleure approximation du classement du Gambler’s Ruin donnerait de meilleurs résultats, ensuite s’il était possible de calculer une fonction d’évaluation prenant en compte les asymétries du poker (tables de jeu et tours de parole) on augmenterait certainement encore la fiabilité de l’évaluation.\nMais après cette question vient la suivante : peut-on trouver un meilleur modèle que l’ICM calculable efficacement ? Expérimentalement par exemple, pourrait on appliquer des techniques modernes de machine learning pour trouver une fonction d’évaluation qui surpasse l’ICM ? Et comment faire tout ça en pratique et pour un grand nombre de joueurs sachant que le calcul de l’ICM a une complexité factorielle ?\nDes débuts de réponses dans un prochain billet !\nPS: dans ce billet, j’essaye de ne pas trop rentrer dans les détails ce qui vaut des imprécisions et des raccourcis volontaires. N’hésitez cependant pas à m’écrire si vous trouvez à redire, ou s’il-y-a des manques criants !\nPS bis: en cadeau, un petit papier sympa qui montre deux théorèmes contre-intuitifs.\nTheorem 1. Suppose a tournament has prize money for nth place which is at least that for (n + 1)st place and that at least one player still in the tournament will not earn as much as second place prize money. Under the Independent Chip Model, any fair bet in which only one other player can gain or lose chips in the hand being played will lower the player’s expected prize money.\nTheorem 2. Suppose a tournament has prize money for nth place which is at least that for (n + 1)st place and that at least one player still in the tournament will not earn as much as second place prize money. Under the Independent Chip Model, the expected prize money of any player not involved in a fair bet between two players will increase*\nTraduit à la pelle par :\nSi t’es en duel avec une équité de 50% contre un seul adversaire au sein d’un tournoi avec des prix croissants, tu es perdant selon l’ICM. Si deux joueurs sont en duel dans ces mêmes circonstances, tous les autres joueurs sont gagnants en ICM. Ces jeux sont de natures très variées. C’est ce qui fait d’ailleurs qu’à l’heure actuelle, les meilleures IA de poker sont basées sur des techniques très différentes de l’impressionnant MuZero de DeepMind (j’espère avoir le temps de faire un petit papier “CFR vs Reinforcement Learning pour les nuls” tiens). ↩︎\nles papiers en question : Swan, Y., \u0026 Bruss, F. (2006). A matrix-analytic approach to the N-player ruin problem. Journal of Applied Probability, 43(3), 755-766. doi:10.1239/jap/1158784944, et Gambler’s Ruin and the ICM - arXiv:2011.07610v2. Et bien sûr toutes leurs références 🙃 ↩︎\n","description":"Où il est question des fonctions d’évaluation en théorie des jeux, du Gambler’s Ruin et de l’ICM.","tags":["Poker","AI","ICM","MTT","Gambler's Ruin","Game Theory"],"title":"Poker : MTT et ICM #1 - La Question","uri":"/posts/poker_mtt_icm_question/"},{"categories":null,"content":"Je suis architecte logiciel généraliste et algorithmicien polyglotte.\nDe l’idée à la ligne de code, les choix sont innombrables et variés. Distinguer les décisions qui importent et les qualifier efficacement est aussi déterminant que l’expertise technique.\nToujours motivé par la recherche de la solution la plus pertinente dans les contextes des plus communs aux plus complexes mais aussi par sa réalisation de bout en bout, contactez-moi pour me parler de vos projets :\npar email pierre@pittscraft.com par téléphone (ou Signal, Whatsapp, Telegram) au +33 (0)6 62 98 24 38 Pierre Mardon (Pitt)\n","description":"","tags":null,"title":"À propos","uri":"/about/"},{"categories":null,"content":"","description":"","tags":null,"title":"Combine","uri":"/tags/combine/"},{"categories":null,"content":"","description":"","tags":null,"title":"SwiftUI","uri":"/tags/swiftui/"},{"categories":["Application mobile"],"content":"J’avais déjà croisé un exemple d’implémentation de property wrapper et devant leur simplicité, je m’étais mis en tête de créer un property wrapper accélérant le stockage de valeurs dans les UserDefaults.\nIl se trouve que dans mes expérimentations autour de Combine j’avais bien envie de créer un wrapper publiant les nouvelles valeurs seulement après les avoirs stockées (voir ici).\nEt puis j’ai finalement voulu faire tout en même temps !\nQu’est-ce donc qu’un property wrapper ? Un property wrapper très simple s’écrit de cette manière :\n@propertyWrapper public class Print\u003cValue\u003e {ss private var val: Value public init(wrappedValue value: Value) { val = value } public var wrappedValue: Value { set { print(\"Setting '\\(val)'\") val = newValue } get { print(\"Returning '\\(val)'\") return val } } } et s’utilise ensuite ainsi :\nclass SomeClass { @Print var myString: String = \"Coucou copaing !\" func doThings() { myString = \"Bye friend\" var something = myString } } SomeClass().doThings() ce qui imprimera\n\u003e Setting 'Bye friend' \u003e Getting 'Bye friend' ce qui est plutôt nul.\nCeci-dit, si on décidait de faire des choses plus intéressantes que des print, on pourrait bien se faciliter la vie !\nGot UserDefaults ? Stocker des propriétés dans les UserDefaults Voilà un usage fréquent et intéressant.\n@propertyWrapper public struct UserDefaultsBacked\u003cValue\u003e { private let key: String private let defaultValue: Value private let storage: UserDefaults public init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) { defaultValue = value self.key = key self.storage = storage } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Et une implémentation un peu naïve comme celle ci-dessus peut faire l’affaire.\nUn petit warning quand même, on n’oublie pas que chaque setValue sur une clé de UserDefaults réécrit le dictionnaire complet. On utilisera donc tout ça en connaissance de cause, et n’oublions pas qu’on peut aussi réduire leur taille en n’utilisant pas systématiquement le .standard.\nOn peut noter la présence de nouveaux arguments du constructeur, la key et le storage. Ils peuvent être fournis via la déclaration de l’annotation, ou doivent l’être pour ceux qui n’ont pas de valeur par défaut comme la key.\n@UserDefaultsBacked(\"int-key\") // Smells like Java var someInt = 8 @UserDefaultsBacked(\"my-data\", storage: UserDefaults(\"DBName\")) var someData: Data? = nil struct SomeStruct { var prop = \"Yup\" } @UserDefaultsBacked(\"my-struct\") var myStruct = SomeStruct() // Wait... What ? Stocker uniquement les types compatibles Ce wrapper fonctionnera très bien avec tous les types supportés par les UserDefaults mais attendez-vous à de bons crashes pour tous les autres cas, comme SomeStruct.\nRestreignons-donc déjà l’usage aux bonnes valeurs grâce à un flag protocol :\npublic protocol UserDefaultsStorable {} extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} @propertyWrapper public struct UserDefaultsBacked\u003cValue\u003e { private let key: String private let defaultValue: Value private let storage: UserDefaults public init(wrappedValue value: Value, key: String, storage: UserDefaults = .standard) where Value: UserDefaultsStorable { defaultValue = value self.key = key self.storage = storage } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Ok, on a maintenant un property wrapper sélectif et une belle erreur de compilation dans le cas où le type ne se conforme pas à UserDefaultsStorable.\n@UserDefaultsBacked(\"my-struct\") var myStruct = SomeStruct() // Error: Initializer 'init(wrappedValue:_:storage)' requires that 'SomeStruct' conform to 'UserDefaultsStorable' Stocker les Codables Bien mais SomeStruct n’est pas bien mystérieux, ce serait bien sympa de pouvoir le stocker aussi. En fait, tout codable est a priori stockable puisque Data l’est. Seulement pour éviter de se faire la conversion à chaque accès, profitons donc de notre wrapper.\nGénéralisons : on peut avoir à mapper les données dans un sens et dans l’autre pour pouvoir les stocker. L’interface de UserDefaults utilise le très générique Any?, on va donc définir les mappers :\ntypealias StoringMapper\u003cValue\u003e = (Value) -\u003e Any? typealias StoreReadingMapper\u003cValue\u003e = (Any?) -\u003e Value? Puis:\ndéfinir des propriétés de ce type dans notre wrapper. définir un constructeur privé aveugle qui prend de bonne fois n’importe quel type de propriété avec des mappers définir des constructeurs publics stricts sur le type qui vont fournir des mappers au constructeur privé @propertyWrapper public class UserDefaultsBacked\u003cValue\u003e { private let key: String private let storage: UserDefaults private let defaultValue: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String , storage: UserDefaults, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { var initValue = value if let storedValue = storeReadingMapper(storage.object(forKey: key)) { initValue = storedValue } defaultValue = initValue self.key = key self.storage = storage self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Mais pour mes Codables les mappers ne sont pas si évidents.\npublic extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } Ci-dessus la fonction d’encodage, avec absolument pas de check sur le cas où l’objet est également stockable nativement, car la discrimination s’effectuera en amont. Bon, c’est l’équivalent de try? JSONEncoder().encode(self) mais avec une trace pour ne pas être complètement dans le brouillard en cas de problème. Evidemment on préfèrera certainement donner de meilleures options de traçage, et certains se sentent mal (à raison) de ne pas throw quoi que ce soit, mais ce n’est pas le débat ici. Et puis comme on dit parfois : “Quand tout va bien, tout va bien !”.\n/// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } Joyeusement pompé de ce post SO\nTiens je parlais dans mon poste précédent de type erasure, mais saviez vous que l’inverse est le type opening ? Eh bien pareil, je me suis couché moins bête. Et pour tous ceux qui ont déjà joué avec un JSONDecoder dans des contextes génériques un peu poussés, la feinte ci-dessus est plutôt cool à retenir : une fonction statique a toujours accès au type concret, ce qui satisfait le compilo.\npublic extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to ignore thrown errors return nil } } } Et voilà, sur tout type se conformant à Decodable on a désormais cette fonction mapOutOfStorage.\nJe rappelle que typealias Codable = Decodable \u0026 Encodable, donc pour tout type Codable on a nos deux mappers \\o/\nRajoutons donc ce petit constructeur à notre property wrapper UserDefaultsBacked :\nconvenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, storingMapper: Value.mapForStorage, storeReadingMapper: Value.mapOutOfStorage) } Nice, et maintenant qu’est ce qui se passe si je déclare quelque chose comme :\n@UserDefaultsBacked(\"myKey\") var myInt = 0 // Error: Ambiguous use of 'init(wrappedValue:_:storage:sendAfterStore:)' Eh bien les Int étant Codable mais aussi UserDefaultsStorable, le compilateur ne saura quel constructeur choisir. Deux solutions : enlever l’ambiguité en changeant la signature d’un des constructeurs (ce qui est un peu minable, même simplement d’y avoir pensé), ou donner un constructeur qui match encore mieux, avec where Value : Codable \u0026 UserDefaultsStorable. Encore un bon trick, vous êtes bienvenus.\nCheckpoint Voici un petit bilan :\n/// Any type implementing this protocol can be stored natively in UserDefaults public protocol UserDefaultsStorable {} /** Declare proper flag protocol conformance for all types natively compatible with UserDefaults storage */ extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} /// `Encodable` mapping for storage public extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } /// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { // Useful trick from https://stackoverflow.com/questions/54963038/codable-conformance-with-erased-types static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } /// `Decodable` mapping for reading from storage public extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to almost ignore thrown errors return nil } } } @propertyWrapper public class UserDefaultsBacked\u003cValue\u003e { private let key: String private let storage: UserDefaults private let defaultValue: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String, storage: UserDefaults, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { defaultValue = value self.key = key self.storage = storage self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, storingMapper: Value.mapForStorage, storeReadingMapper: Value.mapOutOfStorage) } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable \u0026 UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: {$0 as? Value}) } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Fun fact : j’ai retrouvé le même flag protocol sur un post (je l’ai plus sous la main là), puis vu des implémentations proches pour les Codable, mais tout ça bien sûr après avoir réinventé la roue. Et même si on dit souvent ça péjorativement, dans une démarche d’apprentissage ça a tout son sens de regarder les solutions seulement ensuite. Et en plus c’était vachement moins bien fait, genre là pas de type checking, aucune cohabitation entre les Codable et les types natifs… Nan mais jvous jure…\nEt puis de toute façon je voulais aussi m’occuper de faire …\nUn publisher un peu custom Lorsqu’on utilise SwiftUI et Combine simplement, on va naturellement devoir taper des expression comme $myState ou $myObject.prop. Une fois passée mon aversion forte pour le PHP, j’ai creusé rapidement pour constater que ce n’était qu’une syntaxe un peu flippante pour accéder à la valeur projetée d’une wrapped property.\nProjected value ? En bref, n’importe quel property wrapper peut déclarer une var projectedValue: SomeType {...} dont le type n’est pas nécessairement le même que celui de sa wrappedValue. Et cette projectedValue est accessible grâce au dollar américain (comme tellement de choses).\n@propertyWrapper public class Print\u003cValue\u003e { private var val: Value public init(wrappedValue value: Value) { val = value } public var wrappedValue: Value { set { print(\"Setting '\\(val)'\") val = newValue } get { print(\"Returning '\\(val)'\") return val } } public var projectedValue: Int { print(\"42\") return 8 } } @Print var myString: String = \"5\" myString = \"40\" print(\"Coucou \\($myString)\") printera donc\n\u003e Setting '40' \u003e 42 \u003e Coucou 8 Aaah, je pense que j’ai fait le pire exemple qui soit, “service !” comme on dit dans l’est.\nBref, ce $ n’a en théorie pas forcément grand chose à voir avec Combine excepté qu’on l’y utilise en permanence.\nQuelques notions de Combine Typiquement, le property wrapper Published a pour type projeté la struct Published\u003cValue\u003e.Publisher (doc) qui respecte notamment le protocole Publisher (et bien plus, doc), et peut donc envoyer des Value à des Subscriber.\nDonc quand j’accède à un @Published var myString: String via $myString j’obtiens en gros une propriété dont je peux écouter les valeurs successives.\nEt quand je fais du SwiftUI ainsi : .sheet(isPresented: $vm.router.showSheet, ...), je passe donc un Publisher à la fonction sheet qui se fera un plaisir d’écouter si on doit où non présenter cette sheet.\nRappel : lorsqu’on utilise sink pour écouter les valeurs d’une var @Published via son Publisher, on reçoit la nouvelle valeur alors que la wrappedValue est encore l’ancienne valeur. Et je voudrais contourner ça dans certains cas (voir mon post précédent).\nMaintenant, ce qui m’intéresserait ce serait d’avoir ça, un Publisher que je pourrais contrôler finement pour lui envoyer des valeurs. Eh bien Combine nous fournit gracieusement le protocole Subject qui hérite de Publisher et qui présente de surcroit une fonction send(_:) permettant d’envoyer des valeurs à publier. Ses implémentations sont :\nCurrentValueSubject qui détient une valeur courante PassthroughSubject qui au contraire ne retient rien On devrait s’en sortir avec ça !\nDidSet Publisher property wrapper Pour reproduire le comportement de @Published on pourrait écrire comme ça comme ça.\n@propertyWrapper public class BasicPublished\u003cValue\u003e { private let subject: CurrentValueSubject\u003cValue, Never\u003e public init(wrappedValue value: Value) { subject = CurrentValueSubject(value) wrappedValue = value } public var wrappedValue: Value { set { subject.send(newValue) } get { subject.value } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } Le problème étant que lorsque le send va provoquer l’exécution de toutes les closures des subscribers, subject.value aura toujours l’ancienne valeur.\nAssez simple du coup d’y remédier :\n@propertyWrapper public class DidSetPublished\u003cValue\u003e { private var val: Value private let subject: CurrentValueSubject\u003cValue, Never\u003e public init(wrappedValue value: Value) { val = value subject = CurrentValueSubject(value) wrappedValue = value } public var wrappedValue: Value { set { val = newValue subject.send(val) } get { subject.value } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } (je crois que cette implémentation vient de là, et je crois aussi qu’il serait plus pertinent d’utiliser PassthroughSubject a priori)\nTout ensemble Vous le saviez, mon but ultime était ~la conquête de la Suède en lama~ de combiner tout ça. Pas juste pour le fun, mais parce que dans mon archi, à un moment, j’avais besoin d’une propriété Codable (un enum) stockée dans les UserDefaults et qui ne publierait son changement de valeur qu’après l’avoir affecté à sa wrappedValue.\nEt puis d’autres besoins avec des variations : pas de stockage mais publication après affectation, stockage natif mais publication avant affectation…\nJ’aurais bien pu contourner tout ça, ou encore essayer de faire fonctionner des wrappers imbriqués, mais je voulais me frotter à cette implémentation spécifique.\nEt voilà, je vous colle juste l’ensemble là dessous, chaque détail étant expliqué dans les parties précédente (enfin faut savoir quelques trucs en amont quand même, oui).\nN’oubliez pas que la perf n’est pas l’objectif de ce wrapper (du tout).\nJe vous suggère d’ailleurs de jeter un oeil à l’implémentation de Published chez OpenCombine, qui est particulièrement élégante (ya un enum \u003c3).\n// // SmartPublished.swift // attestation // // Created by Pierre Mardon on 01/01/1970. Trust me. // import Foundation import Combine /// We need functions to map values before storing them to user defaults fileprivate typealias StoringMapper\u003cValue\u003e = (Value) -\u003e Any? /// We need functions to map values read from user defaults storage to an expected type fileprivate typealias StoreReadingMapper\u003cValue\u003e = (Any?) -\u003e Value? /// Any type implementing this protocol can be stored natively in UserDefaults public protocol UserDefaultsStorable {} /** Declare proper flag protocol conformance for all types natively compatible with UserDefaults storage */ extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} /// `Encodable` mapping for storage public extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } /// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { // Useful trick from https://stackoverflow.com/questions/54963038/codable-conformance-with-erased-types static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } /// `Decodable` mapping for reading from storage public extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to almost ignore thrown errors return nil } } } /** Property wrapper that provides some common use cases options. Do NOT use for heavy performance demanding components. - `UserDefaults` storage is activated when a `key` is provided for all natively handled types and `Codable` ones - option `sendAfterStore` makes the subject send the value only after it has effectively been affected to the property itself: WARNING this is not recommended for UI bindings. Disabled by default. Usage: \\``` @SmartPublished(\"someKey\") var myProp = \"Bonjoir !\" \\``` The string property will be backed in UserDefaults.standard for the key \"someKey\". It will be effectively stored only if the value of the var is affected after its initialization, until then UserDefaults entry will stay untouched. The initial value of the property will be `\"Bonjoir !\"` if there's not value in the store. \\``` @SmartPublished(\"myCodableValueUserDefaultsKey\") var myProp = someValueOfCodableType \\``` The codables are stored the same way except they are JSON encoded if they're not natively handled by UserDefaults. \\``` @SmartPublished(sendAfterStore = true) var myProp = 8 $myProp.sink { print(\"property: \\(myProp), received: \\($0)\") } myProp = 1 \\``` Will print `property: 1, received: 1`, while with `@Published` or `sendAfterStore = false` it would be `property: 8, received: 1`. It is not recommended to use this `sendAfterStore = true` for UI-bound properties. \\``` @SmartPublished \\``` Why would you do that, just use `@Published` then! */ @propertyWrapper public class SmartPublished\u003cValue\u003e { private let key: String? private let storage: UserDefaults private let sendAfterStore: Bool private let subject: CurrentValueSubject\u003cValue, Never\u003e private var val: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String? , storage: UserDefaults, sendAfterStore: Bool, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { var initValue = value if let key = key, let storedValue = storeReadingMapper(storage.object(forKey: key)) { initValue = storedValue } val = initValue subject = CurrentValueSubject(initValue) self.key = key self.storage = storage self.sendAfterStore = sendAfterStore self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper subject.send(val) } public convenience init(wrappedValue value: Value, _ key: String? = nil, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, _ key: String?, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0.mapForStorage()}, storeReadingMapper: Value.mapOutOfStorage) } public convenience init(wrappedValue value: Value, _ key: String?, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable \u0026 UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, sendAfterStore: Bool = false) { self.init(wrappedValue: value, nil, storage: .standard, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: {$0 as? Value}) } public var wrappedValue: Value { set { if sendAfterStore { subject.send(newValue) } if let key = self.key { storage.setValue(storingMapper(newValue), forKey: key) } else { val = newValue } if !sendAfterStore { subject.send(newValue) } } get { if let key = self.key { return storeReadingMapper(storage.value(forKey: key)) ?? val } return val } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } N’hésitez pas à me contacter pour toute remarque, insulte ou éloge, mon email est dans le footer ;)\n","description":"","tags":["iOS","Combine","SwiftUI"],"title":"SwiftUI \u0026 Combine Feedback #2 : property wrapper pour UserDefaults et @Published","uri":"/posts/swiftui_combine2/"},{"categories":["Application mobile"],"content":"Après mon premier petit TP autour de SwiftUI et Combine pour générer mes attestations de déplacement ~à la barbe de la maréchaussée~ à la volée voire en retard, j’ai profité de l’adaptation au second format d’attestation pour faire des explorations un peu plus poussées de mon architecture autour de Combine.\nJ’en sors une petite liste de considérations techniques que j’espère d’intérêt, et voici les premières !\nArchitecture: MVVM+ Pour une petite app comme celle-ci, je m’autorise des entorses à nombre de principes stricts overkill que je n’estime pas pertinents ici, avec des gains principalement en concision et lisibilité. Le MVVM est tout à fait indiqué pour un cloisonnement minimal, et en l’occurence ça ressemblait à ça\nAvec des injection par construction et donc cette instanciation initiale :\nlet store = Store(context: moContext) let model = MainViewModel(store: store, router: Router()) return MainView(model: model) On peut remarquer le petit Router qui s’est avéré fort utile pour éviter trop de plomberie. Son rôle est juste de publier des propriétés destinées à contrôler et rendre compte de la navigation. Il ne fait donc clairement pas partie du modèle ni des vues, et j’ai du mal à le considérer comme un modèle de vue étant donnée sa nature transverse.\nTant qu’il ne dépasse pas ce rôle de navigation, ne stocke qu’un minimum de données transitoires au besoin (immuables de préférence, la struct d’une personne à éditer par exemple), ça reste très lisible et on évite les chaînages de @Published orthodoxes.\nenum ActiveSheet { case attestationPresentation(person: PersonStruct), addPerson, edit(person: PersonStruct) } enum ActiveAlert { case confirmAttestation, detail(reason: Reason) } class Router: ObservableObject { @Published var showSheet = false @Published var showAlert = false private(set) var activeSheet = ActiveSheet.addPerson private(set) var activeAlert = ActiveAlert.confirmAttestation func showAttestationCreationAlert() { activeAlert = .confirmAttestation showAlert = true } func startAddPerson() { activeSheet = .addPerson showSheet = true } func startEdit(person: PersonStruct) { activeSheet = .edit(person: person) showSheet = true } func showReasonDetail(_ reason: Reason) { activeAlert = .detail(reason: reason) showAlert = true } func showAttestationView(person: PersonStruct) { activeSheet = .attestationPresentation(person: person) showSheet = true } func closeSheet() { showSheet = false } } Plutôt concis, ça vaut clairement le coup plutôt que de perdre ces quelques variables dans des chemins trop tortueux.\nTous mes proches le savent, les enums Swift c’est ma grande passion. Et ceux du petit routeur ci-dessus me permettent de faire des fonctions SwiftUI bien compactes :\nfunc alert() -\u003e Alert { switch vm.router.activeAlert { case .confirmAttestation: return Alert(title: coldFeetTitle, message: coldFeetMessage, primaryButton: .default(Text(\"Je certifie\")) { vm.generateNewAttestation() }, secondaryButton: .cancel(Text(\"Annuler\"))) case .detail(reason: let reason): return Alert(title: Text(reason.niceString), message: Text(reason.detail), dismissButton: .default(Text(\"Ok\"))) } } func sheet() -\u003e AnyView { switch vm.router.activeSheet { case .attestationPresentation(let person): return AnyView(AttestationView(vm: vm.attestationViewModel(person: person))) case .addPerson: return AnyView(AddOrEditPersonSheet(vm: vm.addPersonViewModel)) case .edit(let person): return AnyView(AddOrEditPersonSheet(vm: vm.editPersonViewModel(person: person))) } } Et enfin, le body de ma View principale sera très concis :\nvar body: some View { NavigationView { VStack(alignment: .center, spacing: 5) { MainListsView(model: vm.mainListsViewModel).environment(\\.editMode, $editMode) BottomMenu(model: vm.bottomMenuViewModel) } .sheet(isPresented: $vm.router.showSheet, onDismiss: { vm.checkShouldShowPinnedAttestation() }, content: sheet) .navigationBarTitle(\"\", displayMode: .inline) .navigationBarItems(leading: navigationBarLeadingItem, trailing: EditButton(editMode: $editMode)) } .alert(isPresented: $vm.router.showAlert, content: alert) } (on peut comprendre d’ailleurs pourquoi je sépare le showSheet et showAlert des enums, au lieu de déclarer des .none)\nLa vue principale est la principale consommatrice du routeur, cependant de multiples vues viennent agir dessus.\nEvidemment, cette architecture est adaptée à ce projet particulier, ne cherchez pas à reproduire ça à la maison.\nLes petits trucs pénibles Type erasure Ci-dessus, vous pouvez voir que j’utilise AnyView(...) pour renvoyer un type consistant de View. Pour tous ceux qui ont joué un peu en profondeur avec les protocoles et génériques en Swift, on atteint vite des obstacles mystérieux particulièrement brainboiling.\nHeureusement on observe un effort de type erasure dans les bibliothèques système avec ces AnyView, AnyCancellable…\nAinsi que de nouveaux mots clé mystérieux comme some qui est la réponse directe à la sentence :\nProtocols ‘WouldBeSoNice’ can only be used as a generic constraint because it has Self or associated type requirements\nSi ça vous intéresse je vous conseille ce petit article.\nCeci-dit, même si ça disparaît vite, je pense que c’est un frein assez considérable notamment pour des débutants.\nObserver des objets imbriqués Un ViewModel en mode Combine doit avoir cette allure :\nclass MyViewModel : ObservableObject { @Published var someProperty = \"Coucou copaing !\" } Le wrapper @Published est tout à fait adaptée aux structs puisque toute mutation d’une struct est un changement de valeur. Mais les classes si elles sont faites pour être mutées ne remonteront point l’évènement au wrapper.\nOr pour observer une propriété imbriquée au deuxième niveau dans SwiftUI, comme .sheet(isPresented: $vm.router.showSheet) {…}, on peut essayer :\nd’observer le routeur qui serait une struct et de prendre sa valeur showSheet avec le routeur en ObservableObject, observer directement showSheet Eh bien aucune des deux options ne fonctionne directement depuis une vue SwiftUI. Ce petit $ qui désigne la projectedValue d’une propriété encapsulée par un @Published ou un @State n’est pas magique, et ça ne fonctionne qu’au premier niveau, c’est à dire un @Published propriété d’un ObservableObject.\nEt la feinte officielle n’est pas bien glorieuse :\nclass MyViewModel : ObservableObject { @Published var router = Router private var cancellables = Set\u003cAnyCancellable\u003e() init(router: Router) { self.router = router router.objectWillChange.sink { [weak self] _ in self?.objectWillChange.send() }.store(in: \u0026cancellables) } deinit { cancellables.forEach({ $0.cancel() }) } } Il-y-a des variantes plus concises au prix de sacrifices discutables, mais voilà le principe. A chaque fois que le routeur va changer, on va propager l’évènement pour indiquer à l’UI de se rafraîchir. C’est un peu large, un peu “Mario fait du Combine”, mais ne soyons pas obtus, si ça roule après tout…\nUne bonne alternative est de mettre tout ça à plat dans la vue :\nstruct MyView: View { @ObservedObject private var vm: MainViewModel var body: some View {...} } deviendrait\nstruct MyView: View { @ObservedObject private var vm: MyViewModel @ObservedObject private var router: Router var body: some View {...} } C’est plus élégant je trouve, mais imaginons que j’ai 8 entités un peu complexes à embarquer dans mon VM, ça commence alors à foisonner plus que de raison.\nAutre point en passant, impossible de sécuriser l’instance embarquée du routeur dans le view-model avec un private(set) modifier dans la première version. C’est de l’ordre du TOC - c’est bien d’en être conscient - mais ça me gène 😅\nPropager des @Published, Model -\u003e VM -\u003e View class Store : ObservableObject { @Published private(set) var someUrl: URL? } class MyViewModel : ObservableObject { @Published private(set) var someUrl: URL? init(store: Store) { store.$someUrl.assign(to: \u0026$someUrl) } } Mais c’est très raisonnable, super ! Oui mais iOS14+ seulement.\nEt voici la version iOS 13 :\nclass Store : ObservableObject { @Published private(set) var someUrl: URL? } class MyViewModel : ObservableObject { @Published private(set) var someUrl: URL? private var cancellables = Set\u003cAnyCancellable\u003e() init(store: Store) { store.$someUrl.sink { [weak self] url in self?.someUrl = url }.store(in: \u0026cancellables) } deinit { cancellables.forEach({ $0.cancel() }) } } * whip sound *\nPas mal hein ?\n* whip sound *\nSink twice silence génant\nQuand on observe un sujet avec sink, sachez que la valeur qui vous est passée en closure est celle qui va être attribuée, comme lorsqu’on utilise willSet sur une propriété (quelques détails ici).\nPas de problème pour l’update d’UI, c’est fait pour. Mais pour les autres besoins, comme par exemple quand on a des mécanismes complexes intermédiaires qui ne se résument pas à fusionner deux valeurs publiées, la meilleure chose à faire est encore de créer son publisher.\nEt même si j’aurais encore beaucoup à dire autour de ce sujet, je réserve à un futur article une petite contribution autour de ce sujet, des property wrappers et consorts.\nN’hésitez pas à m’écrire si vous avez un avis quelconque sur ce que j’ai écrit, mon email est (?) dans le footer ;)\n","description":"","tags":["iOS","Combine","SwiftUI"],"title":"SwiftUI \u0026 Combine Feedback #1 : architecture et grains de sable","uri":"/posts/swiftui_combine1/"},{"categories":["Application mobile"],"content":"\nIl m’est arrivé plusieurs fois d’oublier mon attestation de sortie (c’est mal), de la générer au volant en panique (c’est très mal), de prendre du retard en tapant le formulaire avant de partir… Loin de moi l’idée de débattre du bien-fondé du confinement et de ses modalités, cependant j’étais confronté à un inconfort mineur. Et comme tout bon ingé, j’ai cherché et évalué des solutions complètement superflues - toutefois avec un indiscutable sérieux et un professionnalisme inébranlable.\nLa voie des anciens Imprimer des attestations préremplies et ne laisser que le motif, la date, l’heure et la signature à remplir.\nOui ça marche, mais la matérialisation est une contrainte forte. Si on oublie de remplir son attestation (c’est mal) et qu’on prend la voiture on n’a pas de moyen de gérer la situation sans un 180° bien crissant (ce qui est certes classe mais dangereux).\nOn me dit dans l’oreillette qu’on peut tout à fait écrire une attestation à la main sur papier libre… Oui mais bon, change pas de sujet, j’ai pas de stylo ni de papier sur moi, voilà, et puis niveau ergonomie, c’est so les millénaires passés l’écriture…\nLa voie officielle #1 (web) J’ai essayé de faire avec la page web gouvernementale. Et franchement, c’est correct sur ordinateur avec le bon équipement logiciel. J’utilise personnellement un navigateur Chromium avec le plugin de mon gestionnaire de mots de passe Dashlane. Le seul inconfort évident est la lecture des motifs du déplacement. J’ai commencé à faire un petit plugin Chrome pour retravailler ça avant de me raviser rapidement : les plugins ne fonctionnent pas sur les navigateurs Chromium iOS et la génération sur portable est bien plus pratique.\nLa voie officielle #2 (TousAntiCovid) On monte en qualité avec le générateur intégré à l’application TousAntiCovid. Il est possible de faire retenir mes coordonnées par l’appli et les motifs ont un titre en gras qui permet d’y voir un peu plus clair. Cependant je ne suis pas intéressé par la fonctionnalité de traçage de cette application. Donc je n’ai pas apprécié quand j’ai dû impérativement autoriser l’app à utiliser le bluetooth à la première ouverture. Et puis en regardant ça, je commençais à avoir ma petite idée de l’appli idéale donc toutes les petites frictions du parcours pour générer mon autorisation me faisaient tiquer. Ca fait quand même pas mal d’étapes après ouverture de l’application :\nscroll tout en bas tap sur Attestation de déplacement tap sur Nouvelle attestation entrer mes données - ok ça s’enregistre on ne le compte pas tap (optionnel) sur l’heure pour régler l’heure de ma sortie - je n’ai jamais touché à la date jusque là tap pour choisir le motif de déplacement (qui ne s’enregistre pas) sur mon iPhone, il faut 3 hauteurs d’écran pour lire intégralement la liste des motifs, on ajoute donc souvent un scroll ou deux tap sur le motif tap sur Générer alerte de confirmation : tap sur Je certifie Donc dans le cas idéal (je pars maintenant, c’est bien moi qui gènère l’attestation et je suis la dernière personne à avoir utilisé le générateur sur cet appareil, et mon motif est mon caractère laborieux) j’ai donc 7 actions avant d’obtenir le QR Code tant convoité. C’est beaucoup.\nLa voie des ptits malins (app iOS Raccourcis) Certaines boîtes comme Luko ou Newzik vous proposent de générer un lien qui contient vos données, et qui mène à un générateur automatique qui affiche l’attestation générée avec l’heure de sortie actuelle.\nL’idée est notamment d’utiliser un raccourci déclenché par Siri par exemple pour commander son attestation à la voix ou encore la faire ouvrir automatiquement dès qu’on quitte son domicile. On n’est pas loin de la solution idéale, seulement je ne peux pas générer une attestation à la bourre.\nCeci-dit, ce lien est un bon exemple de ce qu’on peut faire rapidement pour se faciliter la vie. Quelques bookmarks, un peu de configuration et pour les gens pas trop technophobes on s’en sort.\nL’app de mes rêves Cahier des charges L’app de mes rêves\ndans le meilleur des cas, nécessite une seule action pour générer une attestation si le motif change, une à deux actions supplémentaires sont tolérables. demande le plus rarement possible des actions supplémentaires. permet à ma compagne de faire son attestation sur mon téléphone sans effacer mes données préremplies gère très efficacement mon cas pathologique d’oubli. Elle doit donc me permettre de générer mon attestation lorsque je me rends compte après 20 minutes de trajet que j’ai oublié mon attestation : pour être dans les clous, mon heure de sortie doit alors être 20 minutes dans le passé n’embarque aucune autre fonctionnalité non souhaitée n’envoie aucune donnée à qui que ce soit (pas de tracking publicitaire ou autre) n’utilise aucune bibliothèque tierce non maîtrisée à 100% Je me suis auto-défié, et au bout d’une petite journée de développement j’avais un prototype fonctionnel, ce qui m’a encouragé à continuer. Au bout de trois jours de développement j’avais une app présentable, les aspects légaux étaient confirmés, et la plupart des raffinements majeurs étaient implémentés.\nRéalisation ! Je suis bien content d’annoncer que j’ai respecté *presque* tous les points de l’app de mes rêves. Seule entorse, comme il faut quand même être un peu sérieux, j’ai ajouté une confirmation de véracité des données à la génération de l’attestation, on a donc deux actions pour générer l’attestation.\nTout comme pour la solution de génération par liens, j’ai récupéré le code publié par le ministère de l’intérieur pour générer les PDFs en inspectant son intégralité, en extrayant uniquement les parties nécessaires, puis en le modifiant pour son intégration dans l’app.\nJe ne vais pas vous cacher que je n’aurais pas fait cette application juste pour me faciliter les sorties. Je voulais également expérimenter SwiftUI, la bibliothèque déclarative d’interface utilisateur d’Apple qui me tend les bras depuis plusieurs années, et c’était une bonne occasion.\nEt voici le résultat :\nVue principale Ici on peut :\najouter / supprimer / réordonner les personnes sélectionner un ou plusieurs motifs de sortie sélectionner la date de sortie en temps relatif par rapport à l’heure actuelle : les boutons du Stepper (+ / -) ajoutent ou retirent 10 minutes et surtout aller vers l’attestation ! Vue d’édition de personne Un simple formulaire tout bête :)\nPrésentation de l’attestation Très simple, on peut juste :\npartager le PDF épingler l’attestation : dans ce cas la présentation en carte ne se laisse pas fermer comme d’habitude par swipe vertical, la croix de fermeture disparaît, et au cas où l’utilisateur ferme l’app, l’attestation sera restaurée à la réouverture Temps de génération de l’attestation : 3s Dans mon usage quotidien, avec ma (vraie) identité de remplie, je mets environ 3s à remplir mon attestation entre l’ouverture de l’app, le choix ou la vérification du motif et le réglage ou la vérification de l’heure. Oui je suis lent, mais mon objectif est atteint, je peux sans risque générer mon attestation dans des situation d’urgence et d’oubli \\o/\nApp Store ? Eh bien malgré ma gestion paranoïaque des données utilisateur, il semble que ce ne soit pas suffisant pour Apple qui (je pense) n’autorise simplement aucune app avec cette fonctionnalité sauf celle du gouvernement.\nWe found in our review that your app provides services or requires sensitive user information related to the COVID-19 pandemic. Since the COVID-19 pandemic is a public health crisis, services and information related to it are considered to be part of the healthcare industry. In addition, the seller and company names associated with your app are not from a recognized institution, such as a governmental entity, hospital, insurance company, non-governmental organization, or university.\nPer section 5.1.1 (ix) of the App Store Review Guidelines, apps that provide services or collect sensitive user information in highly-regulated fields, such as healthcare, should be submitted by a legal entity that provides these services, and not by an individual developer.\nJ’ai évidemment fait appel mais je ne pense pas qu’ils cèderont, tant pis, je ne partagerai donc mon app qu’avec mes proches (du moins ceux qui possèdent un iPhone) !\nDéveloppement : retour d’XP SwiftUI + Combine Tout d’abord SwiftUI est très agréable à utiliser. On a évidemment les traditionnelles errances de XCode 12, que ce soit niveau compilation, complétion, aperçu de l’UI… Mais il convient de saluer la prouesse qu’est l’implémentation de ce framework, un très bon exemple de DSL sur Swift, qui s’y prête particulièrement bien.\n1struct AddEditPersonSheet: View { 2 3\t// Local state 4 @State 5 private var tappedOkButton = false 6\t7\t// The ViewModel data and callbacks / Yeah I should have created a struct for this 8 @Binding 9 var editingPerson: EditingPerson 10 let isCreation: Bool 11 var cancelAddPerson: () -\u003e Void 12 var endAddOrEditPerson: () -\u003e Void 13 14\t// No constructor (structs are cool) 15\t16 private var title: String { 17 isCreation ? \"Créer\" : \"Modifier\" 18 } 19 20 private func isEmpty(_ str: String) -\u003e Bool { 21 str.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty 22 } 23 24 var body: some View { 25 NavigationView { 26 Form {ss 27 Section(header: Text(\"Identité\")) { 28 if tappedOkButton \u0026\u0026 isEmpty(editingPerson.firstName) { 29 Text(\"Prénom manquant\").foregroundColor(.red) 30 } 31 TextField(\"Prénom\", text: $editingPerson.firstName).textContentType(.givenName) 32 if tappedOkButton \u0026\u0026 isEmpty(editingPerson.lastName) { 33 Text(\"Nom manquant\").foregroundColor(.red) 34 } 35 TextField(\"Nom\", text: $editingPerson.lastName).textContentType(.familyName) 36 } 37 // ... other sections 38 } 39 .navigationBarItems(leading: Button(action: cancelAddPerson) { 40 Text(\"Annuler\") 41 }, trailing: Button(action: { 42 withAnimation { 43 tappedOkButton = true 44 if (editingPerson.isValid) { 45 endAddOrEditPerson() 46 } 47 } 48 }) { 49 Text(\"Enregistrer\") 50 }.disabled(tappedOkButton \u0026\u0026 editingPerson.isValid)) 51 .navigationBarTitle(Text(title), displayMode: .inline) 52 } 53 } 54} Pas de critiques les puristes, j’ai fait du monolingue et du gros inline volontairement.\nDéveloppement rapide : Grâce à cette approche DSL, on se retrouve avec du code à l’imbrication proche de l’UI, facilement intelligible, avec de très bons comportements par défaut. Comme c’était mon premier test j’ai forcément un peu ramé, mais j’aurais pris bien plus de 3 jours de développement pour une petite app complète, fonctionnelle et propre si j’avais dû rapprendre UIKit ou pire : HTML + CSS.\nLe couplage avec Combine permet de s’engager sur le chemin des state-driven apps. Pour avoir pas mal joué avec React + Redux, je ne peux que vous inciter à adopter ce paradigme. Evidemment, quand on n’a jamais fait que de la programmation impérative, beaucoup de petites choses peuvent être frustrantes au premier abord. Mais ça dégraisse tellement ! Et pour ceux qui ont déjà eu des interrogations philosophiques sur les architectures logicielles en iOS - entre MVC = Massive View Controller par exemple) et le trop souvent overkill VIPER -, SwiftUI + Combine incitent très naturellement à dérouler le code en MVVM, apportant enfin une alternative moderne et structurante.\nRIP UIKit ? : Bien sûr que non, SwiftUI est principalement une surcouche d’UIKit qui a encore de beaux jours devant lui. On peut d’ailleurs palier assez facilement l’absence de nombreux composants essentiels de SwiftUI en encapsulant une UIView, comme j’ai dû le faire pour le lecteur PDF et la webview qui appelle le code de génération du document PDF.\nC’est tout, ce fut un bon petit défi sympa et enrichissant !\nJ’espère avoir l’occasion de récrire sur Swift qui reste un de mes langages préférés, mais pour le moment je replonge dans mes projets TypeScript qui se positionne franchement pas mal non plus et a l’avantage d’être largement adopté en dehors du petit monde Apple.\n","description":"","tags":["iOS","Combine","SwiftUI","confinement","covid"],"title":"Attestation 2s iOS","uri":"/posts/attestation-ios/"},{"categories":null,"content":"","description":"","tags":null,"title":"confinement","uri":"/tags/confinement/"},{"categories":null,"content":"","description":"","tags":null,"title":"covid","uri":"/tags/covid/"},{"categories":null,"content":"Merci de patienter un instant…\n","description":"","tags":null,"title":"Redirection vers la salle de réunion","uri":"/visio/"}]

[{"categories":null,"content":"","description":"","tags":null,"title":"Android","uri":"/tags/android/"},{"categories":null,"content":"","description":"","tags":null,"title":"Application mobile","uri":"/categories/application-mobile/"},{"categories":null,"content":"","description":"","tags":null,"title":"Architecture","uri":"/tags/architecture/"},{"categories":null,"content":"","description":"","tags":null,"title":"Categories","uri":"/categories/"},{"categories":null,"content":"","description":"","tags":null,"title":"iOS","uri":"/tags/ios/"},{"categories":null,"content":"","description":"","tags":null,"title":"Kotlin","uri":"/tags/kotlin/"},{"categories":null,"content":"","description":"","tags":null,"title":"Pitt‚Äôs Craft","uri":"/"},{"categories":null,"content":"","description":"","tags":null,"title":"Posts","uri":"/posts/"},{"categories":["Application mobile"],"content":"Over the dozen mobile missions I worked on, the main caveats of codebases I faced were that the Model is unclear and disseminated, and data paths and behaviors are hardly readable.\nThis article digs into these problems and offers concrete directions on the architectural level, as well as some advices on the implementation level.\nIt‚Äôs not supposed to create a new shiny big-brained architecture abstraction, but it rather aims to explicit practical design advices that should bring clarity and reliability to your app‚Äôs business.\nThis article‚Äôs scope is wide but I tried to make it concise enough. It‚Äôs addressed to developers and architects of intermediary to expert level. It‚Äôs also deeply anchored in my own experience, including all the biases it can carry.\nTL;DR ‚ö†Ô∏è The diagram below can look like a new annoying architecture claiming to be the state of the art.\nWell it‚Äôs not.\nFurther you‚Äôll see multiple mitigations, for example about the need of some Repositories. Also, I do not introduce new layers or too strict data paths (like VIPER does) that lock you in a specific paradigm.\nThis article is about practice and pragmatism, and the balance to avoid both spaghetti code and over-engineering.\nStill, this is a ‚ÄúTL;DR‚Äù so here you go!\nI. Model and Repositories concepts in architecture patterns Mobile devs often mistake Model for ‚Äúdata model‚Äù.\nHere is the Wikipedia‚Äôs schematic of MVVM:\nFrom https://en.wikipedia.org/wiki/Model‚Äìview‚Äìviewmodel\nWell, ‚ÄúBusiness Logic and Data‚Äù seems to be much more than ‚Äúdata model‚Äù.\nWhen you‚Äôre searching about mobiles architectures online, it‚Äôs in fact one of the most precise descriptions of the Model you can get.\nFrom https://www.techyourchance.com/mvc-android-1/\nSometimes, the Model is just assimilated to Repositories.\nFrom https://medium.com/swlh/mvi-architecture-with-android-fcde123e3c4a\nAnd sometimes there‚Äôs something between the ViewModel and the Repositories.\nNamely UseCases:\nFrom https://dev.to/kaleidot725/implementaing-jetpack-compose-orbit-mvi-3gea\nOr Interactors:\nFrom https://medium.com/@thereallukesimpson/clean-architecture-with-mvvmi-architecture-components-rxjava-8c5093337b43\nOf course you can find infinite minor variations of such schematics, with local models for example like above, or ViewModel‚Äôs model.\nBut in most cases the terminology is:\nModel: Business Logic and Data\nRepository: API with a backend, a local storage, a SDK‚Ä¶\nII. The Problem MVC, MVP, MVI, MVVM‚Ä¶ There are many paradigms helping you bind your business logic to your actual UI implementation. But in the end, none of them is meant to help your with your actual business logic implementation. Well there‚Äôs VIPER and friends, but I‚Äôm trying to avoid over-engineering here.\nThe first step in dealing with this issue is usually to identify the model to the repositories. What you get when your apps starts growing, is often ViewModels reuse: ViewModels are not always tight to one specific View because you need some business logic that it implements in some other part of your app. And then you start carrying extra business logic to many Views because you needed a piece of it, and your architecture becomes fuzzy.\nThe second step is to look at clean architecture principles and its applications in the mobile context, and introduce UseCases or Interactors (couldn‚Äôt get the difference in implementations I actually saw). And in fact, that‚Äôs a nice step: now you‚Äôve got identified entities that carry your business logic.\nThe third step is to get overwhelmed with instabilities or maintainability problems even though you were very thorough in your intermediary layer implementation.\nThe final step is to switch to a new project, hoping your problems were intrinsic to some other part of the app - typically the backend - and you may not find them in this whole new shiny project.\nIII. The solution: materialize the Model First things first: you need that extra layer between your UI (Views and ViewModels) and the Repositories. If I were to define terms again, I would call this the Model. And I do in the scope of this article.\nUI should be dumb as hell. It changes often, and you don‚Äôt want to embed any business logic in it.\nRepositories should be dumb as well. They are only interfaces to CRUD systems, SDKs or a backend, all the related complex work is done inside them.\nShift all complexity you can to this business layer. And organize it.\nIsn‚Äôt that what UseCases and Interactors are supposed to do? Well it really depends how you implement them. The usual caveat is that these terms imply unitary implementations: each one is focused on one specific task (getting some data or executing a command).\nYou just atomized your Model.\nReusing common code inside a feature brings more files and code navigation becomes harder and harder. Some build a graph of UseCases and in the end, the issue is that it‚Äôs just not readable. New needs will be implemented poorly if done by a dev that doesn‚Äôt know the graph on its fingertips.\nSo let‚Äôs call the entities of this business layer something else. Arbitrarily I‚Äôll call them ‚ú®Services‚ú®, but feel free to choose your own terminology. And let‚Äôs make these Services more consistent.\nIV. Model‚Äôs theory From my experience, apps that have the least bugs have a Model that is:\ncompact thorough split in enough and not too many Services actually depicting the app‚Äôs domain And one of the best way to achieve that is to conceive it.\nTake your hands off the code and draw your Model.\nI must insist because too many devs are focusing on UI first, then try to bind it to the repositories while considering that 99% of the work already done, and don‚Äôt bring enough care to this step.\nIn fact, my favorite approach is to conceive and implement the Model first, before even writing the first line of UI code.\nA good model implements the app‚Äôs domain while accounting for practical constraints.\n1. App‚Äôs domain representation a. Your Model has Entities Not only backend‚Äôs one (and often not all of them): your mobile app is not just an externality, it has its own business to mind!\nb. Services contracts should be exposed The inputs (commands) and outputs (values, events) of each feature (the Service‚Äôs responsibility) should be gathered and have a place to stand.\nc. But what IS the app‚Äôs domain? It‚Äôs how you represent the world knowing:\nwhat interface you need to provide to the UI for it to perform its job how the Repositories behave and what actual work should be achieved in between. It‚Äôs not what the repositories do or what the UI does, but it‚Äôs the abstraction of what the ‚Äúbindings‚Äù manipulate and do.\n2. Practical constraints Our domain describes the business that happens between the UI and the Repositories. As such, it must account for input and output abilities and needs on both sides.\nTo put it another way: as the app‚Äôs domain stands for the Model‚Äôs design, the constraints of the Model‚Äôs I/Os should be considered in the domain.\nConcretely, what can these constraints be then?\na. The UI navigation The Model should not take care of the navigation, but it should definitely drive most of it in the sense that UI components (like VMs, or Coordinators for UIKit veterans) should be able to perform very direct navigation flows while staying dumb enough.\nb. The UI SDK There aren‚Äôt many alternatives in the mobile world anyway, but mainly if your UI SDK is declarative or imperative (SwiftUI vs UIKit, Jetpack Compose vs legacy Jetpack) can make a great difference.\nc. The UI architecture Should you decide to use MVVM, MVI or TCA, all of them don‚Äôt define your model. But they might shape your model output: Do you better store a global reactive state or divide it by feature, by flow?\nd. The repositories natures A RESTFul API, a reactive NoSQL storage (like Firestore), a local relational DB with an ORM, an IoT SDK‚Ä¶ Each kind of repository has specific constraints: it may be asynchronous or not, online or not, and expose specific paradigms that may impact greatly how the entire app should work.\nI‚Äôm not saying we shouldn‚Äôt abstract many specificities of the repositories, but that some of them sometimes shape at least a bit their abstraction anyway.\n3. What your Model feels like I think that there are three great criteria to judge if your Model is well written.\nIf you take a look at your Services interfaces / protocols and your entities, you should see a satisfying representation of your domain. Don‚Äôt think about the implementation, don‚Äôt think about UI details: do you see your domain while reading your Model? If you think about binding your Model to the UI you‚Äôre supposed to build, are the bindings obvious? If you think about using your Repositories to create these Services, does it make sense? V. Quick parenthesis: Clean Architecture In Android especially (I guess because it‚Äôs a child of Java culture), there is a great influence of Clean Architecture theory. Sometimes, layers separation concerns come at the point that you may have the same entity duplicated 3 times for theoretical reasons, but bringing literally nothing in practice - worse, sometimes introducing weaknesses. That‚Äôs just not pragmatic and I would advise you against these kinds of maniac satisfaction.\nThere can be good reasons to follow unproductive rules, and the limit is thin between good design principles and a blind worship.\nSo a couple of advices you can go with is to read a lot about clean architecture (it‚Äôs a very nice theoretical basis) and to adapt theory to what actually works, in practice and for your team.\nMy proposal should mostly fit in Clean Architecture paradigm, but I don‚Äôt consider it necessary.\nAbout that, let‚Äôs take a step backward.\nVI. Pragmatic Mobile Architecture I drawn a concise representation of the architecture I use in all my mobile jobs and missions. Don‚Äôt ignore the text in it, it‚Äôs not decorative but really part of the architecture. Else it‚Äôs just totally similar to UseCase/Interactor architectures (except for the naming).\nFirst, you will find that this architecture is compatible with MVVM, MVI, MVP‚Ä¶ Of course, as I focus on the (green) Model part, you can tune the details of the UI layer as you wish.\nThen you can see that my graph is kinda oriented (well navigation is a strange beast), and that‚Äôs a quality that I kept from Clean Architecture. It‚Äôs really a key point to make things clean.\nAnother point hidden in the text, is that Services form an oriented graph. To explicit things a bit, it means that this Services graph:\nis totally valid. I know it can be tempting to have explicit Service layers and to apply isolation rules between them, but in practice I‚Äôm convinced it‚Äôs terribly counter-productive. I‚Äôd say we‚Äôre stepping in the overengineering area.\nNote that an obvious golden rule is to never-ever let UI use Repositories directly. If you do so, you‚Äôre missing modeling. Also, even if it can be a local reasonable shortcut, it will make precedence and you‚Äôll soon be back in the spaghetti hell we‚Äôre trying to escape from.\nOn the opposite, sometimes it does not make sense to create some Repositories.\nI also just materialized what I wrote earlier about entities: I happily let them flow from Repositories to UI when it‚Äôs relevant.\nFinally, what‚Äôs not described in this diagram is how to design your Services.\nVII. Service design and beyond I gave you a few directions on what the app‚Äôs domain and its Model are. This should lead the theoretical conception of your Services. Then I briefly presented my favorite shape of Model architecture. Now I want to share how I actually implement all of this with a simple list of practices. It‚Äôll be a lot less structured, more opinionated, but you can see that as pointillism. Crossing all of these should define a relevant frame to write a good Model with nice intrinsic qualities, and still with a good performance.\n1. CQRS everywhere CQRS stands for Command and Query Responsibility Segregation.\nIn our context, it translates to:\nA function can either query data or execute a command, but never both.\nIt can seem dumb and/or impractical, but just applying this rule will enhance your data flow and your commands flow readability more than you‚Äôd expect.\nI admit, there are high value exceptions sometimes, beginning with the result of a command (that is actually data). But in many cases, the data that a command would return is either:\na success / error flag that can be ignored by the caller and taken into account by the Service, making potentially this event flow in a query channel if needed updated data that is already bound via a query channel A specific mention here for reactive programming: it‚Äôs even more important in this paradigm to avoid side effects and not mix query streams and command streams (as it‚Äôs easier to confuse them).\n2. Reactive, async, imperative‚Ä¶ My personal balancing lead me to use reactive programming in a very limited scope. The main reason for that (putting aside my personal taste) is that most devs are used to imperative programming, and reactive programming adds a big overhead to their project onboarding. Readability for junior devs and staffing ease are actual concerns. It also brings intrinsic qualities to your Model.\nThus I advise to use reactive programming:\nonly for queries relative to reactive data exposed by services. By reactive data, I‚Äôm speaking about values that can change over time. A counter-example is an HTTP request as it encapsulates an execution returning a single result: an asynchronous function will be way more explicit for this purpose. On the contrary, a service exposing data that may be fetched or not, or updated at any point should expose a reactive stream. by using streams that always provide a value as soon as you subscribe to them, except for events of course. Use nullables, enums with associated values (Swift) or sealed class (Kotlin) to represent initial values if needed. by publishing only values and make your streams error proof. Manage errors ASAP, and turn them to Model states or values (or ignore them if it‚Äôs relevant), before even emitting through reactive streams: it‚Äôs simpler for consumers, there‚Äôs only one linear stream to handle. Else many will just consider them as an unwanted consequence of Services business implementation and in many case wrongfully ignore them. it forces you to make errors management explicit and in the right place. One Service‚Äôs model can be designed to expose its errors explicitly, and another one‚Äôs consuming it can handle their side effects and expose an errorless Model to UI. by not exposing completing streams. Handling the end of a stream is another difficulty that should be handled ASAP, for the same reasons as errors. It makes a lot of sense if you use reactive streams only for reactive data queries (first point). So flatMap internally as much as needed, or use relays that won‚Äôt complete, and if you still want to let a stream complete (it can make sense), just don‚Äôt expect consumers to handle it. still allowing direct values exposure when it‚Äôs needed from consumers. A plain old var is straightforward and explicit, and sometimes a one time value is needed. Don‚Äôt make things complicated for consumers when they should be exposed simply. This way, most of the unknowns and difficulties of reactive paradigm go away.\nNote that we can do this because Swift Concurrency and Kotlin Coroutines have made their holes.\nThe reactive hell trying to fix the callback hell is no longer a thing: what is asynchronous should be asynchronous (using either async functions in Swift or suspend ones in Kotlin).\nStill, I suggest to make asynchronous functions private in most cases. If the result of an asynchronous command is not needed or can flow through a query channel without adding complexity, the consumers will bless you. Also, checking which function is called in an asynchronous context will be much easier.\nBut of course, if your ViewModel needs to perform a single remote command and it‚Äôs relevant that it‚Äôs it that locally manages the loading state of its View, then don‚Äôt overthink and make your asynchronous function public.\n3. Main Thread is the place to be In mobile apps, you know that when any event or data triggers the UI, it should happen on the main thread. So let‚Äôs try to do everything here!\nIf there‚Äôs a sensible performance issue, identify what should be done in the background and encapsulate with clear boundaries what code will run in the background. But don‚Äôt do it by default. If you‚Äôve got 1000+ entities to process and map, don‚Äôt be frightened by big numbers and just check the execution time if you have any doubt.\nSometimes, your performance issue is caused only by bad code. Manually finding relationships between huge lists of entities with nested loops can be unnecessarily long to execute: optimize it and use caches, Sets or HashMaps (Dict for Swifters) instead of moving your process to the background in the first place.\nIf you still implement a background task and it should trigger anything else (publish on a reactive stream for example at any point of some heavy process), do it on the main thread.\nSome would rather try to always make ViewModels consume what Services provide on the main thread. But it‚Äôs not enough. Not knowing by default if any Service output will happen on the main or a background thread is too risky. It can also lead to concurrency issues and unexpected race conditions in the business code. Monothread paradigm is simple, comfortable and safe.\n4. Avoid inheritance OOP is no more the center of the world, and its nice principles are no more the state of art. The issue with inheritance is that it‚Äôs a bit hard to design properly, implement and read, especially for juniors. In simple case it‚Äôs not of course. But in general it can easily be split down to interfaces (protocols), composition, value types and concrete utilities. Your Model‚Äôs quality will increase while doing so.\nAs usual, stay pragmatic. If you see a real benefit to inheritance and the alternatives are overkill, then use inheritance.\n5. Do you really need this Repository? Don‚Äôt be systematic in your architectural approach on this point. A great example is user preferences (UserDefaults in iOS, SharedPreferences in Android). If you have a simple utility function that takes a key and allows to build a get / set / reactive-stream property from it, using it inside your Service directly is way simpler than grouping unrelated explicit properties in some store.\nIn this case, ideally, don‚Äôt write a store interface and implementation.\nSometimes the store is needed. Well in that case, make it expose generic accesses and declare your actual properties in your Service. After all, each preference property is part of your domain and the best place to expose it is inside the Service responsible for its feature.\nOpportunistic ad: for iOS I engage you to try my neat reactive PDefaults property wrapper üòÅ\n6. Split your Model You can read many advices about files and function lengths, and you should absolutely apply them to your Services. Your Model should evolve as the implementation clarifies the technical constraints. The business layer is the layer where you shouldn‚Äôt make compromises and let technical debt settle. As soon as a Service is too big or its responsibility seems a bit fuzzy, take a step back and draw a variation of your Model. It should often lead to splitting a Service, but sometimes you can also centralize in a new Service responsibility dispatched in multiple others.\nStill remember: don‚Äôt atomize your Model!\n7. Services naming Name interfaces, not implementations. Don‚Äôt implement a Service named MyService and name its interface MyServiceItf. Because the default representation of your Service across the app should be its interface (and you should try to write it first!). If you don‚Äôt have any clever name for your implementation, then just use a suffix: MyServiceImpl.\nThere are many advices around the importance of naming worth reading. A great advice is to avoid generic suffixes like Manager. Indeed it can lead to classes like BookManager whose responsibility is to manage everything about books, and that‚Äôs clearly a bad scope definition. So we should find the right words to describe this class‚Äôs responsibility. BookOrderValidator, BookLendingMonitor‚Ä¶\nBut thinking about newcomers, flagging your interfaces with their nature as a suffix has value as it increases architecture‚Äôs readability. So here‚Äôs my unpopular opinion: enforce your classes (or interfaces) nature readability at least by using Service suffixes. The layers of the architecture and its shape will be quicker to grasp.\nAlso, if your Model is not well defined at some time (because specs are fuzzy, as it happens like always), allow yourself to temporarily have vague responsibility services. BookService is ok as long as you take care of splitting it to properly scoped Services as it grows. And if it doesn‚Äôt grow or evolve enough to be worth splitting, then no big deal. It‚Äôs readable and takes care of everything related to books: that‚Äôs a good enough name and Model!\n8. Untested proposal: name Services that are exposed to UI differently I know I wrote the opposite earlier (don‚Äôt split the Model into multiple layers). But identifying by name Services that UI devs are supposed to use or not may prove itself useful. Indeed, even if they don‚Äôt bypass the golden rule and use repositories directly, I already saw confusion between well defined Services. This happens because developers that focus mainly on the UI just don‚Äôt know the Model on their fingertips, and we shouldn‚Äôt expect them to do so.\nI think this distinction could also bring some overall clarity. I would suggest to name ‚ÄúUX Services‚Äù using the UXServicesuffix, simply keeping Service suffix for ‚ÄúBusiness Only Services‚Äù.\nVIII. Conclusion As you saw, above are pretty general considerations and no sample code. I still have doubts about the very wide ambition of this article. But in the end, everything I wanted to write down is. And I skipped many crucial topics that are directly related: Dependencies Injection, Testing (UTs, UI Tests, previews), Declarative UI practices‚Ä¶ This would have been too much for sure.\nI hope some of you will reach this conclusion and benefit from what I wrote.\nAnd as always, I‚Äôm eager for your comments and critics, being them mean or off the point.\nDo not hesitate!\n","description":"","tags":["iOS","Android","Architecture","Swift","Kotlin"],"title":"Pragmatic Mobile Architecture","uri":"/posts/pragmatic-mobile-architecture/"},{"categories":null,"content":"","description":"","tags":null,"title":"Swift","uri":"/tags/swift/"},{"categories":null,"content":"","description":"","tags":null,"title":"Tags","uri":"/tags/"},{"categories":null,"content":"","description":"","tags":null,"title":"AI","uri":"/tags/ai/"},{"categories":null,"content":"","description":"","tags":null,"title":"C++","uri":"/tags/c-/"},{"categories":null,"content":"","description":"","tags":null,"title":"Deep Learning","uri":"/tags/deep-learning/"},{"categories":null,"content":"","description":"","tags":null,"title":"Game Theory","uri":"/tags/game-theory/"},{"categories":null,"content":"","description":"","tags":null,"title":"Game Theory","uri":"/categories/game-theory/"},{"categories":null,"content":"","description":"","tags":null,"title":"ICM","uri":"/tags/icm/"},{"categories":null,"content":"","description":"","tags":null,"title":"ML","uri":"/tags/ml/"},{"categories":null,"content":"","description":"","tags":null,"title":"Monte Carlo","uri":"/tags/monte-carlo/"},{"categories":null,"content":"","description":"","tags":null,"title":"MTT","uri":"/tags/mtt/"},{"categories":null,"content":"","description":"","tags":null,"title":"Poker","uri":"/tags/poker/"},{"categories":["Game Theory"],"content":"Un micro-post pour vous indiquer que le code C++ de calcul d‚ÄôICM est disponible sur mon Github sous licence CC NC SA (pas d‚Äôutilisation commerciale et propagation de la license obligatoire).\n","description":"Nouvelles cassantes","tags":["Poker","AI","ICM","MTT","Game Theory","ML","Deep Learning","Monte Carlo","C++"],"title":"Poker : MTT et ICM #4.1 - Publication du code C++","uri":"/posts/poker_mtt_icm_cpp_code/"},{"categories":["Game Theory"],"content":"Rappelons-nous une des conclusion du dernier √©pisode :\n(‚Ä¶) le calcul prend 27ms pour une moyenne sur 15500 √©chantillons. C‚Äôest tr√®s raisonnable en soi, mais si j‚Äôenvisage de simuler quelques milliers de tournois comportant des milliers de mains elles-m√™mes incluant plusieurs calculs d‚ÄôICM, ce ne sera pas suffisant. Damned.\nDu coup¬©‚Ñ¢ peut-on obtenir des valeurs tout aussi satisfaisantes mais beaucoup plus rapidement ?\nPour ceux qui nous rejoignent seulement, je vous conseille de parcourir les articles pr√©c√©dents :\n#1 : La probl√©matique expos√©e sur les fonctions d‚Äô√©valuation en tournoi de poker #2 : L‚Äôimpl√©mentation d‚Äôun calcul exact de l‚ÄôICM #3 : Un calcul pour un plus grand nombre de joeurs par la m√©thode de Monte-Carlo Neural-Networks‚ÄîDeep‚ÄîMachine-Learning-Artificial-Intelligence-MotherF****r Quelques d√©finitions au doigt mouill√© :\nle machine learning c‚Äôest l‚Äôapproche pour laquelle la machine n‚Äôa pas √©t√© programm√©e pour r√©soudre un probl√®me explicitement (ce n‚Äôest donc pas une heuristique). Elle apprend √† le r√©soudre. les r√©seaux de neurones sont une technique antique (ils datent de 1943) qui convient particuli√®rement bien au machine learning. On n‚Äôa juste pas pu les exploiter pleinement jusqu‚Äô√† r√©cemment, lorsque les machines ont commencer √† envoyer suffisamment de p√¢t√© (le fameux point P√¢t√© H√©naff pour nos amis franglophones). Une minute de silence pour cette vanne, merci.\nles r√©seaux de neurones ont une couche de neurones d‚Äôentr√©e qui acceptent un signal (des donn√©es) et une couche de neurones de sortie qui donne un r√©sultat associ√© √† ce signal. Entre les deux, on peut avoir plusieurs autres couches de neurones, auquel cas le r√©seau devient profond. Et on commence √† parler de deep learning. Ce que permet le deep learning c‚Äôest surtout d‚Äôextraire des caract√©ristiques des donn√©es d‚Äôentr√©e brutes gr√¢ce au seul bourrinage d‚Äôun nombre gigantesque de donn√©es, au lieu d‚Äôessayer de traiter les donn√©es en amont pour les rendres assimilables par un r√©seau de neurones plus modeste, et ce n‚Äôest pas rien. Tout ceci est une sous-partie du domaine de l‚Äôintelligence artificielle qui consiste √† coder disons‚Ä¶ des trucs un peu compliqu√©s. Ici on se fiche un peu de ces distinctions, on va utiliser un r√©seau de neurones pour faire un calcul qui comprend des additions et des multiplications, et non pas des trucs r√©volutionnaires qui changent la soci√©t√© comme faire chanter nos dictateurs favoris.\nObjectif et param√®tres Depuis la derni√®re fois, on sait g√©n√©rer des valeurs d‚ÄôICM pour une cinquantaine de joueurs avec une pr√©cision et une probabilit√© abitraires. Cependant s‚Äôassurer de cette pr√©cision probable a un co√ªt. Comme je le proposais pr√©c√©demment, on peut simplement observer le nombre de tirages n√©cessaires pour l‚Äôatteindre sur pas mal de cas, prendre le maximum, et on ne sera pas bien loin de la garantie initiale pour des valeurs similaires.\nOn peut donc se d√©douaner des checks co√ªteux de convergence, mais ce qu‚Äôon voudrait vraiment pour le solstice c‚Äôest un temps de calcul bien plus faible. Genre maximum une milliseconde.\nAlors pour √ßa on va fixer quelques param√®tres, parce que si je m‚Äôint√©resse √† 10, 50 ou 1000 joueurs c‚Äôest pas le m√™me topo. De m√™me, si seul le premier du classement est pay√© ou si la distribution des prix est exponentielle, c‚Äôest pas bien pareil. Et enfin si tous les joueurs ont le m√™me stack √ßa diff√®re franchement de la situation o√π on a quelques Bezos et des dizaines d‚Äôultra-pauvres.\nMe, showing off with my monster stack on the final table.\nJe vais rester sur 50 joueurs maximum parce que √ßa repr√©sente quelque chose pour lequel le calcul ICM classique est incapable de finir dans un temps raisonnable, et Monte-Carlo a du mal √† √™tre super rapide mais peut quand m√™me me fournir des valeurs. Pour les prix (le prizepool, les payouts), on va copier sur un tournoi d‚Äôune cinquantaine de joueurs que j‚Äôai trouv√© sur Winamax au pif. Car oui, on va fixer le prizepool, je ne vois pas pourquoi on se mettrait des b√¢tons dans les roues, puisqu‚Äôon va par contre faire varier √† fond la distribution des stacks. L‚Äôid√©e est de correspondre au cas d‚Äôusage pour lequel on fait tourner plein de simulations de tournoi sur une configuration donn√©e : 50 joueurs et prizepool d√©termin√©.\n√âtape #1 : G√©n√©rer les donn√©es Pour entra√Æner mon r√©seau je vais avoir besoin de couples (input, output) = (distribution de stacks, icm). Je sais calculer l‚ÄôICM, j‚Äôai donc juste besoin de listes de stacks vari√©es. Comme je vais avoir du mal √† extraire ces donn√©es de leurs milieux naturels (les plateformes de poker en ligne), je vais les g√©n√©rer en mimant les processus de m√®re Nature, c‚Äôest √† dire en organisant des petits simili-tournois. Ca tombe bien, j‚Äôen aurai besoin plus tard pour √©valuer des concurrents √† l‚ÄôICM !\nLa conception de ces tournois est un large sujet, mais ce qui va compter ici c‚Äôest surtout de g√©n√©rer une vari√©t√© de situations assez grande. J‚Äôai donc pris un petit test avec des joueurs omniscients que j‚Äôai cod√© et dont on va ignorer les d√©fauts pour le moment :\npour chaque main on va tirer un certain nombre de couples de joueurs qui vont s‚Äôaffronter √† chaque affrontement, une √©quit√© va √™tre tir√©e qui va donner la probabilit√© que le premier joueur gagne au showdown (si les joueurs payent les relances des adversaires) les jeu est un simple push/call/fold : le premier joueur peut se coucher et perd sa blinde, ou relancer √† tapis. S‚Äôil relance, le second joueur peut suivre et aller au showdown ou se coucher et perdre sa blinde. les joueurs vont jouer en connaissance de leur √©quit√©. Le second joueur va d‚Äôabord d√©cider s‚Äôil suivra au cas o√π le premier joueur relance, et le premier joueur sachant tout √ßa (son √©quit√© et la future d√©cision du second joueur car il est omniscient), va d√©cider de relancer ou pas. pour estimer les situations futures les joueurs se servent de fonctions d‚ÄôEV qui pourraient √™tre l‚ÄôICM mais seront en l‚Äôoccurence une estimation proportionnelle aux jetons (Chips EV) On fait donc prendre leurs d√©cisions √† tous les couples de joueurs en m√™me temps, puis on r√©soud en faisant les tirages al√©atoires n√©cessaires pour les affrontements et redistribuant les jetons selon les issues de toutes les mains.\nOn va ins√©rer une sonde au niveau de l‚Äô√©valuation d‚ÄôEV pour r√©pertorier toutes les situations qui sont √©valu√©es dans un bon vieux Set[Tuple] histoire de ne pas avoir de doublons, et hop on peut jouer des tournois pour g√©n√©rer des distributions de stacks cr√©dibles.\nAujourd‚Äôhui je ne vous colle pas le code : on est prooches de la fin de cette petite √©pop√©e, et je mettrai simplement mon code √† disposition sur Github une fois que tout sera fini.\n√âtape #2 : Calculer l‚ÄôICM On a jou√© autant de simili-tournois que n√©cessaire pour avoir assez (N) de situations diff√©rentes, et nous allons maintenant calculer l‚ÄôICM de chaque :\nprenons en √©chantillon toutes les situations g√©n√©r√©es par un tournoi suppl√©mentaire observons la convergence des caculs d‚ÄôICM m√©thode Monte-Carlo pour r√©cup√©rer le nombre de tirages n√©cessaires √† une bonne pr√©cision probable pour chaque situation prenons le maximum de ces nombres, ce qui est bien pessimiste pour toutes les N situations g√©n√©r√©es pr√©c√©demment, calculons l‚ÄôICM avec ce nombre de tirages Gr√¢ce √† notre pessimisme, on ne doit pas s‚Äô√©loigner beaucoup (en fr√©quence et en distance) des garanties statistiques de notre √©chantillon et on va prendre le raccourci de consid√©rer qu‚Äôon a les m√™mes garanties.\n√âtape #3 : D√©finition du NN (Neural Network) Comment construit-on un NN ? √Ä t√¢tons. Sisi. Enfin on peut quand m√™me trouver de bons conseils pour orienter ses t√¢tonnements de mani√®re pertinente. √Ä ce sujet et apr√®s avoir bien compris de quoi il retourne, je ne peux que vous conseiller le blog de Jason Brownlee qui couvre √©norm√©ment de cas et de questions que les data scientists se posent en pratique.\nPour le d√©tail, on va normaliser en peu nos donn√©es :\nen input on va consid√©rer uniquement des stacks tri√©s par ordre d√©croissants (on a fait √ßa au moment m√™me de la g√©n√©ration des stacks et avant de calculer l‚ÄôICM) et divis√©s par la somme des stacks en output on va diviser l‚ÄôICM par la somme des payouts (qui est la somme des valeurs d‚ÄôICM) Si vous vous rappelez du calcul de l‚ÄôICM, on est dans des combinaisons de multiplications et de sommes et les couches de neurones denses - chaque neurone est connect√© √† chaque neurone de la couche suivante - se pr√™tent particuli√®rement bien √† ce ce genre de calculs. Apr√®s quelques essais, j‚Äôai trouv√© que cette forme de r√©seau marchait pas mal :\n[Input layer] : nb_players neurons (stacks) | | | | | | | | | | | | | | | | | | | | | | [Hidden layer 1] : 3 * nb_players neurons | | | | | | | | | | | | | | | | | | | | | | [Hidden layer 2] : 3 * nb_players neurons | | | | | | | | | | | | | | | | | | | | | | [Output layer] : nb_players neurons (ICM) On utilise de traditionnelles fonctions d‚Äôactivation relu, une fonction de perte mean_squared_error et un optimizer RMS ce qui correspond bien √† un probl√®me de r√©gression.\n√áa nous donne pour du Keras :\nnn = Sequential() nn.add(Dense(nb_players, activation='relu')) nn.add(Dense(nb_players * 3, activation='relu')) nn.add(Dense(nb_players * 3, activation='relu')) nn.add(Dense(nb_players, activation='relu')) nn.compile( loss='mean_squared_error', optimizer=keras.optimizers.RMSprop(), metrics=[keras.metrics.RootMeanSquaredError()] ) Entrainement et r√©sultats 9k situations d‚Äôentra√Ænement 1k situations de validation 1k situations de test une configuration de tournoi avec 50 joueurs 100 blindes de stack initial les blindes qui sont multipli√©es toutes les 10 mains par 1,3 30% des joueurs qui participent √† chaque main (comme sur une table de 6 joueurs en gros) le prizepool : 4650. 3450. 2325. 1650. 1200. 825. 600 0 0 0 ... donc un buy-in de 294 milliards de dollars (pourquoi pas) une pr√©cision pour les √©valuation ICM en Monte-Carlo de un demi buy-in avec 90% de confiance J‚Äôobtiens un nombre de tirages n√©cessaires pour chaque √©valuation ICM de 3100.\nJe fais tourner mes calculs en multithread pendant une minute environ pour une moyenne de 6ms par √©valuation ICM (mais le multithread n‚Äôest pas facilement r√©alisable au sein d‚Äôun tournoi, on est plut√¥t autour de 15ms en monothread).\nMaintenant que j‚Äôai toutes mes situations et les estimations ICM associ√©es, j‚Äôentra√Æne mon NN pour 10 epochs avec un batch-size de 30 - pour ceux √† qui √ßa parle - ce qui me prend environ 5 secondes.\nUn petit plot pour la convergence du NN :\net sur les tests finaux une RMSE (root means squared error) moyenne de 100.62 (milliards de dollars).\nCe que √ßa veut dire, c‚Äôest qu‚Äôen une minute j‚Äôai entra√Æn√© un r√©seau de neurones dont les erreurs par rapport aux √©valuations de Monte-Carlo sont de l‚Äôordre de la pr√©cision de ces √©valuations. Et √ßa, c‚Äôest d√©j√† pas mal !\nMais l‚Äôobjectif √©tait d‚Äôaller plus vite que les quelques millisecondes de calculs de Monte-Carlo, et √ßa se confirme en effet.\nTemps de calcul d‚Äôune √©valuation ICM en utilisant le mod√®le Keras : 19 microsecondes ! Objectif atteint : on a divis√© par 316 le temps de calcul par rapport √† l‚Äô√©valuation de Monte-Carlo.\nAllez, une derni√®re optimisation pour la route : Keras √©tant utilis√© tant pour l‚Äôentra√Ænement tant que l‚Äô√©valuation, il est possible de d√©graisser un peu tout √ßa en utilisant TensorFlow lite (un bon guide ici). Et dans ce cas, on obtient moins de 10 microsecondes par √©valuation.\nConcluons Je vous ai cach√© quelques technicit√©s, notamment l‚Äôexposition des fonctions de calcul d‚ÄôICM cod√©es en C++ √† du code Python gr√¢ce √† Boost qui fut une aventure d√©plaisante mais relativement efficace. Ceci-dit, voil√†, on peut calculer l‚ÄôICM avec une bonne pr√©cision en quelques micro-secondes moyennant une √©tape pr√©liminaire d‚Äôenviron une minute. On peut augmenter cette pr√©cision ce qui gonflera le temps de pr√©paration, mais si on travaille √† configuration de tournoi fixe et pour un nombre important de tournois, on passera tr√®s certainement √©norm√©ment moins de temps au total.\nLa suite ? On va enfin faire des simulations marrantes avec de l‚ÄôICM et tenter de comprendre quels sont son domaine d‚Äôapplication, ses limites, et si on a le temps on cherchera √† cr√©er de meilleures √©valuations.\nMalgr√© les milliards de mails par secondes que je re√ßois concernant ces exp√©riences, n‚Äôh√©sitez pas √† m‚Äô√©crire pour me dire ce que vous en pensez ou me poser toute question - ou me proposer une mission autour de l‚ÄôIA ;)\n","description":"Jusqu‚Äôau-boutisme de l‚Äôextr√™me qui envoie du p√¢t√©.","tags":["Poker","AI","ICM","MTT","Game Theory","ML","Deep Learning","Monte Carlo"],"title":"Poker : MTT et ICM #4 - Perf Tuning avec du Deep Learning","uri":"/posts/poker_mtt_icm_deep_learning/"},{"categories":["Game Theory"],"content":"R√©sum√© des √©pisodes pr√©c√©dents:\nEn th√©orie des jeux, les fonctions d‚Äô√©valuation permettent d‚Äô√©valuer des situations, de les comparer, et donc de faire des choix renseign√©s l‚ÄôIndependent Chip Model (ICM) est la fonction d‚Äô√©valuation de r√©f√©rence pour les tournois de poker, et on cherche √† trouver mieux, notamment pour un grand nombre de joueurs l‚ÄôICM est long √† calculer pour un grand nombre de joueurs. Apr√®s pas mal d‚Äôoptimisations, on a des temps humainement raisonnables pour une vingtaine de joueurs pay√©s maximum. Si on veut utiliser l‚ÄôICM de mani√®re intensive comme dans une simulation de tournoi, il faudra viser plut√¥t autour de dix joueurs pay√©s. Du coup¬©‚Ñ¢ peut-on obtenir des valeurs correctes pour un plus grand nombre de joueurs ?\nMonte-Carlo : le t√¢tonnement convergent Une m√©thode commune d‚Äôapproximation de valeur est la m√©thode de Monte-Carlo (MC). On va √©valuer diff√©rents points d‚Äôune fonction complexe choisis al√©atoirement pour d√©duire une approximation probabiliste de sa moyenne. En l‚Äôoccurence pour l‚ÄôICM on peut typiquement essayer de tirer al√©atoirement le classement des joueurs selon les hypoth√®ses de l‚ÄôICM ce qui n‚Äôest somme-toute pas √©vident.\nNa√Øvement on devrait tirer le premier joueur class√© selon une probabilit√© proportionnelle √† son stack, puis le second parmi les joueurs restants et les stacks restants et ainsi de suite. Autant vous dire qu‚Äôon ne va pas bien loin avec √ßa car la complexit√© est alors assez violente : pour chaque tirage on doit calculer la distribution de probabilit√© et effectuer un tirage, ce qui au minimum va nous mener sur du O(n2) pour un tirage, et il en faut pas mal.\nHeureusement des gens ont r√©fl√©chi, et notamment le d√©veloppeur d‚ÄôIA Tysen Streib qui a beaucoup contribu√© √† l‚Äôanalyse strat√©gique au poker (il a co-√©crit Kill everyone notamment). Il a donc tr√®s justement analys√© en 2011 qu‚Äôil √©tait possible d‚Äôeffectuer un tirage de la sorte en tirant al√©atoirement la dur√©e de vie de chaque joueur selon uniform_random[O:1]1/stack, puis en ordonnant les dur√©es de vie pour obtenir l‚Äôordre de classement des joueurs.\nJe vous recommande fortement la lecture de son post original ici et du thread qui suit, o√π l‚Äôalgorithme tant que les raisons de la convergence sont bien expliqu√©s, √† un niveau intuitif, avec une interpr√©tation th√©orique et m√™me des optimisations.\nImpl√©mentation Les gros points de consommation de CPU sont :\nle tirage al√©atoire le calcul de puissance le tri Comme sugg√©r√© dans le fil du post, on obtient de meilleures performance en utilisant le logarithme de la formule de tirage, log est strictement croissant donc l‚Äôordre reste le m√™me.\nPour le tirage al√©atoire, on a besoin d‚Äôun al√©atoire statistique correct mais sans qualit√© cryptographique particuli√®re. On gagne pas mal en utilisant SFMT, une variante de l‚Äôalgorithme de Mersenne-Twister plus rapide sur les microprocesseurs modernes.\nEnfin pour le tri il faut noter que selon la distribution des prix, on peut √©ventuellement chercher √† classer les premiers joueurs pour les places ayant un prix non-nul. Ce n‚Äôest pas une optimisation syst√©matique mais lorsqu‚Äôelle est pertinente il serait dommage de l‚Äôignorer.\nVoici une version directe, sans autre optimisation.\n#include \"monte-carlo-icm.hpp\" #include \u003crandom\u003e #include \u003cunordered_map\u003e #include \u003csfmt.hpp\u003e /** * Compute a permutation according to the sorting of random values put to the power of given weights. * In fact, logarithm is used for performance, and logarithm tables could certainly be used to fasten the * computation. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param dist random distribution * @param mt SFMT (fast Mersenne-Twister algorithm) */ void monteCarloPermutation(const double *weights, int *destination, const int size, uniform_real_distribution\u003cdouble\u003e \u0026dist, wtl::sfmt19937 \u0026mt) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(dist(mt)) * weights[i]; destination[i] = i; } sort(destination, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); } ); } /** * Same as `monteCarloPermutation` except the sorting process stops for performance * after the first values are sorted. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param nbRelevant number of top values that should be strictly sorted. The other ones may not be sorted * according to the random draw. * @param dist random distribution * @param mt SFMT (fast Mersenne-Twister algorithm) */ void monteCarloPermutationPartial(const double *weights, int *destination, const int size, const int nbRelevant, uniform_real_distribution\u003cdouble\u003e \u0026dist, wtl::sfmt19937 \u0026mt) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(dist(mt)) * weights[i]; destination[i] = i; } partial_sort(destination, destination + nbRelevant, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); } ); } int firstZeroPayout(vector\u003cdouble\u003e payouts) { const int size = payouts.size(); int firstZeroPayout = -1; for (int i = 0; i \u003c size; ++i) { if (firstZeroPayout \u003c 0) { if (payouts[i] == 0) { firstZeroPayout = i; } } else if (payouts[i] != 0) { firstZeroPayout = -1; } } return firstZeroPayout; } /** * Monte-Carlo ICM Ranking algorithm. * * @param stacks * @param payouts * @param trials * @param relevantRanksCount * @param results array of ICM EV */ void monteCarloIcm(const double *stacks, const double *payouts, const int nbPlayers, const long trials, const int relevantRanksCount, double *results) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/ // Initialize random distribution // https://stackoverflow.com/questions/19665818/generate-random-numbers-using-c11-random-library // SFMT variant random_device rd; wtl::sfmt19937 mt(rd()); uniform_real_distribution\u003cdouble\u003e dist(0, 1); int permutation[nbPlayers]; const double stacksAvg = accumulate(stacks, stacks + nbPlayers, 0.) / (double) nbPlayers; double weights[nbPlayers]; double contrib[nbPlayers]; // - Normalize stacks (not really necessary but cheap) and invert to weights // - Prepare each trial ranking contribution to the total for (int i = 0; i \u003c nbPlayers; i++) { weights[i] = stacksAvg / stacks[i]; contrib[i] = payouts[i] / trials; } // Partial sort vs sort : interesting only if we have many zero payouts at the end const float partialSortThreshold = 0.2; // Magic number \u003c3 const bool partialSort = relevantRanksCount \u003e= 1 \u0026\u0026 ((float) relevantRanksCount / (float) nbPlayers \u003c= partialSortThreshold); for (long i = 0; i \u003c trials; i++) { // Draw a permutation if (partialSort) { monteCarloPermutationPartial(weights, permutation, nbPlayers, relevantRanksCount, dist, mt); } else { monteCarloPermutation(weights, permutation, nbPlayers, dist, mt); } // Cumulate payouts according to the random permutation for (int j = 0; j \u003c nbPlayers; j++) { results[permutation[j]] += contrib[j]; } } } /** * Vector wrapper of MC ICM * @param stacks * @param payouts * @param trials * @return ICM EV */ vector\u003cdouble\u003e monteCarloIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts, const long trials) { const int nbPlayers = stacks.size(); const int relevantRanksCount = firstZeroPayout(payouts); vector\u003cdouble\u003e results(nbPlayers); double stacksArray[nbPlayers]; double payoutsArray[nbPlayers]; double resultsArray[nbPlayers]; for (int i = 0; i \u003c nbPlayers; ++i) { stacksArray[i] = stacks[i]; payoutsArray[i] = payouts[i]; resultsArray[i] = 0; } monteCarloIcm(stacksArray, payoutsArray, nbPlayers, trials, relevantRanksCount, resultsArray); for (int i = 0; i \u003c nbPlayers; i++) { results[i] = resultsArray[i]; } return results; } Autres pistes d‚Äôoptimisation Voici quelques optimisations que j‚Äôimagine pertinentes :\nl‚Äô√©chantillonnage pr√©f√©rentiel : plus d‚Äô√©chantillons pour les cas les plus probables. On pourrait par exemple fixer successivement chaque joueur premier du classement, et estimer ce cas avec plus ou moins de pr√©cision par exemple avec un nombre d‚Äô√©chantillon proportionnel √† sa probabilit√© au carr√© (la contribution de chaque cas restant proportionnelle au stack du joueur bien s√ªr). Pourquoi pas aller un ou plusieurs crans plus loin en envisageant toutes les combinaisons des k premiers joueurs. le quasi-Monte-Carlo, une r√©partition plus homog√®ne peut apporter une convergence plus rapide pour le tri et pour les tr√®s grands nombre de joueurs, comme les payouts sont souvent par palliers, utiliser quand c‚Äôest pertinent une succession de tris partiels par palier (plus pr√©cis√©ment des algorithmes de s√©lection). Si vous explorez ces optimisations (ou d‚Äôautres), faites-m‚Äôen part, je suis curieux !\nConvergence On sait qu‚Äôon a une convergence en O(1/sqrt(n)) (note : ajouter une extension LateX √† mon site builder). Mais √ßa ne nous dit pas quand il faut arr√™ter l‚Äô√©chantillonnage ! Par le pass√© j‚Äôutilisais de petits algos observant la variation sur des lots de puissances de deux d‚Äô√©chantillons, ce qui n‚Äôest pas fiable : on peut avoir une convergence tr√®s lente, et un fort ralentissement ne permet pas de conclure en une pr√©cision donn√©e. ‚ÄúEn pratique, √ßa marche‚Äù oui, enfin peut-√™tre, mais ce n‚Äôest pas forc√©ment beaucoup plus dur d‚Äôimpl√©menter des garanties statistiques s√ªres.\nApr√®s quelques recherches j‚Äôai trouv√© une m√©thode assez g√©n√©rique dans ce (vieux) papier1. Le calcul se base sur un plafond en dessous duquel la variance d‚Äôun √©chantillon satisfait une garantie statistique : avec une probabilit√© Œ±, la moyenne de l‚Äô√©chantillon est dans l‚Äôintervalle de confiance de taille d autour de la moyenne √† la limite.\nJ‚Äôai donc r√©organis√© un peu mon code pour l‚Äôimpl√©menter. Le co√ªt du calcul √©tant assez √©lev√©, il convient de ne pas l‚Äôappliquer √† chaque √©tape de l‚Äô√©chantillonage, mais plut√¥t r√©guli√®rement, tous les 100 √©chantillons par exemple. De plus, j‚Äôai extrait les d√©finitions du RNG (pour un futur quasi-Monte-Carlo) et du tri (pour un futur tri partiel par palliers) histoire de pouvoir plus facilement impl√©menter d‚Äôautres versions de l‚Äôalgorithme - voir le code en fin d‚Äôarticle.\nUn point important √† consid√©rer est que la variance d‚Äôun calcul d‚ÄôICM par la m√©thode de Monte-Carlo d√©pend fortement de la distribution des stacks des joueurs et de celle des prix. En effet, pour prendre un extr√™me, si tous les prix sont √©gaux la variance est simplement nulle. On va √©videmment souhaiter √©viter le co√ªt de calcul de cette stopping rule si on en op√®re en nombre, mais il faudra √™tre prudent pour garder des garanties correctes. De plus, la taille d de l‚Äôintervalle de confiance est li√©e lin√©airement aux prix. Si on distribue deux fois plus de prix aux joueurs, pour une m√™me pr√©cision relative on devra multiplier d par deux. L‚Äôid√©al est alors d‚Äôexprimer d en fonction d‚Äôune grandeur pertinente comme la somme des prix distribu√©s et d‚Äôen tenir compte lors du traitement d‚Äô√©chantillons vari√©s pour au moins conna√Ætre la pr√©cision des r√©sultats calcul√©s.\nSi les √©chantillons sont assez homog√®nes, on pourra par exemple faire une petite tambouille comme calculer le nombre d‚Äôit√©rations n√©cessaires sur un petit ensemble de situations extraites du paquet √† traiter, prendre le maximum et le multiplier par deux pour traiter tout le paquet (√† vue de nez, ‚Äúen pratique, √ßa marche‚Äù).\nPerformance Je me suis int√©ress√© au cas de 50 joueurs, les 40 premiers √©tant pay√©s. Pour construire la structure de prix, j‚Äôai notamment lu cette pr√©sentation qui m‚Äôa encourag√© √† utiliser une power law fall-off (une chute de loi de puissance..?) telle que le joueur au rang i obtienne un prix proportionnel √† 1 / pow(i, a). J‚Äôai n√©glig√© les √©tapes d‚Äôhumanisation car je suspecte qu‚Äôau mieux elles font baisser la variance en cr√©ant des plateaux. Soyons-donc joyeusement pessimistes !\nJ‚Äôai ensuite pris une distribution de stacks al√©atoires selon une loi normale tronqu√©e. Je ne pense pas que c‚Äôest vraiment repr√©sentatif d‚Äôune situation particuli√®re, les distributions de stack sont assez difficiles √† mod√©liser. Enfin pour le moment √ßa suffira, on cherche juste √† conna√Ætre la performance de notre algorithme.\nDans ces circonstances, l‚Äô√©valuation de la stopping rule pour une probabilit√© de 0.9 avec un intervalle de confiance de taille 1 (sachant que la somme des prix vaut 1000) me donne de mani√®re assez stable une taille d‚Äô√©chantillon de 15500.\nEt une fois d√©barrass√©s de cette √©valuation, le calcul prend 27ms pour une moyenne sur 15500 √©chantillons. C‚Äôest tr√®s raisonnable en soi, mais si j‚Äôenvisage de simuler quelques milliers de tournois comportant des milliers de mains elles-m√™mes incluant plusieurs calculs d‚ÄôICM, ce ne sera pas suffisant. Damned.\nMais j‚Äôai une id√©e un peu taquine pour r√©soudre √ßa‚Ä¶\nNext step Tout √ßa pour‚Ä¶ pour quoi d√©j√† ? Pour d√©fier l‚ÄôICM, parce qu‚Äôon se demande s‚Äôil n‚Äôy a pas mieux, et sinon pour se convaincre que c‚Äôest une bonne approximation.\nJe pense qu‚Äôon pourrait d√©j√† aller vers des simulations int√©ressantes avec un nombre r√©duit de joueurs pour mettre en √©vidence certains comportements. Mais je suis sur une bonne lanc√©e, on va pas s‚Äôarr√™ter en si bon chemin !\nCe sera donc pour mon prochain article, en attendant n‚Äôh√©sitez pas √† me contacter pour toute critique ou discussion via mon email en pied de page !\nBonus : le code Tout d‚Äôabord on a besoin d‚Äôune fonction qui n‚Äôexiste pas dans les biblioth√®ques standard : norminv qui permet de d√©terminer pour quelle abscisse on obtient √† gauche une certaine fraction de la population d‚Äôune distribution normale unitaire centr√©e en 0.\nUn certain John D. Cook l‚Äôa fait pour nous, on va donc utiliser son code.\nutil/math.cpp\nCollez le code de cette page https://www.johndcook.com/blog/cpp_phi_inverse/\nutil/math.hpp\n#ifndef MTT_EXPERIMENTS_C_MATH_HPP #define MTT_EXPERIMENTS_C_MATH_HPP double NormalCDFInverse(double p); #endif //MTT_EXPERIMENTS_C_MATH_HPP monte-carlo-icm.cpp\n#include \"monte-carlo-icm.hpp\" #include \u003crandom\u003e #include \u003csfmt.hpp\u003e #include \u003cutil/math.hpp\u003e using namespace std; namespace icm { /** * The Random Number Generator type : functions denoted by this alias are expected to draw doubles between 0 and 1. * Abstracted in order to plug a proper RNG for quasi-Monte-Carlo in the future. */ using RNG = std::function\u003cdouble()\u003e; /** * The sorter functions are expected to sort the indexes of the draw array in reverse order according to the values * of the array. */ using Sorter = std::function\u003cvoid(double *draw, int *destination, int size)\u003e; /** * Private section */ namespace { /** * Compute a permutation according to the sorting of random values put to the power of given weights. * In fact, logarithm is used for performance, and logarithm tables could certainly be used to fasten the * computation. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param rng random number generator * @param sorter function to sort the permutation */ void monteCarloPermutation(const double *weights, int *destination, const int size, const RNG \u0026rng, const Sorter \u0026sorter) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(rng()) * weights[i]; destination[i] = i; } sorter(draw, destination, size); } /** * Get the index of the first zero payout after which all payouts are zero as well * @param payouts the payouts array * @param size the size of the array * @return the index of the first zero payout */ int firstZeroPayout(const double *payouts, int size) { int firstZeroPayout = -1; for (int i = 0; i \u003c size; ++i) { if (firstZeroPayout \u003c 0) { if (payouts[i] == 0) { firstZeroPayout = i; } } else if (payouts[i] != 0) { firstZeroPayout = -1; } } return firstZeroPayout; } /** * Compute the mean of a batch of samples * @param samples the samples * @param nbPlayers the size of each sample aka the number of players * @return a vector containing the mean of the samples */ vector\u003cdouble\u003e mean(vector\u003cdouble *\u003e samples, const int nbPlayers) { const long long nbSamples = samples.size(); vector\u003cdouble\u003e result(nbPlayers, 0); for (int i = 0; i \u003c nbSamples; i++) { double *sample = samples[i]; for (int j = 0; j \u003c nbPlayers; ++j) { result[j] += sample[j]; } } for (int i = 0; i \u003c nbPlayers; ++i) { result[i] /= (double) nbSamples; } return result; } /** * Compute the variance of samples * @param samples the samples * @param nbPlayers the size of each sample aka the number of players * @return the variance */ double variance(vector\u003cdouble *\u003e samples, const int nbPlayers) { const long long nbSamples = samples.size(); vector\u003cdouble\u003e meanSample = mean(samples, nbPlayers); double result = 0; for (int i = 0; i \u003c nbSamples; i++) { double *sample = samples[i]; for (int j = 0; j \u003c nbPlayers; ++j) { double diff = sample[j] - meanSample[j]; result += diff * diff; } } // Not sure about nbSamples - 1, should be nbSamples but the paper about the stopping rule states n-1... return result / (double) (nbSamples - 1); } /** * Compute the threshold for the variance under which the stopping limit is considered reached * @param alphaProbability confidence probability * @param confidenceIntervalLength confidence interval length (root mean square) * @param nbSamples number of samples * @return the variance threshold */ double stoppingRuleLimit(double alphaProbability, double confidenceIntervalLength, long long nbSamples) { double zAlpha = NormalCDFInverse(alphaProbability + (1 - alphaProbability) / 2); // Symmetrical distribution return (double)nbSamples * confidenceIntervalLength * confidenceIntervalLength / zAlpha; } /** * Pick the appropriate sorter depending on payouts. We can use a partial sort if most of the payouts are zero * @param payouts the payouts * @param nbPlayers the size of the payouts array aka the number of players * @return a sorter */ Sorter chooseSorter(const double *payouts, int nbPlayers) { // Partial sort vs sort : interesting only if we have many zero payouts at the end const int relevantRanksCount = firstZeroPayout(payouts, nbPlayers); const float partialSortThreshold = 0.2; // Magic number \u003c3 const bool partialSort = (float) relevantRanksCount / (float) nbPlayers \u003c= partialSortThreshold; if (partialSort) { return [=](const double *draw, int *destination, int size) { partial_sort(destination, destination + relevantRanksCount, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); } ); }; } return [](const double *draw, int *destination, int size) { sort(destination, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order return (draw[a] \u003e draw[b]); }); }; } /** * Create a RNG instance (using SFMT) * @return a RNG instance */ RNG defaultRng() { // Initialize random distribution // https://stackoverflow.com/questions/19665818/generate-random-numbers-using-c11-random-library // SFMT variant random_device rd; wtl::sfmt19937 mt(rd()); shared_ptr\u003cwtl::sfmt19937\u003e mtPtr = std::make_shared\u003cwtl::sfmt19937\u003e(mt); uniform_real_distribution\u003cdouble\u003e dist(0, 1); return [mtPtr = make_shared\u003cwtl::sfmt19937\u003e(mt), distPtr = make_shared\u003cuniform_real_distribution\u003cdouble\u003e\u003e(dist)]() -\u003e double { return (*distPtr)((*mtPtr)); }; } /** * Check if we can stop the trials according to the confidence probability and interval * @param alphaProbability the confidence probability * @param confidenceIntervalLength confidence interval length (root mean square) * @param samples the samples * @param nbPlayers the number of players * @return true if the stopping rule criteria are met */ bool canStop(const double alphaProbability, const double confidenceIntervalLength, const vector\u003cdouble *\u003e \u0026samples, const int nbPlayers) { const long long nbSamples = samples.size(); if (nbSamples \u003c 2) { return false; } double limit = stoppingRuleLimit(alphaProbability, confidenceIntervalLength, nbSamples); return variance(samples, nbPlayers) \u003c= limit; } /** * Normalize stacks (not really necessary but cheap) and invert to weights * @param stacks the stacks * @param nbPlayers the number of players * @param weights the destination array */ void fillWeights(const double *stacks, int nbPlayers, double *weights) { const double stacksAvg = accumulate(stacks, stacks + nbPlayers, 0.) / (double) nbPlayers; for (int i = 0; i \u003c nbPlayers; i++) { weights[i] = stacksAvg / stacks[i]; } } } /** * Perform one MC trial * * @param results destination array to add trial contribution into * @param payouts the contribution to add to the results per rank * @param weights something proportional to the inverse of the stacks of the players * @param permutation an array that will be used to store the permutation (permutation[i] = player that reaches rank i) * @param nbPlayers the number of players * @param rng random number generator * @param sorter function to sort the permutation */ void monteCarloIcmTrial(double *results, const double *payouts, double *weights, int *permutation, int nbPlayers, const RNG \u0026rng, const Sorter \u0026sorter) { monteCarloPermutation(weights, permutation, nbPlayers, rng, sorter); // Cumulate payouts according to the random permutation for (int j = 0; j \u003c nbPlayers; j++) { results[permutation[j]] += payouts[j]; } } /** * Monte-Carlo ICM Ranking algorithm. * * @param stacks the stacks * @param payouts the payouts * @param nbPlayers the number of players * @param trials the number of trials to perform * @param results destination array for ICM EV */ void monteCarloIcm(const double *stacks, const double *payouts, const int nbPlayers, const long long trials, double *results) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/ RNG rng = defaultRng(); int permutation[nbPlayers]; double weights[nbPlayers]; fillWeights(stacks, nbPlayers, weights); double contrib[nbPlayers]; // Prepare each trial ranking contribution to the total for (int i = 0; i \u003c nbPlayers; i++) { contrib[i] = payouts[i] / (double) trials; } const Sorter sorter = chooseSorter(payouts, nbPlayers); for (long i = 0; i \u003c trials; i++) { monteCarloIcmTrial(results, contrib, weights, permutation, nbPlayers, rng, sorter); } } /** * Monte-Carlo ICM Ranking algorithm with stopping rule. * * @param stacks the stacks * @param payouts the payouts * @param nbPlayers the number of players * @param results destination array for ICM EV * @param stoppingAlphaProbability the confidence probability * @param stoppingConfidenceIntervalLength confidence interval length (root mean square) * @param stoppingEvalLag the number of trials that are performed before each evaluation of the stopping rule */ long long monteCarloIcmWithStoppingRule(const double *stacks, const double *payouts, const int nbPlayers, double *results, const double stoppingAlphaProbability, const double stoppingConfidenceIntervalLength, long long stoppingEvalLag) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/ // Stopping rule : http://www.lib.ncsu.edu/resolver/1840.4/5244 (first method for independent samples) RNG rng = defaultRng(); int permutation[nbPlayers]; double weights[nbPlayers]; fillWeights(stacks, nbPlayers, weights); // For each trial we'll contribute the real payouts because we want to use them for the stopping rule // computation const Sorter sorter = chooseSorter(payouts, nbPlayers); vector\u003cdouble *\u003e samples; vector\u003cdouble *\u003e allocated; long long count = 0; while (true) { // While we don't stop according to the stopping rule, we create a batch of samples auto *memory = (double *) calloc(nbPlayers * stoppingEvalLag, sizeof(double)); // Store the allocated memory area pointer allocated.push_back(memory); for (long i = 0; i \u003c stoppingEvalLag; i++) { double *sampleMemory = memory + i * nbPlayers; monteCarloIcmTrial(sampleMemory, const_cast\u003cdouble *\u003e(payouts), weights, permutation, nbPlayers, rng, sorter); // Store the pointer to the sample samples.push_back(sampleMemory); } count += stoppingEvalLag; // Break if the stopping rule says it's enough if (canStop(stoppingAlphaProbability, stoppingConfidenceIntervalLength, samples, nbPlayers)) { break; } } // Sum the samples for (double *sample : samples) { for (int i = 0; i \u003c nbPlayers; i++) { results[i] += sample[i]; } } // Divide the sum to get the mean for (int i = 0; i \u003c nbPlayers; i++) { results[i] /= (double) count; } // Free the allocated memory areas for (double *memory : allocated) { free(memory); } // Return the number of samples that were generated return count; } } monte-carlo-icm.hpp D√©clarez les fonctions qu‚Äôil vous int√©resse d‚Äôexposer !\nA Brief Survey of Stopping Rules in Monte Carlo Simulations, 1968, Gilman - https://repository.lib.ncsu.edu/handle/1840.4/5244¬†‚Ü©Ô∏é\n","description":"Un Monaco-Picon s‚Äôil vous pla√Æt. En pinte.","tags":["Poker","AI","ICM","MTT","Game Theory","Monte Carlo"],"title":"Poker : MTT et ICM #3 - M√©thode de Monte-Carlo","uri":"/posts/poker_mtt_icm_monte_carlo/"},{"categories":["Game Theory"],"content":"Dans mon pr√©c√©dent billet, je vous parlais des fonctions d‚Äô√©valuation en th√©orie des jeux, plus particuli√®rement dans les tournois de poker No-Limit Hold‚ÄôEm (NLHE), et sp√©cifiquement de l‚ÄôIndependent Chip Model (ICM).\nPour rappel une fonction d‚Äô√©valuation donne une estimation probabiliste des gains de chaque joueur en fonction de l‚Äô√©tat du jeu. L‚ÄôICM utilise la taille des stacks des joueurs pour √©valuer leurs chances d‚Äôatteindre chaque rang dans le classement final du tournoi. Ces probabilit√©s multipli√©es par les prix de chaque rangs donnent une esp√©rance de gain en monnaie sonnante et tr√©buchante qui permettra aux joueurs de prendre des d√©cisions selon les issues possibles de ses actions.\nCalcul de l‚ÄôICM L‚ÄôICM suppose que la probabilit√© pour chaque joueur d‚Äôacc√©der √† la premi√®re place est √©gale √† la proportion repr√©sent√©e par son stack sur la totalit√© des jetons en jeu (la somme des stacks). R√©cursivement la probabilit√© pour un joueur A d‚Äôacc√©der √† la seconde place va √™tre une somme pour chaque autre joueur B en premi√®re place.\nSA = stack du joueur A SB = stack du joueur B P2A = probabilit√© du joueur A d'acc√©der √† la seconde place, initialis√© √† 0 Pour chaque autre joueur B: P1B = probabilit√© du joueur B d'√™tre premier = SB / Somme des stacks P2A_sachant_1B = probabilit√© du joueur consid√©r√© d'acc√©der √† la seconde place quand le joueur B acc√®de √† la premi√®re place P2A_sachant_1B = SA / (Somme des stacks - SB) P2A = P2A + P1B x P2A_sachant_1B Pour calculer le tableau de valeurs de l‚ÄôICM en fonction des stacks et des prix (payouts) on pourrait √©crire un algorithme de ce type :\npayouts = [Q1, Q2, Q3, ...] : prix pour la premi√®re, deuxi√®me, troisi√®me.. place. r√©sultat = [RA, RB, RC, ...] : tableau des r√©sultats, avec chaque valeur initialis√©e √† 0 pour tout classement possible des joueurs : (prenons le classement (A, B, C...) pour l'exemple) p = probabilit√© de ce classement = P1A x P2B_sachant_1A x P3C_sachant_1A_et_2B x ... RA = RA + p x Q1 RB = RB + p x Q2 RC = RC + p x Q3 ... Voici un bout de code python na√Øf qui fait √ßa :\nfrom itertools import permutations import numpy as np def icm_proba(permutation, stacks: np.ndarray, stacks_sum: int): result = 1 for rank, player in enumerate(permutation): stack = stacks[player] result *= stack / stacks_sum stacks_sum -= stack return result def icm(stacks: np.ndarray, payouts: np.ndarray) -\u003e np.ndarray: if len(stacks) == 0: return np.array([]) nb_stacks = len(stacks) stacks_sum = sum(stacks) result = np.zeros((nb_stacks,)) for permutation in permutations(range(nb_stacks)): probability = icm_proba(permutation, stacks, stacks_sum) for rank, player in enumerate(permutation): result[player] += probability * payouts[rank] return result if __name__ == '__main__': val = icm(np.array([500, 300, 200]), np.array([600, 400, 0])) print(val) Output :\n[435.71428571 330. 234.28571429] On note la finesse du formattage\nComplexit√© Prendre tout classement possible de N joueurs, c‚Äôest ce qu‚Äôon appelle une permutation ou encore un arrangement. Et on calcule tr√®s facilement combien il existe d‚Äôarrangement pour un nombre donn√© de joueurs :\n1 : 1 (ben oui) 2 : 2 x 1 = 2 (jur√© √ßa change apr√®s) 3 : 3 x 2 x 1 = 6 4 : 4 x 3 x 2 x 1 = 24 5 : 5 x 4 x 3 x 2 x 1 = 120 C‚Äôest la factorielle, et on peut voir que √ßa croit tr√®s rapidement (plus vite qu‚Äôune exponentielle). Si on code √ßa comme √ßa on obtient une complexit√© tellement violente qu‚Äôil est difficile de calculer l‚ÄôICM au del√† de 10 joueurs dans un temps raisonnable.\nPar exemple avec le code ci-dessus j‚Äôai obtenu ces temps :\n3.695487976074219e-05 seconds for 2 players 2.8848648071289062e-05 seconds for 3 players 8.177757263183594e-05 seconds for 4 players 0.0006070137023925781 seconds for 5 players 0.0037360191345214844 seconds for 6 players 0.027889013290405273 seconds for 7 players 0.24523401260375977 seconds for 8 players 2.2415449619293213 seconds for 9 players 23.641671180725098 seconds for 10 players Je vous rappelle qu‚Äô√† l‚Äôorigine, je m‚Äôint√©resse √† l‚ÄôICM en tournoi multi-table. C‚Äôest √† dire dans des tournois o√π le nombre de joueur est entre dix et‚Ä¶ quelques milliers.\nDe plus, quand je regarde par exemple sur HoldemRessources, leur calculateur me r√©pond en environ 200ms pour une vingtaine de joueurs. M√™me si ils ont mis un serveur tr√®s performant, on est dans des ordres de grandeur tr√®s lointains. On peut faire beaucoup mieux.\nPremi√®re optimisation : passer en r√©cursif et en C++ Eh oui car le Python n‚Äôest rapide que quand il appelle des biblioth√®ques compil√©es. Faisons-donc la notre ! Et j‚Äôen profite pour faire une version r√©cursive de l‚Äôalgorithme qui va nous √©conomiser pas mal de multiplications pour le calcul de probabilit√©. En effet, on regroupe toutes les permutations pour lesquelles le premier joueur dans le classement est le joueur d‚Äôindex 0 dans les stacks par exemple, mais voyez plut√¥t ci-dessous.\nAu premier appel, la fonction recursiveNaiveIcm va √©num√©rer tous les joueurs possibles en premi√®re place. Pour chacun, elle va s‚Äôappeler elle-m√™me pour la seconde place, etc.\nvoid recursiveNaiveIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts, vector\u003cdouble\u003e \u0026result, vector\u003cbool\u003e \u0026usedPlayers, const int rank, const int size, const double factor, const double stacksSum) { if (rank == size) { // No player to rank left return; } for (int i = 0; i \u003c size; i++) { if (usedPlayers[i]) { continue; } // ith player has already been considered // The probability to have this ith player at this rank knowing the previous ranking is stacks[i] / stacksSum // The total probability of this ranking chain is thus : const double newFactor = factor * stacks[i] / stacksSum; // Let's remember this player is ranked usedPlayers[i] = true; // Add his pondered payout to the result result[i] += newFactor * payouts[rank]; // Rank all possible next players recursiveNaiveIcm(stacks, payouts, result, usedPlayers, rank + 1, size, newFactor, stacksSum - stacks[i]); // Reset the flag usedPlayers[i] = false; } } // Entry point vector\u003cdouble\u003e naiveIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts) { // Number of players const int size = stacks.size(); vector\u003cdouble\u003e result(size); // Flags to note down players that were already considered vector\u003cbool\u003e usedPlayers(size); double stacksSum = accumulate(stacks.begin(), stacks.end(), 0.); recursiveNaiveIcm(stacks, payouts, result, usedPlayers, 0, size, 1, stacksSum); return result; } Je n‚Äôavais pas fait de C++ depuis plus de 10 ans alors on ne se moque pas. De mon temps on codait en C++98, on avait une orange √† No√´l, et on √©tait content !\nVoyons ce qu‚Äôon gagne en temps d‚Äôex√©cution :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 2ms for 8 players Duration 18ms for 9 players Duration 177ms for 10 players Duration 2087ms for 11 players Duration 25924ms for 12 players Pas mal, on peut ajouter un onzi√®me et un douzi√®me joueurs pour presque le m√™me temps de calcul. En gros, on a une acc√©l√©ration de 11 x 12, donc de l‚Äôordre de la centaine !\nMais √ßa ne nous emm√®ne pas si loin. Continuons de gratter !\nDeuxi√®me optimisation : cache et C-moins-moins Supposons que nous avons n joueurs. √Ä un moment du calcul o√π on a d√©fini les rangs des k premiers joueurs, il reste n - k joueurs dont on va √©num√©rer les diff√©rentes classements possibles.\nSi on prend ces m√™mes k premiers joueurs mais dans un autre ordre, l‚Äô√©num√©ration des diff√©rents classements des n - k joueurs restants va √™tre presque identique :\nsize, stacks et payouts ne bougent pas result est la destination, ce n‚Äôest pas un param√®tre du calcul usedPlayers a les m√™mes indexes √† true (correspondant aux k joueurs class√©s) rank = k, c‚Äôest le m√™me stacksSum correspond √† la somme des stacks des n - k joueurs restants et a la m√™me valeur En fait, seul le param√®tre factor varie, car la probabilit√© d‚Äôavoir les k premiers joueurs class√©s dans un ordre ou un autre n‚Äôest pas la m√™me.\nCependant, ce facteur est finalement appliqu√© √† toutes les contributions des appels imbriqu√©s. Mais on peut donc l‚Äôextraire et l‚Äôappliquer a posteriori.\nCe-faisant, on va calculer une seule fois cette sous-partie pour n - k joueurs au lieu de la calculer pour chaque classement des m√™mes k premiers joueurs.\nSi en plus on applique √ßa pour tous les k entre 0 et n - 1, on n‚Äôa en fait √† calculer la sous partie que pour toutes les combinaisons (de taille 1 √† n) de joueurs.\nHors on sait tr√®s bien d√©nombrer √©galement le nombre de combinaisons possible de joueurs parmis n, et c‚Äôest 2n. J‚Äô√©voquais tout √† l‚Äôheure la complexit√© factorielle de l‚Äôalgorithme na√Øf, la r√©duire √† une complexit√© exponentielle semble prometteur !\nOn va indexer les sous-calculs √† mettre en cache selon la liste non-ordonn√©e des joueurs d√©j√† class√©s, qui implicitement d√©finit le rang actuel et la somme des stacks restants. Pour ce faire, on va choisir un vecteur de bits repr√©sent√© par un entier, avec √† 1 les bits des joueurs d√©j√† class√©s, et on a une indexation parfaite (et on retombe d‚Äôailleurs sur la complexit√© en 2n). En bonus, on peut se servir de ce bitmask pour remplacer l‚Äôancien tableau de bool√©ens, ce qui va nous √©conomiser quelques cycles de CPU.\nPour ajouter encore un peu de perf, je vous mets avec √ßa des pointeurs old-sChool plut√¥t que des vectors, car oui, √ßa fait une vraie diff√©rence.\nEntendons-nous bien, le niveau d‚Äôoptimisation d√©pend fortement de la nature du probl√®me. Si on bosse sur une app de TODO list, le nombre d‚Äôop√©rations est tellement faible qu‚Äôil n‚Äôy a en g√©n√©ral1 aucune raison de chercher √† √©conomiser des cycles de CPU. Mais quand on multiplie un nombre d‚Äôop√©rations par 220 c‚Äôest √† dire environ un million, on s‚Äôapproche dangereusement de la seconde d‚Äôex√©cution.\net voici ce que √ßa donne :\nvoid recursiveIcm(const double *stacks, const double *payouts, double *result, long long usedPlayers, int rank, int size, double factor, double stacksSum, double *cacheValues, bool *cacheFlags) { if (rank == size || payouts[rank] == 0) { return; } // Point subResult to the cache entry double *subResult = cacheValues + usedPlayers * size; // If the subResult wasn't computed previously, let's do it if (!*(cacheFlags + usedPlayers)) { for (int i = 0; i \u003c size; i++) { const long long iMask = 0x1ll \u003c\u003c i; if (usedPlayers \u0026 iMask) { continue; } // Probability of ith player to have this rank *among remaining players* // (ignoring previously ranked ones) const double newFactor = stacks[i] / stacksSum; // Fill the EV of this subresult for this player subResult[i] += newFactor * payouts[rank]; recursiveIcm(stacks, payouts, subResult, usedPlayers | iMask, rank + 1, size, newFactor, stacksSum - stacks[i], cacheValues, cacheFlags); } // Mark the cache entry as filled *(cacheFlags + usedPlayers) = true; } // Apply the factor accounting for previously ranked players and add to the destination array for (int i = 0; i \u003c size; ++i) { result[i] += factor * subResult[i]; } } vector\u003cdouble\u003e icm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts) { const int size = stacks.size(); // Prepare the array that will receive the results from the recursive function double result[size]; fill_n(result, size, 0); // Just translate vectors to C arrays double stacksArray[size]; double payoutsArray[size]; for (int i = 0; i \u003c size; ++i) { stacksArray[i] = stacks[i]; payoutsArray[i] = payouts[i]; } // Compute the total stack sum const double stacksSum = accumulate(stacks.begin(), stacks.end(), 0.); // ## Cache ## const auto cacheEntrySize = size * sizeof(double); // One double for each player // We'll store all cached subresult in this memory area. auto cacheValues = (double *) calloc(pow(2, size), cacheEntrySize); // And we'll store the information of whether each one is filled or not. auto cacheFlags = (bool *) calloc(pow(2, size), sizeof(bool)); // Ok let's go recursiveIcm(stacksArray, payoutsArray, result, 0, 0, size, 1, stacksSum, cacheValues, cacheFlags); // Just translate back to vector vector\u003cdouble\u003e toReturn(size); for (int i = 0; i \u003c size; ++i) { toReturn[i] = result[i]; } // And free the allocated memory free(cacheValues); free(cacheFlags); return toReturn; } Mais surtout le r√©sultat en termes de performance :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 0ms for 8 players Duration 0ms for 9 players Duration 0ms for 10 players Duration 0ms for 11 players Duration 1ms for 12 players Duration 1ms for 13 players Duration 3ms for 14 players Duration 7ms for 15 players Duration 19ms for 16 players Duration 51ms for 17 players Duration 130ms for 18 players Duration 321ms for 19 players Duration 737ms for 20 players Vous aurez peut-√™tre remarqu√© une optimisation suppl√©mentaire : si le prix du rang concern√© est nul on sort imm√©diatement. Sous l‚Äôhypoth√®se fort raisonnable que les prix sont d√©croissants, les calculs subs√©quents auraient en effet un effet nul. C‚Äôn‚Äôest peut-√™tre qu‚Äôun d√©tail pour vous mais c‚Äôest loin d‚Äô√™tre anodin. On va ainsi r√©duire les combinaisons de joueurs √† un classement uniquement pour les kclasses pay√©es, ce qui nous donne en complexit√© une combinaison potentiellement r√©duite √† Ckn apr√®s application du cache.\nLes chiffres ci-dessus valent lorsqu‚Äôaucun prix n‚Äôest nul, voici l‚Äôeffet quand la moiti√© des places sont pay√©es :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 0ms for 8 players Duration 0ms for 9 players Duration 0ms for 10 players Duration 0ms for 11 players Duration 0ms for 12 players Duration 1ms for 13 players Duration 1ms for 14 players Duration 4ms for 15 players Duration 9ms for 16 players Duration 17ms for 17 players Duration 47ms for 18 players Duration 90ms for 19 players Duration 276ms for 20 players On a donc deux facteurs qui vont d√©terminer le temps d‚Äôex√©cution :\nle nombre de joueurs le nombre de places pay√©es Chemin d‚Äôoptimisation Je vous passe bien s√ªr le cheminement d√©taill√©, car j‚Äôai pris le temps d‚Äôappr√©hender tout ce que j‚Äôavais rat√© ou oubli√© en termes de gestion de m√©moire et des biblioth√®ques standards en C++20. En bref, disons que je suis pass√© par des versions bien plus moderne et haut niveau de cet algorithme avec notamment une std::map puis std::unordered_map puis robinhood::unordered_map pour le cache, des std::vector (qui se copiaient √† chaque affectation ofc) puis des std::vector\u0026 et ensuite des std::shared_ptr\u003cstd::vector\u003e super hype pour finalement revenir √† des pointeurs et calloc pour des questions de performance √©videntes.\nComme disait Sam Waters : ‚ÄúLe profiling, c‚Äôest ma vie‚Äù.\nConclusion et quoi-est-apr√®s J‚Äôai toujours en t√™te de comparer et de titiller les fonctions d‚Äô√©valuation en MTT. J‚Äôai maintenant une biblioth√®que de calcul de l‚ÄôICM de qualit√© professionnelle, qui m‚Äôautorise des simulations de tournois pour un petit nombre de joueur. √áa peut √™tre suffisant pour faire des tests qualitatifs sur quelques joueurs, mais j‚Äôai envie de voir si je peux aller plus loin.\nComment calculer efficacement l‚ÄôICM pour 50 joueurs ? Ce sera tr√®s probablement le sujet de mon prochain billet !\nIl-y-a pas mal d‚Äô√©coles diff√©rentes sur ce sujet bien s√ªr, et cette question prend de plus en plus d‚Äôimportance avec la mont√©e en puissance de l‚Äô√©co-conception. D‚Äôun c√¥t√© on risque de produire du code plus complexe, moins maintenable et moins fiable en cherchant l‚Äôoptimisation, ce qu‚Äôon traduit par l‚Äôinjonction ‚Äúearly optimization is the root of all evil‚Äù qui nous somme de garder le code simple √† moins qu‚Äôil ne soit constat√© n√©cessaire de l‚Äôoptimiser -, de l‚Äôautre on assiste facilement √† un ph√©nom√®ne d‚Äôencrassement √† mesure que le code grossit : si des op√©rations suboptimales sont diss√©min√©es partout, l‚Äôoptimisation consiste alors √† tout r√©√©crire et on regrette de ne pas avoir anticip√©. Comme disait Bouddha : ‚ÄúLa voie du milieu c‚Äôest bien, enfin rarement en voiture quand m√™me‚Äù.¬†‚Ü©Ô∏é\n","description":"O√π on calcule avec brutalit√© les esp√©rances des joueurs selon un mod√®le ind√©pendantiste.","tags":["Poker","AI","ICM","MTT","Game Theory"],"title":"Poker : MTT et ICM #2 - Le Calcul Brutal","uri":"/posts/poker_mtt_icm_calcul/"},{"categories":null,"content":"","description":"","tags":null,"title":"Gambler‚Äôs Ruin","uri":"/tags/gamblers-ruin/"},{"categories":["Game Theory"],"content":"Comme beaucoup, j‚Äôai eu ma p√©riode ‚Äúpoker‚Äù. Elle s‚Äôest tr√®s vite traduite chez moi par la conception d‚Äôoutils divers d‚Äôaide et d‚Äôanalyse de jeu (parce que je suis trop mauvais), et a donn√© naissance √† cette petite biblioth√®que Java. J‚Äôai tir√© beaucoup de cette exp√©rience, que ce soit en th√©orie des jeux, en algorithmique th√©orique et pratique, en intelligence artificielle ou m√™me en architecture logicielle. Alors bon, je n‚Äôassume pas tout √† fait cette vieille lib, ‚Äúsi je devais la recoder je le ferais diff√©remment‚Äù‚Ñ¢ - pas en Java notamment - mais √ßa fait partie de ces projets tentaculaires qui vous portent pendant des ann√©es et vous font monter en comp√©tence sur un large front dans l‚Äôall√©gresse.\n√áa me titillait depuis longtemps de trouver un sujet dans le domaine et de bonnes raisons de m‚Äôy recoller. Quand soudain, je tombai sur le paradoxe de Saint-P√©tersbourg qui relan√ßa avec un ami une vieille conversation sur l‚Äô√©valuation de l‚ÄôEV (expected value) en MTT (multi-table tournament).\nIl se trouve que la question ‚ÄúFaut-il jouer toutes les mains EV+ ICM en tournoi?‚Äù impliquait un long p√©riple avec dedans du machine-learning, des simulations de jeu et des mod√©lisations int√©ressantes - tout ce que j‚Äôadore.\nMais revenons au d√©but, je vais commencer dans ce billet par tenter de vous expliquer la question.\nTh√©orie des jeux Au poker, on cherche souvent √† jouer GTO (Game Theory Optimal). Derri√®re ce terme, beaucoup d‚Äôimplicite. La th√©orie des jeux √©tudie les interactions strat√©giques d‚Äôagents √† cheval entre les math√©matiques et les sciences sociales, avec de tr√®s int√©ressantes questions qu‚Äôon va oublier bien vite : Comment d√©finit-on la rationalit√© des agents ? Est-elle normative ou prescriptive ? Quelles qualit√©s descriptives a-t-elle ?\nVoil√†, on oublie, et maintenant on constate que dans la plupart des cas, tout le monde cherche √† trouver la meilleure mani√®re de jouer pour gagner - que ce soit aux √©checs, au poker, au go ou √† Starcraft1.\nDans des jeux comme les √©checs, les algorithmes n‚Äôexplorent pas l‚Äôensemble de l‚Äôarbre de jeu mais √©valuent un certain nombre de coups √† l‚Äôavance. Si je regarde les 5 prochains coups possibles et que sur cette base je dois faire un choix, il me faut √©valuer la valeur de chaque situation future r√©sultant de chaque combinaison possible de 5 actions. On appelle fonction d‚Äô√©valuation cette estimation de la valeur d‚Äôune situation qui n‚Äôest pas une situation finale. Dans des jeux faisant intervenir la chance (l‚Äôal√©atoire), on la confond souvent avec la valeur statistique d‚Äôesp√©rance (EV, Expected Value : l‚Äôesp√©rance), car on va prendre les d√©cisions en fonction de l‚ÄôEV calcul√© gr√¢ce la fonction d‚Äô√©valuation. EV+ signifie ainsi ‚Äúd‚Äôesp√©rance positive‚Äù.\nPoker Le poker est un jeu de taille consid√©rable du fait du nombre de combinaisons de cartes multipli√© par le nombre de s√©quences d‚Äôaction (mises) de jeu possibles. Je parle ici uniquement du No-Limit Hold‚ÄôEm (NLHE) qui est la variante la plus commune.\nDans le cas du cash-game o√π les jetons mis√©s valent une somme d√©termin√©e d‚Äôargent, le probl√®me de l‚Äôoptimisation de la strat√©gie est circonscrit √† une main. Cela reste √©norme en complexit√© mais permet aux explorations algorithmiques de ne pas recourir √† des fonctions d‚Äô√©valuation interm√©diaire, et d‚Äôinterpr√©ter directement les gains et pertes futurs r√©sultant des actions en terme d‚Äôargent.\nEn effet, lorsqu‚Äôon va chercher √† √©valuer si telle action est pr√©f√©rable √† telle autre, on va faire ce genre de calcul :\nSi je me couche, √† la fin de la main j‚Äôai un stack (un tapis) de 900 jetons. Si je suis la mise, selon les cartes qui vont √™tre r√©v√©l√©es : j‚Äôai 40% de chances de finir avec un stack de 1300 jetons j‚Äôai 60% de chances de finir avec un stack de 500 jetons Je peux donc calculer mon esp√©rance :\nMe coucher : 900 jetons Suivre : 0,4 x 1300 + 0,6 x 500 = 820 jetons Ok, je dois donc rationnellement me coucher, car plus (+) de jetons, c‚Äôest mieux.\nTournoi Dans un tournoi cependant, les prix sont attribu√©es selon la place finale d‚Äôun joueur. Prenons le cas de trois joueurs qui doivent partager 1000‚Ç¨ de prix et disposent en tout de 1000 jetons. Nous ne connaissons rien des joueurs, si bien qu‚Äôon les consid√®re aveugl√©ment √† √©galit√© strat√©gique.\nSi seul le premier joueur remporte les 1000‚Ç¨ il para√Æt raisonnable d‚Äôestimer leurs chances de gagner proportionnellement √† leurs stacks. On peut d‚Äôailleurs v√©rifier √ßa tr√®s facilement en leur faisant √©changer des jetons al√©atoirement (ce qui simule bien l‚Äô√©galit√© strat√©gique). Si les stacks sont 500, 300 et 200, alors en moyenne le premier joueur remportera la mise 50% du temps, le second 30% et le dernier 20%. Leurs esp√©rances de gain sont donc 500‚Ç¨, 300‚Ç¨ et 200‚Ç¨ respectivement.\nPetite simulation pour v√©rifier √ßa :\nimport numpy as np import random nb_simulations = 100000 players_stacks = [5, 3, 2] # We'll exchange chips one by one, so let's speed-up by setting smaller stacks payouts = [1000, 0, 0] nb_players = len(players_stacks) podiums = [] for i in range(nb_simulations): game_stacks = players_stacks.copy() podium = [] while True: in_game_players = [i for i, stack in enumerate(game_stacks) if stack \u003e 0] if len(in_game_players) == 1: # We have a winner podium = in_game_players + podium break # Exchange chips until one player is broke while True: # Randomly select two players random.shuffle(in_game_players) p1 = in_game_players[0] p2 = in_game_players[1] # And make them exchange one chip game_stacks[p1] += 1 game_stacks[p2] -= 1 # Is the losing player broke ? if game_stacks[p2] == 0: podium = [p2] + podium break # Recompute in_game_players podiums.append(podium) result = [0.0] * nb_players for podium in podiums: for i in range(nb_players): player = podium[i] result[player] += payouts[i] result = np.divide(result, nb_simulations) print(result) Output :\n\u003e [499.611 299.829 200.56 ] Ce qui m‚Äôa bien l‚Äôair de converger vers le r√©sultat attendu.\nPetite note sur la taille des stacks all√®grement divis√©e par 100 : il se trouve que √ßa n‚Äôa aucune influence, je l‚Äôai v√©rifi√© exp√©rimentalement. Cependant comme j‚Äôaimerais bien savoir pourquoi et que je n‚Äôai pas le temps de creuser, j‚Äôai pos√© la question √† l‚ÄôInternet.\n[EDIT] Au temps pour moi, la proportionalit√© n‚Äôest pas la seule √† compter. La taille des stacks a bien une influence dans le cas suivant o√π le second joueur a un prix ! Ceci-dit, m√™me si mes chiffres sont l√©g√®rement biais√©s √ßa n‚Äôinvalide en rien le propos.\nMaintenant, si le premier joueur remporte 600‚Ç¨ et le second 400‚Ç¨, a-t-on les m√™mes esp√©rances de gain ? Faisons donc tourner cette simulation avec ces payouts :\npayouts = [600, 400, 0] Output :\n\u003e [445.71 330.83 223.46] Il est tout de suite moins intuitif d‚Äôestimer √ßa √† vue de nez.\nICM Le jeu simul√© ci-dessus est le Gambler‚Äôs Ruin (qui est en soi plus un probl√®me th√©orique qu‚Äôun jeu).\nLa performance de cette simulation est tr√®s faible pour de nombreux joueurs avec de nombreux jetons. Il existe des techniques de calcul avanc√©es que je n‚Äôai pas encore explor√©es, car en pratique les joueurs de poker pr√©f√®rent mod√©liser leur esp√©rance de classement gr√¢ce √† l‚ÄôIndependent Chip Model (ICM) dont le calcul est bien plus simple.\nL‚ÄôICM est un mod√®le qui statue que la contribution √† l‚Äôacc√®s √† la premi√®re place du tournoi est la m√™me pour chaque jeton, puis r√©cursivement pour les places suivantes. On retrouve donc la proportionnalit√© entre les jetons et l‚Äôesp√©rance lorsque seul le premier joueur remporte le prix.\nAttention cependant, l‚ÄôICM n‚Äôest pas une solution du classement du probl√®me du N-players Gambler‚Äôs Ruin. C‚Äôest par contre une approximation commune.\nPour la situation ci-dessus, l‚ÄôICM nous donnera donc avec les stacks [500, 300, 200]:\nEn notant X_Y = le joueur X finit en Yi√®me position.\nP1_1 = 500 / 1000 = 0.5 P2_1 = 300 / 1000 = 0.3 P3_1 = 200 / 1000 = 0.2 Puis r√©cursivement, en appliquant la formule des probabilit√©s totales, on calcule la probabilit√© que le joueur 1 soit deuxi√®me :\nP1_2 = P2_1 * P(1_2 | 2_1) + P3_1 * P(1_3 | 3_1) P1_2 = 0.3 * (500 / 700) + 0.2 * (500 / 800) = 0,339 De m√™me pour les autres joueurs et ainsi de suite pour la troisi√®me place. Pour vous √©viter les calculs √† la main, il existe des calculateurs en ligne. Celui d‚ÄôHoldemResources et celui d‚ÄôICMIzer.\nPour notre situation, l‚ÄôICM nous donne les valeurs :\n\u003e [435.71 330.00 234.29] Pour comparer les r√©sultats, la simulation de Gambler‚Äôs Ruin nous donnait :\n\u003e [445.71 330.83 223.46] On retrouve un biais classique de l‚ÄôICM qui est de sous-estimer la valeur des plus gros stack et de surestimer les plus petits, tout en restant tr√®s correct pour les autres.\nR√©capitulatif Prenons un tout petit peu de recul. Pourquoi a-t-on besoin de cet ICM d√©j√† ?\nParce que lorsqu‚Äôon cherche une strat√©gie optimale, on doit estimer la valeur des situations vers lesquelles nous m√®nent nos actions potentielles. Dans le cas du cash-game, la valeur est imm√©diatement disponible en fin de main car elle est directement proportionnelle √† la quantit√© de jetons. Mais pour un tournoi, il faudrait aller jusqu‚Äô√† la r√©solution du tournoi entier pour observer le gain obtenu. Et autant dire que lorsqu‚Äôon doit d√©rouler toutes les possibilit√©s de tirages et d‚Äôactions futures, on pr√©f√®re circonscrire le probl√®me √† la main en cours pour avoir un r√©sultat avant la fin des temps dans le cas d‚Äôun calcul informatique.\nOn pr√©f√®rerait savoir calculer les esp√©rances de classement selon le mod√®le du Gambler‚Äôs Ruin, h√©las il est beaucoup plus compliqu√© d‚Äôavoir une performance correcte dans ce calcul (ceci dit √† ce sujet, j‚Äôai dans ma pile de lectures quelques papiers que j‚Äôexplorerai je l‚Äôesp√®re un de ces jours2).\nLa fonction d‚Äô√©valuation est un outil sur lequel on va soit entrainer des IA, soit faire des analyses strat√©giques avec des joueurs r√©els, mais elle ne repr√©sente pas l‚Äôesp√©rance concr√®te des joueurs la plupart du temps. Et c‚Äôest d‚Äôailleurs en g√©n√©ral ce qu‚Äôon souhaite, car essayer de se rapprocher des valeurs concr√®te c‚Äôest essayer de revenir √† la r√©solution du tournoi entier en utilisant strat√©gies calcul√©es sur la base de la fonction d‚Äô√©valuation‚Ä¶ Et c‚Äôest l‚ÄôOuroboros.\nPourtant on pourrait faire tendre vers plus de r√©alisme. Si on sait par exemple qu‚Äôun tournoi typique regroupe des joueurs de diff√©rents niveaux distribu√©s d‚Äôune mani√®re assez r√©guli√®re, mod√©liser ce fait statistique peut produire une fonction d‚Äô√©valuation plus adapt√©e √† l‚Äôentra√Ænement pour ce contexte de jeu. Car pour une IA, le jeu sur laquelle on l‚Äôentra√Æne inclut la fonction d‚Äô√©valuation. Sa confrontation au jeu r√©el sera lourdement affect√©e par le choix de cette fonction. On peut d‚Äôailleurs arbitrairement consid√©rer que le niveau des joueurs fait partie des donn√©es d‚Äôentr√©e de la fonction. Cependant on pr√©f√®re reporter ce genre de donn√©es contextuelles vers les algorithmes strat√©giques pour garder une fonction d‚Äô√©valuation g√©n√©rique et stable : l‚Äôappr√©ciation du niveau des joueurs est une donn√©e strat√©gique et contextuelle, elle sera donc int√©gr√©e comme une donn√©e d‚Äôentr√©e des m√©canismes strat√©giques.\nConclusion La question ‚ÄúFaut-il jouer toutes les mains EV+ ICM en tournoi?‚Äù prise litt√©ralement a une r√©ponse imm√©diate : non, il-y-a m√™me des ajustements que l‚Äôon sait b√©n√©fiques. Tout d‚Äôabord il est fort probable qu‚Äôune meilleure approximation du classement du Gambler‚Äôs Ruin donnerait de meilleurs r√©sultats, ensuite s‚Äôil √©tait possible de calculer une fonction d‚Äô√©valuation prenant en compte les asym√©tries du poker (tables de jeu et tours de parole) on augmenterait certainement encore la fiabilit√© de l‚Äô√©valuation.\nMais apr√®s cette question vient la suivante : peut-on trouver un meilleur mod√®le que l‚ÄôICM calculable efficacement ? Exp√©rimentalement par exemple, pourrait on appliquer des techniques modernes de machine learning pour trouver une fonction d‚Äô√©valuation qui surpasse l‚ÄôICM ? Et comment faire tout √ßa en pratique et pour un grand nombre de joueurs sachant que le calcul de l‚ÄôICM a une complexit√© factorielle ?\nDes d√©buts de r√©ponses dans un prochain billet !\nPS: dans ce billet, j‚Äôessaye de ne pas trop rentrer dans les d√©tails ce qui vaut des impr√©cisions et des raccourcis volontaires. N‚Äôh√©sitez cependant pas √† m‚Äô√©crire si vous trouvez √† redire, ou s‚Äôil-y-a des manques criants !\nPS bis: en cadeau, un petit papier sympa qui montre deux th√©or√®mes contre-intuitifs.\nTheorem 1. Suppose a tournament has prize money for nth place which is at least that for (n + 1)st place and that at least one player still in the tournament will not earn as much as second place prize money. Under the Independent Chip Model, any fair bet in which only one other player can gain or lose chips in the hand being played will lower the player‚Äôs expected prize money.\nTheorem 2. Suppose a tournament has prize money for nth place which is at least that for (n + 1)st place and that at least one player still in the tournament will not earn as much as second place prize money. Under the Independent Chip Model, the expected prize money of any player not involved in a fair bet between two players will increase*\nTraduit √† la pelle par :\nSi t‚Äôes en duel avec une √©quit√© de 50% contre un seul adversaire au sein d‚Äôun tournoi avec des prix croissants, tu es perdant selon l‚ÄôICM. Si deux joueurs sont en duel dans ces m√™mes circonstances, tous les autres joueurs sont gagnants en ICM. Ces jeux sont de natures tr√®s vari√©es. C‚Äôest ce qui fait d‚Äôailleurs qu‚Äô√† l‚Äôheure actuelle, les meilleures IA de poker sont bas√©es sur des techniques tr√®s diff√©rentes de l‚Äôimpressionnant MuZero de DeepMind (j‚Äôesp√®re avoir le temps de faire un petit papier ‚ÄúCFR vs Reinforcement Learning pour les nuls‚Äù tiens).¬†‚Ü©Ô∏é\nles papiers en question : Swan, Y., \u0026 Bruss, F. (2006). A matrix-analytic approach to the N-player ruin problem. Journal of Applied Probability, 43(3), 755-766. doi:10.1239/jap/1158784944, et Gambler‚Äôs Ruin and the ICM - arXiv:2011.07610v2. Et bien s√ªr toutes leurs r√©f√©rences üôÉ¬†‚Ü©Ô∏é\n","description":"O√π il est question des fonctions d‚Äô√©valuation en th√©orie des jeux, du Gambler‚Äôs Ruin et de l‚ÄôICM.","tags":["Poker","AI","ICM","MTT","Gambler's Ruin","Game Theory"],"title":"Poker : MTT et ICM #1 - La Question","uri":"/posts/poker_mtt_icm_question/"},{"categories":null,"content":"Je suis architecte logiciel g√©n√©raliste et algorithmicien polyglotte.\nDe l‚Äôid√©e √† la ligne de code, les choix sont innombrables et vari√©s. Distinguer les d√©cisions qui importent et les qualifier efficacement est aussi d√©terminant que l‚Äôexpertise technique.\nToujours motiv√© par la recherche de la solution la plus pertinente dans les contextes des plus communs aux plus complexes mais aussi par sa r√©alisation de bout en bout, contactez-moi pour me parler de vos projets :\npar email pierre@pittscraft.com par t√©l√©phone (ou Signal, Whatsapp, Telegram) au +33 (0)6 62 98 24 38 Pierre Mardon (Pitt)\n","description":"","tags":null,"title":"√Ä propos","uri":"/about/"},{"categories":null,"content":"","description":"","tags":null,"title":"Combine","uri":"/tags/combine/"},{"categories":null,"content":"","description":"","tags":null,"title":"SwiftUI","uri":"/tags/swiftui/"},{"categories":["Application mobile"],"content":"J‚Äôavais d√©j√† crois√© un exemple d‚Äôimpl√©mentation de property wrapper et devant leur simplicit√©, je m‚Äô√©tais mis en t√™te de cr√©er un property wrapper acc√©l√©rant le stockage de valeurs dans les UserDefaults.\nIl se trouve que dans mes exp√©rimentations autour de Combine j‚Äôavais bien envie de cr√©er un wrapper publiant les nouvelles valeurs seulement apr√®s les avoirs stock√©es (voir ici).\nEt puis j‚Äôai finalement voulu faire tout en m√™me temps !\nQu‚Äôest-ce donc qu‚Äôun property wrapper ? Un property wrapper tr√®s simple s‚Äô√©crit de cette mani√®re :\n@propertyWrapper public class Print\u003cValue\u003e {ss private var val: Value public init(wrappedValue value: Value) { val = value } public var wrappedValue: Value { set { print(\"Setting '\\(val)'\") val = newValue } get { print(\"Returning '\\(val)'\") return val } } } et s‚Äôutilise ensuite ainsi :\nclass SomeClass { @Print var myString: String = \"Coucou copaing !\" func doThings() { myString = \"Bye friend\" var something = myString } } SomeClass().doThings() ce qui imprimera\n\u003e Setting 'Bye friend' \u003e Getting 'Bye friend' ce qui est plut√¥t nul.\nCeci-dit, si on d√©cidait de faire des choses plus int√©ressantes que des print, on pourrait bien se faciliter la vie !\nGot UserDefaults ? Stocker des propri√©t√©s dans les UserDefaults Voil√† un usage fr√©quent et int√©ressant.\n@propertyWrapper public struct UserDefaultsBacked\u003cValue\u003e { private let key: String private let defaultValue: Value private let storage: UserDefaults public init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) { defaultValue = value self.key = key self.storage = storage } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Et une impl√©mentation un peu na√Øve comme celle ci-dessus peut faire l‚Äôaffaire.\nUn petit warning quand m√™me, on n‚Äôoublie pas que chaque setValue sur une cl√© de UserDefaults r√©√©crit le dictionnaire complet. On utilisera donc tout √ßa en connaissance de cause, et n‚Äôoublions pas qu‚Äôon peut aussi r√©duire leur taille en n‚Äôutilisant pas syst√©matiquement le .standard.\nOn peut noter la pr√©sence de nouveaux arguments du constructeur, la key et le storage. Ils peuvent √™tre fournis via la d√©claration de l‚Äôannotation, ou doivent l‚Äô√™tre pour ceux qui n‚Äôont pas de valeur par d√©faut comme la key.\n@UserDefaultsBacked(\"int-key\") // Smells like Java var someInt = 8 @UserDefaultsBacked(\"my-data\", storage: UserDefaults(\"DBName\")) var someData: Data? = nil struct SomeStruct { var prop = \"Yup\" } @UserDefaultsBacked(\"my-struct\") var myStruct = SomeStruct() // Wait... What ? Stocker uniquement les types compatibles Ce wrapper fonctionnera tr√®s bien avec tous les types support√©s par les UserDefaults mais attendez-vous √† de bons crashes pour tous les autres cas, comme SomeStruct.\nRestreignons-donc d√©j√† l‚Äôusage aux bonnes valeurs gr√¢ce √† un flag protocol :\npublic protocol UserDefaultsStorable {} extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} @propertyWrapper public struct UserDefaultsBacked\u003cValue\u003e { private let key: String private let defaultValue: Value private let storage: UserDefaults public init(wrappedValue value: Value, key: String, storage: UserDefaults = .standard) where Value: UserDefaultsStorable { defaultValue = value self.key = key self.storage = storage } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Ok, on a maintenant un property wrapper s√©lectif et une belle erreur de compilation dans le cas o√π le type ne se conforme pas √† UserDefaultsStorable.\n@UserDefaultsBacked(\"my-struct\") var myStruct = SomeStruct() // Error: Initializer 'init(wrappedValue:_:storage)' requires that 'SomeStruct' conform to 'UserDefaultsStorable' Stocker les Codables Bien mais SomeStruct n‚Äôest pas bien myst√©rieux, ce serait bien sympa de pouvoir le stocker aussi. En fait, tout codable est a priori stockable puisque Data l‚Äôest. Seulement pour √©viter de se faire la conversion √† chaque acc√®s, profitons donc de notre wrapper.\nG√©n√©ralisons : on peut avoir √† mapper les donn√©es dans un sens et dans l‚Äôautre pour pouvoir les stocker. L‚Äôinterface de UserDefaults utilise le tr√®s g√©n√©rique Any?, on va donc d√©finir les mappers :\ntypealias StoringMapper\u003cValue\u003e = (Value) -\u003e Any? typealias StoreReadingMapper\u003cValue\u003e = (Any?) -\u003e Value? Puis:\nd√©finir des propri√©t√©s de ce type dans notre wrapper. d√©finir un constructeur priv√© aveugle qui prend de bonne fois n‚Äôimporte quel type de propri√©t√© avec des mappers d√©finir des constructeurs publics stricts sur le type qui vont fournir des mappers au constructeur priv√© @propertyWrapper public class UserDefaultsBacked\u003cValue\u003e { private let key: String private let storage: UserDefaults private let defaultValue: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String , storage: UserDefaults, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { var initValue = value if let storedValue = storeReadingMapper(storage.object(forKey: key)) { initValue = storedValue } defaultValue = initValue self.key = key self.storage = storage self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Mais pour mes Codables les mappers ne sont pas si √©vidents.\npublic extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } Ci-dessus la fonction d‚Äôencodage, avec absolument pas de check sur le cas o√π l‚Äôobjet est √©galement stockable nativement, car la discrimination s‚Äôeffectuera en amont. Bon, c‚Äôest l‚Äô√©quivalent de try? JSONEncoder().encode(self) mais avec une trace pour ne pas √™tre compl√®tement dans le brouillard en cas de probl√®me. Evidemment on pr√©f√®rera certainement donner de meilleures options de tra√ßage, et certains se sentent mal (√† raison) de ne pas throw quoi que ce soit, mais ce n‚Äôest pas le d√©bat ici. Et puis comme on dit parfois : ‚ÄúQuand tout va bien, tout va bien !‚Äù.\n/// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } Joyeusement pomp√© de ce post SO\nTiens je parlais dans mon poste pr√©c√©dent de type erasure, mais saviez vous que l‚Äôinverse est le type opening ? Eh bien pareil, je me suis couch√© moins b√™te. Et pour tous ceux qui ont d√©j√† jou√© avec un JSONDecoder dans des contextes g√©n√©riques un peu pouss√©s, la feinte ci-dessus est plut√¥t cool √† retenir : une fonction statique a toujours acc√®s au type concret, ce qui satisfait le compilo.\npublic extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to ignore thrown errors return nil } } } Et voil√†, sur tout type se conformant √† Decodable on a d√©sormais cette fonction mapOutOfStorage.\nJe rappelle que typealias Codable = Decodable \u0026 Encodable, donc pour tout type Codable on a nos deux mappers \\o/\nRajoutons donc ce petit constructeur √† notre property wrapper UserDefaultsBacked :\nconvenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, storingMapper: Value.mapForStorage, storeReadingMapper: Value.mapOutOfStorage) } Nice, et maintenant qu‚Äôest ce qui se passe si je d√©clare quelque chose comme :\n@UserDefaultsBacked(\"myKey\") var myInt = 0 // Error: Ambiguous use of 'init(wrappedValue:_:storage:sendAfterStore:)' Eh bien les Int √©tant Codable mais aussi UserDefaultsStorable, le compilateur ne saura quel constructeur choisir. Deux solutions : enlever l‚Äôambiguit√© en changeant la signature d‚Äôun des constructeurs (ce qui est un peu minable, m√™me simplement d‚Äôy avoir pens√©), ou donner un constructeur qui match encore mieux, avec where Value : Codable \u0026 UserDefaultsStorable. Encore un bon trick, vous √™tes bienvenus.\nCheckpoint Voici un petit bilan :\n/// Any type implementing this protocol can be stored natively in UserDefaults public protocol UserDefaultsStorable {} /** Declare proper flag protocol conformance for all types natively compatible with UserDefaults storage */ extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} /// `Encodable` mapping for storage public extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } /// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { // Useful trick from https://stackoverflow.com/questions/54963038/codable-conformance-with-erased-types static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } /// `Decodable` mapping for reading from storage public extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to almost ignore thrown errors return nil } } } @propertyWrapper public class UserDefaultsBacked\u003cValue\u003e { private let key: String private let storage: UserDefaults private let defaultValue: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String, storage: UserDefaults, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { defaultValue = value self.key = key self.storage = storage self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, storingMapper: Value.mapForStorage, storeReadingMapper: Value.mapOutOfStorage) } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable \u0026 UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: {$0 as? Value}) } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Fun fact : j‚Äôai retrouv√© le m√™me flag protocol sur un post (je l‚Äôai plus sous la main l√†), puis vu des impl√©mentations proches pour les Codable, mais tout √ßa bien s√ªr apr√®s avoir r√©invent√© la roue. Et m√™me si on dit souvent √ßa p√©jorativement, dans une d√©marche d‚Äôapprentissage √ßa a tout son sens de regarder les solutions seulement ensuite. Et en plus c‚Äô√©tait vachement moins bien fait, genre l√† pas de type checking, aucune cohabitation entre les Codable et les types natifs‚Ä¶ Nan mais jvous jure‚Ä¶\nEt puis de toute fa√ßon je voulais aussi m‚Äôoccuper de faire ‚Ä¶\nUn publisher un peu custom Lorsqu‚Äôon utilise SwiftUI et Combine simplement, on va naturellement devoir taper des expression comme $myState ou $myObject.prop. Une fois pass√©e mon aversion forte pour le PHP, j‚Äôai creus√© rapidement pour constater que ce n‚Äô√©tait qu‚Äôune syntaxe un peu flippante pour acc√©der √† la valeur projet√©e d‚Äôune wrapped property.\nProjected value ? En bref, n‚Äôimporte quel property wrapper peut d√©clarer une var projectedValue: SomeType {...} dont le type n‚Äôest pas n√©cessairement le m√™me que celui de sa wrappedValue. Et cette projectedValue est accessible gr√¢ce au dollar am√©ricain (comme tellement de choses).\n@propertyWrapper public class Print\u003cValue\u003e { private var val: Value public init(wrappedValue value: Value) { val = value } public var wrappedValue: Value { set { print(\"Setting '\\(val)'\") val = newValue } get { print(\"Returning '\\(val)'\") return val } } public var projectedValue: Int { print(\"42\") return 8 } } @Print var myString: String = \"5\" myString = \"40\" print(\"Coucou \\($myString)\") printera donc\n\u003e Setting '40' \u003e 42 \u003e Coucou 8 Aaah, je pense que j‚Äôai fait le pire exemple qui soit, ‚Äúservice !‚Äù comme on dit dans l‚Äôest.\nBref, ce $ n‚Äôa en th√©orie pas forc√©ment grand chose √† voir avec Combine except√© qu‚Äôon l‚Äôy utilise en permanence.\nQuelques notions de Combine Typiquement, le property wrapper Published a pour type projet√© la struct Published\u003cValue\u003e.Publisher (doc) qui respecte notamment le protocole Publisher (et bien plus, doc), et peut donc envoyer des Value √† des Subscriber.\nDonc quand j‚Äôacc√®de √† un @Published var myString: String via $myString j‚Äôobtiens en gros une propri√©t√© dont je peux √©couter les valeurs successives.\nEt quand je fais du SwiftUI ainsi : .sheet(isPresented: $vm.router.showSheet, ...), je passe donc un Publisher √† la fonction sheet qui se fera un plaisir d‚Äô√©couter si on doit o√π non pr√©senter cette sheet.\nRappel : lorsqu‚Äôon utilise sink pour √©couter les valeurs d‚Äôune var @Published via son Publisher, on re√ßoit la nouvelle valeur alors que la wrappedValue est encore l‚Äôancienne valeur. Et je voudrais contourner √ßa dans certains cas (voir mon post pr√©c√©dent).\nMaintenant, ce qui m‚Äôint√©resserait ce serait d‚Äôavoir √ßa, un Publisher que je pourrais contr√¥ler finement pour lui envoyer des valeurs. Eh bien Combine nous fournit gracieusement le protocole Subject qui h√©rite de Publisher et qui pr√©sente de surcroit une fonction send(_:) permettant d‚Äôenvoyer des valeurs √† publier. Ses impl√©mentations sont :\nCurrentValueSubject qui d√©tient une valeur courante PassthroughSubject qui au contraire ne retient rien On devrait s‚Äôen sortir avec √ßa !\nDidSet Publisher property wrapper Pour reproduire le comportement de @Published on pourrait √©crire comme √ßa comme √ßa.\n@propertyWrapper public class BasicPublished\u003cValue\u003e { private let subject: CurrentValueSubject\u003cValue, Never\u003e public init(wrappedValue value: Value) { subject = CurrentValueSubject(value) wrappedValue = value } public var wrappedValue: Value { set { subject.send(newValue) } get { subject.value } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } Le probl√®me √©tant que lorsque le send va provoquer l‚Äôex√©cution de toutes les closures des subscribers, subject.value aura toujours l‚Äôancienne valeur.\nAssez simple du coup d‚Äôy rem√©dier :\n@propertyWrapper public class DidSetPublished\u003cValue\u003e { private var val: Value private let subject: CurrentValueSubject\u003cValue, Never\u003e public init(wrappedValue value: Value) { val = value subject = CurrentValueSubject(value) wrappedValue = value } public var wrappedValue: Value { set { val = newValue subject.send(val) } get { subject.value } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } (je crois que cette impl√©mentation vient de l√†, et je crois aussi qu‚Äôil serait plus pertinent d‚Äôutiliser PassthroughSubject a priori)\nTout ensemble Vous le saviez, mon but ultime √©tait ~la conqu√™te de la Su√®de en lama~ de combiner tout √ßa. Pas juste pour le fun, mais parce que dans mon archi, √† un moment, j‚Äôavais besoin d‚Äôune propri√©t√© Codable (un enum) stock√©e dans les UserDefaults et qui ne publierait son changement de valeur qu‚Äôapr√®s l‚Äôavoir affect√© √† sa wrappedValue.\nEt puis d‚Äôautres besoins avec des variations : pas de stockage mais publication apr√®s affectation, stockage natif mais publication avant affectation‚Ä¶\nJ‚Äôaurais bien pu contourner tout √ßa, ou encore essayer de faire fonctionner des wrappers imbriqu√©s, mais je voulais me frotter √† cette impl√©mentation sp√©cifique.\nEt voil√†, je vous colle juste l‚Äôensemble l√† dessous, chaque d√©tail √©tant expliqu√© dans les parties pr√©c√©dente (enfin faut savoir quelques trucs en amont quand m√™me, oui).\nN‚Äôoubliez pas que la perf n‚Äôest pas l‚Äôobjectif de ce wrapper (du tout).\nJe vous sugg√®re d‚Äôailleurs de jeter un oeil √† l‚Äôimpl√©mentation de Published chez OpenCombine, qui est particuli√®rement √©l√©gante (ya un enum \u003c3).\n// // SmartPublished.swift // attestation // // Created by Pierre Mardon on 01/01/1970. Trust me. // import Foundation import Combine /// We need functions to map values before storing them to user defaults fileprivate typealias StoringMapper\u003cValue\u003e = (Value) -\u003e Any? /// We need functions to map values read from user defaults storage to an expected type fileprivate typealias StoreReadingMapper\u003cValue\u003e = (Any?) -\u003e Value? /// Any type implementing this protocol can be stored natively in UserDefaults public protocol UserDefaultsStorable {} /** Declare proper flag protocol conformance for all types natively compatible with UserDefaults storage */ extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} /// `Encodable` mapping for storage public extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } /// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { // Useful trick from https://stackoverflow.com/questions/54963038/codable-conformance-with-erased-types static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } /// `Decodable` mapping for reading from storage public extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to almost ignore thrown errors return nil } } } /** Property wrapper that provides some common use cases options. Do NOT use for heavy performance demanding components. - `UserDefaults` storage is activated when a `key` is provided for all natively handled types and `Codable` ones - option `sendAfterStore` makes the subject send the value only after it has effectively been affected to the property itself: WARNING this is not recommended for UI bindings. Disabled by default. Usage: \\``` @SmartPublished(\"someKey\") var myProp = \"Bonjoir !\" \\``` The string property will be backed in UserDefaults.standard for the key \"someKey\". It will be effectively stored only if the value of the var is affected after its initialization, until then UserDefaults entry will stay untouched. The initial value of the property will be `\"Bonjoir !\"` if there's not value in the store. \\``` @SmartPublished(\"myCodableValueUserDefaultsKey\") var myProp = someValueOfCodableType \\``` The codables are stored the same way except they are JSON encoded if they're not natively handled by UserDefaults. \\``` @SmartPublished(sendAfterStore = true) var myProp = 8 $myProp.sink { print(\"property: \\(myProp), received: \\($0)\") } myProp = 1 \\``` Will print `property: 1, received: 1`, while with `@Published` or `sendAfterStore = false` it would be `property: 8, received: 1`. It is not recommended to use this `sendAfterStore = true` for UI-bound properties. \\``` @SmartPublished \\``` Why would you do that, just use `@Published` then! */ @propertyWrapper public class SmartPublished\u003cValue\u003e { private let key: String? private let storage: UserDefaults private let sendAfterStore: Bool private let subject: CurrentValueSubject\u003cValue, Never\u003e private var val: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String? , storage: UserDefaults, sendAfterStore: Bool, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { var initValue = value if let key = key, let storedValue = storeReadingMapper(storage.object(forKey: key)) { initValue = storedValue } val = initValue subject = CurrentValueSubject(initValue) self.key = key self.storage = storage self.sendAfterStore = sendAfterStore self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper subject.send(val) } public convenience init(wrappedValue value: Value, _ key: String? = nil, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, _ key: String?, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0.mapForStorage()}, storeReadingMapper: Value.mapOutOfStorage) } public convenience init(wrappedValue value: Value, _ key: String?, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable \u0026 UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, sendAfterStore: Bool = false) { self.init(wrappedValue: value, nil, storage: .standard, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: {$0 as? Value}) } public var wrappedValue: Value { set { if sendAfterStore { subject.send(newValue) } if let key = self.key { storage.setValue(storingMapper(newValue), forKey: key) } else { val = newValue } if !sendAfterStore { subject.send(newValue) } } get { if let key = self.key { return storeReadingMapper(storage.value(forKey: key)) ?? val } return val } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } N‚Äôh√©sitez pas √† me contacter pour toute remarque, insulte ou √©loge, mon email est dans le footer ;)\n","description":"","tags":["iOS","Combine","SwiftUI"],"title":"SwiftUI \u0026 Combine Feedback #2 : property wrapper pour UserDefaults et @Published","uri":"/posts/swiftui_combine2/"},{"categories":["Application mobile"],"content":"Apr√®s mon premier petit TP autour de SwiftUI et Combine pour g√©n√©rer mes attestations de d√©placement ~√† la barbe de la mar√©chauss√©e~ √† la vol√©e voire en retard, j‚Äôai profit√© de l‚Äôadaptation au second format d‚Äôattestation pour faire des explorations un peu plus pouss√©es de mon architecture autour de Combine.\nJ‚Äôen sors une petite liste de consid√©rations techniques que j‚Äôesp√®re d‚Äôint√©r√™t, et voici les premi√®res !\nArchitecture: MVVM+ Pour une petite app comme celle-ci, je m‚Äôautorise des entorses √† nombre de principes stricts overkill que je n‚Äôestime pas pertinents ici, avec des gains principalement en concision et lisibilit√©. Le MVVM est tout √† fait indiqu√© pour un cloisonnement minimal, et en l‚Äôoccurence √ßa ressemblait √† √ßa\nAvec des injection par construction et donc cette instanciation initiale :\nlet store = Store(context: moContext) let model = MainViewModel(store: store, router: Router()) return MainView(model: model) On peut remarquer le petit Router qui s‚Äôest av√©r√© fort utile pour √©viter trop de plomberie. Son r√¥le est juste de publier des propri√©t√©s destin√©es √† contr√¥ler et rendre compte de la navigation. Il ne fait donc clairement pas partie du mod√®le ni des vues, et j‚Äôai du mal √† le consid√©rer comme un mod√®le de vue √©tant donn√©e sa nature transverse.\nTant qu‚Äôil ne d√©passe pas ce r√¥le de navigation, ne stocke qu‚Äôun minimum de donn√©es transitoires au besoin (immuables de pr√©f√©rence, la struct d‚Äôune personne √† √©diter par exemple), √ßa reste tr√®s lisible et on √©vite les cha√Ænages de @Published orthodoxes.\nenum ActiveSheet { case attestationPresentation(person: PersonStruct), addPerson, edit(person: PersonStruct) } enum ActiveAlert { case confirmAttestation, detail(reason: Reason) } class Router: ObservableObject { @Published var showSheet = false @Published var showAlert = false private(set) var activeSheet = ActiveSheet.addPerson private(set) var activeAlert = ActiveAlert.confirmAttestation func showAttestationCreationAlert() { activeAlert = .confirmAttestation showAlert = true } func startAddPerson() { activeSheet = .addPerson showSheet = true } func startEdit(person: PersonStruct) { activeSheet = .edit(person: person) showSheet = true } func showReasonDetail(_ reason: Reason) { activeAlert = .detail(reason: reason) showAlert = true } func showAttestationView(person: PersonStruct) { activeSheet = .attestationPresentation(person: person) showSheet = true } func closeSheet() { showSheet = false } } Plut√¥t concis, √ßa vaut clairement le coup plut√¥t que de perdre ces quelques variables dans des chemins trop tortueux.\nTous mes proches le savent, les enums Swift c‚Äôest ma grande passion. Et ceux du petit routeur ci-dessus me permettent de faire des fonctions SwiftUI bien compactes :\nfunc alert() -\u003e Alert { switch vm.router.activeAlert { case .confirmAttestation: return Alert(title: coldFeetTitle, message: coldFeetMessage, primaryButton: .default(Text(\"Je certifie\")) { vm.generateNewAttestation() }, secondaryButton: .cancel(Text(\"Annuler\"))) case .detail(reason: let reason): return Alert(title: Text(reason.niceString), message: Text(reason.detail), dismissButton: .default(Text(\"Ok\"))) } } func sheet() -\u003e AnyView { switch vm.router.activeSheet { case .attestationPresentation(let person): return AnyView(AttestationView(vm: vm.attestationViewModel(person: person))) case .addPerson: return AnyView(AddOrEditPersonSheet(vm: vm.addPersonViewModel)) case .edit(let person): return AnyView(AddOrEditPersonSheet(vm: vm.editPersonViewModel(person: person))) } } Et enfin, le body de ma View principale sera tr√®s concis :\nvar body: some View { NavigationView { VStack(alignment: .center, spacing: 5) { MainListsView(model: vm.mainListsViewModel).environment(\\.editMode, $editMode) BottomMenu(model: vm.bottomMenuViewModel) } .sheet(isPresented: $vm.router.showSheet, onDismiss: { vm.checkShouldShowPinnedAttestation() }, content: sheet) .navigationBarTitle(\"\", displayMode: .inline) .navigationBarItems(leading: navigationBarLeadingItem, trailing: EditButton(editMode: $editMode)) } .alert(isPresented: $vm.router.showAlert, content: alert) } (on peut comprendre d‚Äôailleurs pourquoi je s√©pare le showSheet et showAlert des enums, au lieu de d√©clarer des .none)\nLa vue principale est la principale consommatrice du routeur, cependant de multiples vues viennent agir dessus.\nEvidemment, cette architecture est adapt√©e √† ce projet particulier, ne cherchez pas √† reproduire √ßa √† la maison.\nLes petits trucs p√©nibles Type erasure Ci-dessus, vous pouvez voir que j‚Äôutilise AnyView(...) pour renvoyer un type consistant de View. Pour tous ceux qui ont jou√© un peu en profondeur avec les protocoles et g√©n√©riques en Swift, on atteint vite des obstacles myst√©rieux particuli√®rement brainboiling.\nHeureusement on observe un effort de type erasure dans les biblioth√®ques syst√®me avec ces AnyView, AnyCancellable‚Ä¶\nAinsi que de nouveaux mots cl√© myst√©rieux comme some qui est la r√©ponse directe √† la sentence :\nProtocols ‚ÄòWouldBeSoNice‚Äô can only be used as a generic constraint because it has Self or associated type requirements\nSi √ßa vous int√©resse je vous conseille ce petit article.\nCeci-dit, m√™me si √ßa dispara√Æt vite, je pense que c‚Äôest un frein assez consid√©rable notamment pour des d√©butants.\nObserver des objets imbriqu√©s Un ViewModel en mode Combine doit avoir cette allure :\nclass MyViewModel : ObservableObject { @Published var someProperty = \"Coucou copaing !\" } Le wrapper @Published est tout √† fait adapt√©e aux structs puisque toute mutation d‚Äôune struct est un changement de valeur. Mais les classes si elles sont faites pour √™tre mut√©es ne remonteront point l‚Äô√©v√®nement au wrapper.\nOr pour observer une propri√©t√© imbriqu√©e au deuxi√®me niveau dans SwiftUI, comme .sheet(isPresented: $vm.router.showSheet) {‚Ä¶}, on peut essayer :\nd‚Äôobserver le routeur qui serait une struct et de prendre sa valeur showSheet avec le routeur en ObservableObject, observer directement showSheet Eh bien aucune des deux options ne fonctionne directement depuis une vue SwiftUI. Ce petit $ qui d√©signe la projectedValue d‚Äôune propri√©t√© encapsul√©e par un @Published ou un @State n‚Äôest pas magique, et √ßa ne fonctionne qu‚Äôau premier niveau, c‚Äôest √† dire un @Published propri√©t√© d‚Äôun ObservableObject.\nEt la feinte officielle n‚Äôest pas bien glorieuse :\nclass MyViewModel : ObservableObject { @Published var router = Router private var cancellables = Set\u003cAnyCancellable\u003e() init(router: Router) { self.router = router router.objectWillChange.sink { [weak self] _ in self?.objectWillChange.send() }.store(in: \u0026cancellables) } deinit { cancellables.forEach({ $0.cancel() }) } } Il-y-a des variantes plus concises au prix de sacrifices discutables, mais voil√† le principe. A chaque fois que le routeur va changer, on va propager l‚Äô√©v√®nement pour indiquer √† l‚ÄôUI de se rafra√Æchir. C‚Äôest un peu large, un peu ‚ÄúMario fait du Combine‚Äù, mais ne soyons pas obtus, si √ßa roule apr√®s tout‚Ä¶\nUne bonne alternative est de mettre tout √ßa √† plat dans la vue :\nstruct MyView: View { @ObservedObject private var vm: MainViewModel var body: some View {...} } deviendrait\nstruct MyView: View { @ObservedObject private var vm: MyViewModel @ObservedObject private var router: Router var body: some View {...} } C‚Äôest plus √©l√©gant je trouve, mais imaginons que j‚Äôai 8 entit√©s un peu complexes √† embarquer dans mon VM, √ßa commence alors √† foisonner plus que de raison.\nAutre point en passant, impossible de s√©curiser l‚Äôinstance embarqu√©e du routeur dans le view-model avec un private(set) modifier dans la premi√®re version. C‚Äôest de l‚Äôordre du TOC - c‚Äôest bien d‚Äôen √™tre conscient - mais √ßa me g√®ne üòÖ\nPropager des @Published, Model -\u003e VM -\u003e View class Store : ObservableObject { @Published private(set) var someUrl: URL? } class MyViewModel : ObservableObject { @Published private(set) var someUrl: URL? init(store: Store) { store.$someUrl.assign(to: \u0026$someUrl) } } Mais c‚Äôest tr√®s raisonnable, super ! Oui mais iOS14+ seulement.\nEt voici la version iOS 13 :\nclass Store : ObservableObject { @Published private(set) var someUrl: URL? } class MyViewModel : ObservableObject { @Published private(set) var someUrl: URL? private var cancellables = Set\u003cAnyCancellable\u003e() init(store: Store) { store.$someUrl.sink { [weak self] url in self?.someUrl = url }.store(in: \u0026cancellables) } deinit { cancellables.forEach({ $0.cancel() }) } } * whip sound *\nPas mal hein ?\n* whip sound *\nSink twice silence g√©nant\nQuand on observe un sujet avec sink, sachez que la valeur qui vous est pass√©e en closure est celle qui va √™tre attribu√©e, comme lorsqu‚Äôon utilise willSet sur une propri√©t√© (quelques d√©tails ici).\nPas de probl√®me pour l‚Äôupdate d‚ÄôUI, c‚Äôest fait pour. Mais pour les autres besoins, comme par exemple quand on a des m√©canismes complexes interm√©diaires qui ne se r√©sument pas √† fusionner deux valeurs publi√©es, la meilleure chose √† faire est encore de cr√©er son publisher.\nEt m√™me si j‚Äôaurais encore beaucoup √† dire autour de ce sujet, je r√©serve √† un futur article une petite contribution autour de ce sujet, des property wrappers et consorts.\nN‚Äôh√©sitez pas √† m‚Äô√©crire si vous avez un avis quelconque sur ce que j‚Äôai √©crit, mon email est (?) dans le footer ;)\n","description":"","tags":["iOS","Combine","SwiftUI"],"title":"SwiftUI \u0026 Combine Feedback #1 : architecture et grains de sable","uri":"/posts/swiftui_combine1/"},{"categories":["Application mobile"],"content":"\nIl m‚Äôest arriv√© plusieurs fois d‚Äôoublier mon attestation de sortie (c‚Äôest mal), de la g√©n√©rer au volant en panique (c‚Äôest tr√®s mal), de prendre du retard en tapant le formulaire avant de partir‚Ä¶ Loin de moi l‚Äôid√©e de d√©battre du bien-fond√© du confinement et de ses modalit√©s, cependant j‚Äô√©tais confront√© √† un inconfort mineur. Et comme tout bon ing√©, j‚Äôai cherch√© et √©valu√© des solutions compl√®tement superflues - toutefois avec un indiscutable s√©rieux et un professionnalisme in√©branlable.\nLa voie des anciens Imprimer des attestations pr√©remplies et ne laisser que le motif, la date, l‚Äôheure et la signature √† remplir.\nOui √ßa marche, mais la mat√©rialisation est une contrainte forte. Si on oublie de remplir son attestation (c‚Äôest mal) et qu‚Äôon prend la voiture on n‚Äôa pas de moyen de g√©rer la situation sans un 180¬∞ bien crissant (ce qui est certes classe mais dangereux).\nOn me dit dans l‚Äôoreillette qu‚Äôon peut tout √† fait √©crire une attestation √† la main sur papier libre‚Ä¶ Oui mais bon, change pas de sujet, j‚Äôai pas de stylo ni de papier sur moi, voil√†, et puis niveau ergonomie, c‚Äôest so les mill√©naires pass√©s l‚Äô√©criture‚Ä¶\nLa voie officielle #1 (web) J‚Äôai essay√© de faire avec la page web gouvernementale. Et franchement, c‚Äôest correct sur ordinateur avec le bon √©quipement logiciel. J‚Äôutilise personnellement un navigateur Chromium avec le plugin de mon gestionnaire de mots de passe Dashlane. Le seul inconfort √©vident est la lecture des motifs du d√©placement. J‚Äôai commenc√© √† faire un petit plugin Chrome pour retravailler √ßa avant de me raviser rapidement : les plugins ne fonctionnent pas sur les navigateurs Chromium iOS et la g√©n√©ration sur portable est bien plus pratique.\nLa voie officielle #2 (TousAntiCovid) On monte en qualit√© avec le g√©n√©rateur int√©gr√© √† l‚Äôapplication TousAntiCovid. Il est possible de faire retenir mes coordonn√©es par l‚Äôappli et les motifs ont un titre en gras qui permet d‚Äôy voir un peu plus clair. Cependant je ne suis pas int√©ress√© par la fonctionnalit√© de tra√ßage de cette application. Donc je n‚Äôai pas appr√©ci√© quand j‚Äôai d√ª imp√©rativement autoriser l‚Äôapp √† utiliser le bluetooth √† la premi√®re ouverture. Et puis en regardant √ßa, je commen√ßais √† avoir ma petite id√©e de l‚Äôappli id√©ale donc toutes les petites frictions du parcours pour g√©n√©rer mon autorisation me faisaient tiquer. Ca fait quand m√™me pas mal d‚Äô√©tapes apr√®s ouverture de l‚Äôapplication :\nscroll tout en bas tap sur Attestation de d√©placement tap sur Nouvelle attestation entrer mes donn√©es - ok √ßa s‚Äôenregistre on ne le compte pas tap (optionnel) sur l‚Äôheure pour r√©gler l‚Äôheure de ma sortie - je n‚Äôai jamais touch√© √† la date jusque l√† tap pour choisir le motif de d√©placement (qui ne s‚Äôenregistre pas) sur mon iPhone, il faut 3 hauteurs d‚Äô√©cran pour lire int√©gralement la liste des motifs, on ajoute donc souvent un scroll ou deux tap sur le motif tap sur G√©n√©rer alerte de confirmation : tap sur Je certifie Donc dans le cas id√©al (je pars maintenant, c‚Äôest bien moi qui g√®n√®re l‚Äôattestation et je suis la derni√®re personne √† avoir utilis√© le g√©n√©rateur sur cet appareil, et mon motif est mon caract√®re laborieux) j‚Äôai donc 7 actions avant d‚Äôobtenir le QR Code tant convoit√©. C‚Äôest beaucoup.\nLa voie des ptits malins (app iOS Raccourcis) Certaines bo√Ætes comme Luko ou Newzik vous proposent de g√©n√©rer un lien qui contient vos donn√©es, et qui m√®ne √† un g√©n√©rateur automatique qui affiche l‚Äôattestation g√©n√©r√©e avec l‚Äôheure de sortie actuelle.\nL‚Äôid√©e est notamment d‚Äôutiliser un raccourci d√©clench√© par Siri par exemple pour commander son attestation √† la voix ou encore la faire ouvrir automatiquement d√®s qu‚Äôon quitte son domicile. On n‚Äôest pas loin de la solution id√©ale, seulement je ne peux pas g√©n√©rer une attestation √† la bourre.\nCeci-dit, ce lien est un bon exemple de ce qu‚Äôon peut faire rapidement pour se faciliter la vie. Quelques bookmarks, un peu de configuration et pour les gens pas trop technophobes on s‚Äôen sort.\nL‚Äôapp de mes r√™ves Cahier des charges L‚Äôapp de mes r√™ves\ndans le meilleur des cas, n√©cessite une seule action pour g√©n√©rer une attestation si le motif change, une √† deux actions suppl√©mentaires sont tol√©rables. demande le plus rarement possible des actions suppl√©mentaires. permet √† ma compagne de faire son attestation sur mon t√©l√©phone sans effacer mes donn√©es pr√©remplies g√®re tr√®s efficacement mon cas pathologique d‚Äôoubli. Elle doit donc me permettre de g√©n√©rer mon attestation lorsque je me rends compte apr√®s 20 minutes de trajet que j‚Äôai oubli√© mon attestation : pour √™tre dans les clous, mon heure de sortie doit alors √™tre 20 minutes dans le pass√© n‚Äôembarque aucune autre fonctionnalit√© non souhait√©e n‚Äôenvoie aucune donn√©e √† qui que ce soit (pas de tracking publicitaire ou autre) n‚Äôutilise aucune biblioth√®que tierce non ma√Ætris√©e √† 100% Je me suis auto-d√©fi√©, et au bout d‚Äôune petite journ√©e de d√©veloppement j‚Äôavais un prototype fonctionnel, ce qui m‚Äôa encourag√© √† continuer. Au bout de trois jours de d√©veloppement j‚Äôavais une app pr√©sentable, les aspects l√©gaux √©taient confirm√©s, et la plupart des raffinements majeurs √©taient impl√©ment√©s.\nR√©alisation ! Je suis bien content d‚Äôannoncer que j‚Äôai respect√© *presque* tous les points de l‚Äôapp de mes r√™ves. Seule entorse, comme il faut quand m√™me √™tre un peu s√©rieux, j‚Äôai ajout√© une confirmation de v√©racit√© des donn√©es √† la g√©n√©ration de l‚Äôattestation, on a donc deux actions pour g√©n√©rer l‚Äôattestation.\nTout comme pour la solution de g√©n√©ration par liens, j‚Äôai r√©cup√©r√© le code publi√© par le minist√®re de l‚Äôint√©rieur pour g√©n√©rer les PDFs en inspectant son int√©gralit√©, en extrayant uniquement les parties n√©cessaires, puis en le modifiant pour son int√©gration dans l‚Äôapp.\nJe ne vais pas vous cacher que je n‚Äôaurais pas fait cette application juste pour me faciliter les sorties. Je voulais √©galement exp√©rimenter SwiftUI, la biblioth√®que d√©clarative d‚Äôinterface utilisateur d‚ÄôApple qui me tend les bras depuis plusieurs ann√©es, et c‚Äô√©tait une bonne occasion.\nEt voici le r√©sultat :\nVue principale Ici on peut :\najouter / supprimer / r√©ordonner les personnes s√©lectionner un ou plusieurs motifs de sortie s√©lectionner la date de sortie en temps relatif par rapport √† l‚Äôheure actuelle : les boutons du Stepper (+ / -) ajoutent ou retirent 10 minutes et surtout aller vers l‚Äôattestation ! Vue d‚Äô√©dition de personne Un simple formulaire tout b√™te :)\nPr√©sentation de l‚Äôattestation Tr√®s simple, on peut juste :\npartager le PDF √©pingler l‚Äôattestation : dans ce cas la pr√©sentation en carte ne se laisse pas fermer comme d‚Äôhabitude par swipe vertical, la croix de fermeture dispara√Æt, et au cas o√π l‚Äôutilisateur ferme l‚Äôapp, l‚Äôattestation sera restaur√©e √† la r√©ouverture Temps de g√©n√©ration de l‚Äôattestation : 3s Dans mon usage quotidien, avec ma (vraie) identit√© de remplie, je mets environ 3s √† remplir mon attestation entre l‚Äôouverture de l‚Äôapp, le choix ou la v√©rification du motif et le r√©glage ou la v√©rification de l‚Äôheure. Oui je suis lent, mais mon objectif est atteint, je peux sans risque g√©n√©rer mon attestation dans des situation d‚Äôurgence et d‚Äôoubli \\o/\nApp Store ? Eh bien malgr√© ma gestion parano√Øaque des donn√©es utilisateur, il semble que ce ne soit pas suffisant pour Apple qui (je pense) n‚Äôautorise simplement aucune app avec cette fonctionnalit√© sauf celle du gouvernement.\nWe found in our review that your app provides services or requires sensitive user information related to the COVID-19 pandemic. Since the COVID-19 pandemic is a public health crisis, services and information related to it are considered to be part of the healthcare industry. In addition, the seller and company names associated with your app are not from a recognized institution, such as a governmental entity, hospital, insurance company, non-governmental organization, or university.\nPer section 5.1.1 (ix) of the App Store Review Guidelines, apps that provide services or collect sensitive user information in highly-regulated fields, such as healthcare, should be submitted by a legal entity that provides these services, and not by an individual developer.\nJ‚Äôai √©videmment fait appel mais je ne pense pas qu‚Äôils c√®deront, tant pis, je ne partagerai donc mon app qu‚Äôavec mes proches (du moins ceux qui poss√®dent un iPhone) !\nD√©veloppement : retour d‚ÄôXP SwiftUI + Combine Tout d‚Äôabord SwiftUI est tr√®s agr√©able √† utiliser. On a √©videmment les traditionnelles errances de XCode 12, que ce soit niveau compilation, compl√©tion, aper√ßu de l‚ÄôUI‚Ä¶ Mais il convient de saluer la prouesse qu‚Äôest l‚Äôimpl√©mentation de ce framework, un tr√®s bon exemple de DSL sur Swift, qui s‚Äôy pr√™te particuli√®rement bien.\n1struct AddEditPersonSheet: View { 2 3\t// Local state 4 @State 5 private var tappedOkButton = false 6\t7\t// The ViewModel data and callbacks / Yeah I should have created a struct for this 8 @Binding 9 var editingPerson: EditingPerson 10 let isCreation: Bool 11 var cancelAddPerson: () -\u003e Void 12 var endAddOrEditPerson: () -\u003e Void 13 14\t// No constructor (structs are cool) 15\t16 private var title: String { 17 isCreation ? \"Cr√©er\" : \"Modifier\" 18 } 19 20 private func isEmpty(_ str: String) -\u003e Bool { 21 str.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty 22 } 23 24 var body: some View { 25 NavigationView { 26 Form {ss 27 Section(header: Text(\"Identit√©\")) { 28 if tappedOkButton \u0026\u0026 isEmpty(editingPerson.firstName) { 29 Text(\"Pr√©nom manquant\").foregroundColor(.red) 30 } 31 TextField(\"Pr√©nom\", text: $editingPerson.firstName).textContentType(.givenName) 32 if tappedOkButton \u0026\u0026 isEmpty(editingPerson.lastName) { 33 Text(\"Nom manquant\").foregroundColor(.red) 34 } 35 TextField(\"Nom\", text: $editingPerson.lastName).textContentType(.familyName) 36 } 37 // ... other sections 38 } 39 .navigationBarItems(leading: Button(action: cancelAddPerson) { 40 Text(\"Annuler\") 41 }, trailing: Button(action: { 42 withAnimation { 43 tappedOkButton = true 44 if (editingPerson.isValid) { 45 endAddOrEditPerson() 46 } 47 } 48 }) { 49 Text(\"Enregistrer\") 50 }.disabled(tappedOkButton \u0026\u0026 editingPerson.isValid)) 51 .navigationBarTitle(Text(title), displayMode: .inline) 52 } 53 } 54} Pas de critiques les puristes, j‚Äôai fait du monolingue et du gros inline volontairement.\nD√©veloppement rapide : Gr√¢ce √† cette approche DSL, on se retrouve avec du code √† l‚Äôimbrication proche de l‚ÄôUI, facilement intelligible, avec de tr√®s bons comportements par d√©faut. Comme c‚Äô√©tait mon premier test j‚Äôai forc√©ment un peu ram√©, mais j‚Äôaurais pris bien plus de 3 jours de d√©veloppement pour une petite app compl√®te, fonctionnelle et propre si j‚Äôavais d√ª rapprendre UIKit ou pire : HTML + CSS.\nLe couplage avec Combine permet de s‚Äôengager sur le chemin des state-driven apps. Pour avoir pas mal jou√© avec React + Redux, je ne peux que vous inciter √† adopter ce paradigme. Evidemment, quand on n‚Äôa jamais fait que de la programmation imp√©rative, beaucoup de petites choses peuvent √™tre frustrantes au premier abord. Mais √ßa d√©graisse tellement ! Et pour ceux qui ont d√©j√† eu des interrogations philosophiques sur les architectures logicielles en iOS - entre MVC = Massive View Controller par exemple) et le trop souvent overkill VIPER -, SwiftUI + Combine incitent tr√®s naturellement √† d√©rouler le code en MVVM, apportant enfin une alternative moderne et structurante.\nRIP UIKit ? : Bien s√ªr que non, SwiftUI est principalement une surcouche d‚ÄôUIKit qui a encore de beaux jours devant lui. On peut d‚Äôailleurs palier assez facilement l‚Äôabsence de nombreux composants essentiels de SwiftUI en encapsulant une UIView, comme j‚Äôai d√ª le faire pour le lecteur PDF et la webview qui appelle le code de g√©n√©ration du document PDF.\nC‚Äôest tout, ce fut un bon petit d√©fi sympa et enrichissant !\nJ‚Äôesp√®re avoir l‚Äôoccasion de r√©crire sur Swift qui reste un de mes langages pr√©f√©r√©s, mais pour le moment je replonge dans mes projets TypeScript qui se positionne franchement pas mal non plus et a l‚Äôavantage d‚Äô√™tre largement adopt√© en dehors du petit monde Apple.\n","description":"","tags":["iOS","Combine","SwiftUI","confinement","covid"],"title":"Attestation 2s iOS","uri":"/posts/attestation-ios/"},{"categories":null,"content":"","description":"","tags":null,"title":"confinement","uri":"/tags/confinement/"},{"categories":null,"content":"","description":"","tags":null,"title":"covid","uri":"/tags/covid/"},{"categories":null,"content":"Merci de patienter un instant‚Ä¶\n","description":"","tags":null,"title":"Redirection vers la salle de r√©union","uri":"/visio/"}]

[{"categories":["Game Theory"],"content":"Résumé des épisodes précédents:\n En théorie des jeux, les fonctions d’évaluation permettent d’évaluer des situations, de les comparer, et donc de faire des choix renseignés l’Independent Chip Model (ICM) est la fonction d’évaluation de référence pour les tournois de poker, et on cherche à trouver mieux, notamment pour un grand nombre de joueurs l’ICM est long à calculer pour un grand nombre de joueurs. Après pas mal d’optimisations, on a des temps humainement raisonnables pour une vingtaine de joueurs payés maximum. Si on veut utiliser l’ICM de manière intensive comme dans une simulation de tournoi, il faudra viser plutôt autour de dix joueurs payés.  Du coup©™ peut-on obtenir des valeurs correctes pour un plus grand nombre de joueurs ?\nMonte-Carlo : le tâtonnement convergent Une méthode commune d’approximation de valeur est la méthode de Monte-Carlo (MC). On va évaluer différents points d’une fonction complexe choisis aléatoirement pour déduire une approximation probabiliste de sa moyenne. En l’occurence pour l’ICM on peut typiquement essayer de tirer aléatoirement le classement des joueurs selon les hypothèses de l’ICM ce qui n’est somme-toute pas évident.\nNaïvement on devrait tirer le premier joueur classé selon une probabilité proportionnelle à son stack, puis le second parmi les joueurs restants et les stacks restants et ainsi de suite. Autant vous dire qu’on ne va pas bien loin avec ça car la complexité est alors assez violente : pour chaque tirage on doit calculer la distribution de probabilité et effectuer un tirage, ce qui au minimum va nous mener sur du O(n2) pour un tirage, et il en faut pas mal.\nHeureusement des gens ont réfléchi, et notamment le développeur d’IA Tysen Streib qui a beaucoup contribué à l’analyse stratégique au poker (il a co-écrit Kill everyone notamment). Il a donc très justement analysé en 2011 qu’il était possible d’effectuer un tirage de la sorte en tirant aléatoirement la durée de vie de chaque joueur selon uniform_random[O:1]1/stack, puis en ordonnant les durées de vie pour obtenir l’ordre de classement des joueurs.\nJe vous recommande fortement la lecture de son post original ici et du thread qui suit, où l’algorithme tant que les raisons de la convergence sont bien expliqués, à un niveau intuitif, avec une interprétation théorique et même des optimisations.\nImplémentation Les gros points de consommation de CPU sont :\n le tirage aléatoire le calcul de puissance le tri  Comme suggéré dans le fil du post, on obtient de meilleures performance en utilisant le logarithme de la formule de tirage, log est strictement croissant donc l’ordre reste le même.\nPour le tirage aléatoire, on a besoin d’un aléatoire statistique correct mais sans qualité cryptographique particulière. On gagne pas mal en utilisant SFMT, une variante de l’algorithme de Mersenne-Twister plus rapide sur les microprocesseurs modernes.\nEnfin pour le tri il faut noter que selon la distribution des prix, on peut éventuellement chercher à classer les premiers joueurs pour les places ayant un prix non-nul. Ce n’est pas une optimisation systématique mais lorsqu’elle est pertinente il serait dommage de l’ignorer.\nVoici une version directe, sans autre optimisation.\n#include \"monte-carlo-icm.hpp\"#include \u003crandom\u003e#include \u003cunordered_map\u003e#include \u003csfmt.hpp\u003e /** * Compute a permutation according to the sorting of random values put to the power of given weights. * In fact, logarithm is used for performance, and logarithm tables could certainly be used to fasten the * computation. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param dist random distribution * @param mt SFMT (fast Mersenne-Twister algorithm) */ void monteCarloPermutation(const double *weights, int *destination, const int size, uniform_real_distribution\u003cdouble\u003e \u0026dist, wtl::sfmt19937 \u0026mt) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(dist(mt)) * weights[i]; destination[i] = i; } sort(destination, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order  return (draw[a] \u003e draw[b]); } ); } /** * Same as `monteCarloPermutation` except the sorting process stops for performance * after the first values are sorted. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param nbRelevant number of top values that should be strictly sorted. The other ones may not be sorted * according to the random draw. * @param dist random distribution * @param mt SFMT (fast Mersenne-Twister algorithm) */ void monteCarloPermutationPartial(const double *weights, int *destination, const int size, const int nbRelevant, uniform_real_distribution\u003cdouble\u003e \u0026dist, wtl::sfmt19937 \u0026mt) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(dist(mt)) * weights[i]; destination[i] = i; } partial_sort(destination, destination + nbRelevant, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order  return (draw[a] \u003e draw[b]); } ); } int firstZeroPayout(vector\u003cdouble\u003e payouts) { const int size = payouts.size(); int firstZeroPayout = -1; for (int i = 0; i \u003c size; ++i) { if (firstZeroPayout \u003c 0) { if (payouts[i] == 0) { firstZeroPayout = i; } } else if (payouts[i] != 0) { firstZeroPayout = -1; } } return firstZeroPayout; } /** * Monte-Carlo ICM Ranking algorithm. * * @param stacks * @param payouts * @param trials * @param relevantRanksCount * @param results array of ICM EV */ void monteCarloIcm(const double *stacks, const double *payouts, const int nbPlayers, const long trials, const int relevantRanksCount, double *results) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/  // Initialize random distribution  // https://stackoverflow.com/questions/19665818/generate-random-numbers-using-c11-random-library  // SFMT variant  random_device rd; wtl::sfmt19937 mt(rd()); uniform_real_distribution\u003cdouble\u003e dist(0, 1); int permutation[nbPlayers]; const double stacksAvg = accumulate(stacks, stacks + nbPlayers, 0.) / (double) nbPlayers; double weights[nbPlayers]; double contrib[nbPlayers]; // - Normalize stacks (not really necessary but cheap) and invert to weights  // - Prepare each trial ranking contribution to the total  for (int i = 0; i \u003c nbPlayers; i++) { weights[i] = stacksAvg / stacks[i]; contrib[i] = payouts[i] / trials; } // Partial sort vs sort : interesting only if we have many zero payouts at the end  const float partialSortThreshold = 0.2; // Magic number \u003c3  const bool partialSort = relevantRanksCount \u003e= 1 \u0026\u0026 ((float) relevantRanksCount / (float) nbPlayers \u003c= partialSortThreshold); for (long i = 0; i \u003c trials; i++) { // Draw a permutation  if (partialSort) { monteCarloPermutationPartial(weights, permutation, nbPlayers, relevantRanksCount, dist, mt); } else { monteCarloPermutation(weights, permutation, nbPlayers, dist, mt); } // Cumulate payouts according to the random permutation  for (int j = 0; j \u003c nbPlayers; j++) { results[permutation[j]] += contrib[j]; } } } /** * Vector wrapper of MC ICM * @param stacks * @param payouts * @param trials * @return ICM EV */ vector\u003cdouble\u003e monteCarloIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts, const long trials) { const int nbPlayers = stacks.size(); const int relevantRanksCount = firstZeroPayout(payouts); vector\u003cdouble\u003e results(nbPlayers); double stacksArray[nbPlayers]; double payoutsArray[nbPlayers]; double resultsArray[nbPlayers]; for (int i = 0; i \u003c nbPlayers; ++i) { stacksArray[i] = stacks[i]; payoutsArray[i] = payouts[i]; resultsArray[i] = 0;s } monteCarloIcm(stacksArray, payoutsArray, nbPlayers, trials, relevantRanksCount, resultsArray); for (int i = 0; i \u003c nbPlayers; i++) { results[i] = resultsArray[i]; } return results; } Autres pistes d’optimisation Voici quelques optimisations que j’imagine pertinentes :\n l’échantillonnage préférentiel : plus d’échantillons pour les cas les plus probables. On pourrait par exemple fixer successivement chaque joueur premier du classement, et estimer ce cas avec plus ou moins de précision par exemple avec un nombre d’échantillon proportionnel à sa probabilité au carré (la contribution de chaque cas restant proportionnelle au stack du joueur bien sûr). Pourquoi pas aller un ou plusieurs crans plus loin en envisageant toutes les combinaisons des k premiers joueurs. le quasi-Monte-Carlo, une répartition plus homogène peut apporter une convergence plus rapide pour le tri et pour les très grands nombre de joueurs, comme les payouts sont souvent par palliers, utiliser quand c’est pertinent une succession de tris partiels par palier (plus précisément des algorithmes de sélection).  Si vous explorez ces optimisations (ou d’autres), faites-m’en part, je suis curieux !\nConvergence On sait qu’on a une convergence en O(1/sqrt(n)) (note : ajouter une extension LateX à mon site builder). Mais ça ne nous dit pas quand il faut arrêter l’échantillonnage ! Par le passé j’utilisais de petits algos observant la variation sur des lots de puissances de deux d’échantillons, ce qui n’est pas fiable : on peut avoir une convergence très lente, et un fort ralentissement ne permet pas de conclure en une précision donnée. “En pratique, ça marche” oui, enfin peut-être, mais ce n’est pas forcément beaucoup plus dur d’implémenter des garanties statistiques sûres.\nAprès quelques recherches j’ai trouvé une méthode assez générique dans ce (vieux) papier1. Le calcul se base sur un plafond en dessous duquel la variance d’un échantillon satisfait une garantie statistique : avec une probabilité α, la moyenne de l’échantillon est dans l’intervalle de confiance de taille d autour de la moyenne à la limite.\nJ’ai donc réorganisé un peu mon code pour l’implémenter. Le coût du calcul étant assez élevé, il convient de ne pas l’appliquer à chaque étape de l’échantillonage, mais plutôt régulièrement, tous les 100 échantillons par exemple. De plus, j’ai extrait les définitions du RNG (pour un futur quasi-Monte-Carlo) et du tri (pour un futur tri partiel par palliers) histoire de pouvoir plus facilement implémenter d’autres versions de l’algorithme - voir le code en fin d’article.\nUn point important à considérer est que la variance d’un calcul d’ICM par la méthode de Monte-Carlo dépend fortement de la distribution des stacks des joueurs et de celle des prix. En effet, pour prendre un extrême, si tous les prix sont égaux la variance est simplement nulle. On va évidemment souhaiter éviter le coût de calcul de cette stopping rule si on en opère en nombre, mais il faudra être prudent pour garder des garanties correctes. De plus, la taille d de l’intervalle de confiance est liée linéairement aux prix. Si on distribue deux fois plus de prix aux joueurs, pour une même précision relative on devra multiplier d par deux. L’idéal est alors d’exprimer d en fonction d’une grandeur pertinente comme la somme des prix distribués et d’en tenir compte lors du traitement d’échantillons variés pour au moins connaître la précision des résultats calculés.\nSi les échantillons sont assez homogènes, on pourra par exemple faire une petite tambouille comme calculer le nombre d’itérations nécessaires sur un petit ensemble de situations extraites du paquet à traiter, prendre le maximum et le multiplier par deux pour traiter tout le paquet (à vue de nez, “en pratique, ça marche”).\nPerformance Je me suis intéressé au cas de 50 joueurs, les 40 premiers étant payés. Pour construire la structure de prix, j’ai notamment lu cette présentation qui m’a encouragé à utiliser une power law fall-off (une chute de loi de puissance..?) telle que le joueur au rang i obtienne un prix proportionnel à 1 / pow(i, a). J’ai négligé les étapes d’humanisation car je suspecte qu’au mieux elles font baisser la variance en créant des plateaux. Soyons-donc joyeusement pessimistes !\nJ’ai ensuite pris une distribution de stacks aléatoires selon une loi normale tronquée. Je ne pense pas que c’est vraiment représentatif d’une situation particulière, les distributions de stack sont assez difficiles à modéliser. Enfin pour le moment ça suffira, on cherche juste à connaître la performance de notre algorithme.\nDans ces circonstances, l’évaluation de la stopping rule pour une probabilité de 0.9 avec un intervalle de confiance de taille 1 (sachant que la somme des prix vaut 1000) me donne de manière assez stable une taille d’échantillon de 15500.\nEt une fois débarrassés de cette évaluation, le calcul prend 27ms pour une moyenne sur 15500 échantillons. C’est très raisonnable en soi, mais si j’envisage de simuler quelques milliers de tournois comportant des milliers de mains elles-mêmes incluant plusieurs calculs d’ICM, ce ne sera pas suffisant. Damned.\nMais j’ai une idée un peu taquine pour résoudre ça…\nNext step Tout ça pour… pour quoi déjà ? Pour défier l’ICM, parce qu’on se demande s’il n’y a pas mieux, et sinon pour se convaincre que c’est une bonne approximation.\nJe pense qu’on pourrait déjà aller vers des simulations intéressantes avec un nombre réduit de joueurs pour mettre en évidence certains comportements. Mais je suis sur une bonne lancée, on va pas s’arrêter en si bon chemin !\nCe sera donc pour mon prochain article, en attendant n’hésitez pas à me contacter pour toute critique ou discussion via mon email en pied de page !\nBonus : le code Tout d’abord on a besoin d’une fonction qui n’existe pas dans les bibliothèques standard : norminv qui permet de déterminer pour quelle abscisse on obtient à gauche une certaine fraction de la population d’une distribution normale unitaire centrée en 0.\nUn certain John D. Cook l’a fait pour nous, on va donc utiliser son code.\nutil/math.cpp\nCollez le code de cette page https://www.johndcook.com/blog/cpp_phi_inverse/\nutil/math.hpp\n#ifndef MTT_EXPERIMENTS_C_MATH_HPP #define MTT_EXPERIMENTS_C_MATH_HPP double NormalCDFInverse(double p); #endif //MTT_EXPERIMENTS_C_MATH_HPP monte-carlo-icm.cpp\n#include \"monte-carlo-icm.hpp\"#include \u003crandom\u003e#include \u003csfmt.hpp\u003e#include \u003cutil/math.hpp\u003e using namespace std; namespace icm { /** * The Random Number Generator type : functions denoted by this alias are expected to draw doubles between 0 and 1. * Abstracted in order to plug a proper RNG for quasi-Monte-Carlo in the future. */ using RNG = std::function\u003cdouble()\u003e; /** * The sorter functions are expected to sort the indexes of the draw array in reverse order according to the values * of the array. */ using Sorter = std::function\u003cvoid(double *draw, int *destination, int size)\u003e; /** * Private section */ namespace { /** * Compute a permutation according to the sorting of random values put to the power of given weights. * In fact, logarithm is used for performance, and logarithm tables could certainly be used to fasten the * computation. * * @param weights * @param destination where the permutation will be written to * @param size size of weights and destination array * @param rng random number generator * @param sorter function to sort the permutation */ void monteCarloPermutation(const double *weights, int *destination, const int size, const RNG \u0026rng, const Sorter \u0026sorter) { double draw[size]; for (int i = 0; i \u003c size; i++) { draw[i] = log2(rng()) * weights[i]; destination[i] = i; } sorter(draw, destination, size); } /** * Get the index of the first zero payout after which all payouts are zero as well * @param payouts the payouts array * @param size the size of the array * @return the index of the first zero payout */ int firstZeroPayout(const double *payouts, int size) { int firstZeroPayout = -1; for (int i = 0; i \u003c size; ++i) { if (firstZeroPayout \u003c 0) { if (payouts[i] == 0) { firstZeroPayout = i; } } else if (payouts[i] != 0) { firstZeroPayout = -1; } } return firstZeroPayout; } /** * Compute the mean of a batch of samples * @param samples the samples * @param nbPlayers the size of each sample aka the number of players * @return a vector containing the mean of the samples */ vector\u003cdouble\u003e mean(vector\u003cdouble *\u003e samples, const int nbPlayers) { const long long nbSamples = samples.size(); vector\u003cdouble\u003e result(nbPlayers, 0); for (int i = 0; i \u003c nbSamples; i++) { double *sample = samples[i]; for (int j = 0; j \u003c nbPlayers; ++j) { result[j] += sample[j]; } } for (int i = 0; i \u003c nbPlayers; ++i) { result[i] /= (double) nbSamples; } return result; } /** * Compute the variance of samples * @param samples the samples * @param nbPlayers the size of each sample aka the number of players * @return the variance */ double variance(vector\u003cdouble *\u003e samples, const int nbPlayers) { const long long nbSamples = samples.size(); vector\u003cdouble\u003e meanSample = mean(samples, nbPlayers); double result = 0; for (int i = 0; i \u003c nbSamples; i++) { double *sample = samples[i]; for (int j = 0; j \u003c nbPlayers; ++j) { double diff = sample[j] - meanSample[j]; result += diff * diff; } } // Not sure about nbSamples - 1, should be nbSamples but the paper about the stopping rule states n-1...  return result / (double) (nbSamples - 1); } /** * Compute the threshold for the variance under which the stopping limit is considered reached * @param alphaProbability confidence probability * @param confidenceIntervalLength confidence interval length (root mean square) * @param nbSamples number of samples * @return the variance threshold */ double stoppingRuleLimit(double alphaProbability, double confidenceIntervalLength, long long nbSamples) { double zAlpha = NormalCDFInverse(alphaProbability + (1 - alphaProbability) / 2); // Symmetrical distribution  return (double)nbSamples * confidenceIntervalLength * confidenceIntervalLength / zAlpha; } /** * Pick the appropriate sorter depending on payouts. We can use a partial sort if most of the payouts are zero * @param payouts the payouts * @param nbPlayers the size of the payouts array aka the number of players * @return a sorter */ Sorter chooseSorter(const double *payouts, int nbPlayers) { // Partial sort vs sort : interesting only if we have many zero payouts at the end  const int relevantRanksCount = firstZeroPayout(payouts, nbPlayers); const float partialSortThreshold = 0.2; // Magic number \u003c3  const bool partialSort = (float) relevantRanksCount / (float) nbPlayers \u003c= partialSortThreshold; if (partialSort) { return [=](const double *draw, int *destination, int size) { partial_sort(destination, destination + relevantRanksCount, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order  return (draw[a] \u003e draw[b]); } ); }; } return [](const double *draw, int *destination, int size) { sort(destination, destination + size, [\u0026](const int \u0026a, const int \u0026b) { // Reverse order  return (draw[a] \u003e draw[b]); }); }; } /** * Create a RNG instance (using SFMT) * @return a RNG instance */ RNG defaultRng() { // Initialize random distribution  // https://stackoverflow.com/questions/19665818/generate-random-numbers-using-c11-random-library  // SFMT variant  random_device rd; wtl::sfmt19937 mt(rd()); shared_ptr\u003cwtl::sfmt19937\u003e mtPtr = std::make_shared\u003cwtl::sfmt19937\u003e(mt); uniform_real_distribution\u003cdouble\u003e dist(0, 1); return [mtPtr = make_shared\u003cwtl::sfmt19937\u003e(mt), distPtr = make_shared\u003cuniform_real_distribution\u003cdouble\u003e\u003e(dist)]() -\u003e double { return (*distPtr)((*mtPtr)); }; } /** * Check if we can stop the trials according to the confidence probability and interval * @param alphaProbability the confidence probability * @param confidenceIntervalLength confidence interval length (root mean square) * @param samples the samples * @param nbPlayers the number of players * @return true if the stopping rule criteria are met */ bool canStop(const double alphaProbability, const double confidenceIntervalLength, const vector\u003cdouble *\u003e \u0026samples, const int nbPlayers) { const long long nbSamples = samples.size(); if (nbSamples \u003c 2) { return false; } double limit = stoppingRuleLimit(alphaProbability, confidenceIntervalLength, nbSamples); return variance(samples, nbPlayers) \u003c= limit; } /** * Normalize stacks (not really necessary but cheap) and invert to weights * @param stacks the stacks * @param nbPlayers the number of players * @param weights the destination array */ void fillWeights(const double *stacks, int nbPlayers, double *weights) { const double stacksAvg = accumulate(stacks, stacks + nbPlayers, 0.) / (double) nbPlayers; for (int i = 0; i \u003c nbPlayers; i++) { weights[i] = stacksAvg / stacks[i]; } } } /** * Perform one MC trial * * @param results destination array to add trial contribution into * @param payouts the contribution to add to the results per rank * @param weights something proportional to the inverse of the stacks of the players * @param permutation an array that will be used to store the permutation (permutation[i] = player that reaches rank i) * @param nbPlayers the number of players * @param rng random number generator * @param sorter function to sort the permutation */ void monteCarloIcmTrial(double *results, const double *payouts, double *weights, int *permutation, int nbPlayers, const RNG \u0026rng, const Sorter \u0026sorter) { monteCarloPermutation(weights, permutation, nbPlayers, rng, sorter); // Cumulate payouts according to the random permutation  for (int j = 0; j \u003c nbPlayers; j++) { results[permutation[j]] += payouts[j]; } } /** * Monte-Carlo ICM Ranking algorithm. * * @param stacks the stacks * @param payouts the payouts * @param nbPlayers the number of players * @param trials the number of trials to perform * @param results destination array for ICM EV */ void monteCarloIcm(const double *stacks, const double *payouts, const int nbPlayers, const long long trials, double *results) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/  RNG rng = defaultRng(); int permutation[nbPlayers]; double weights[nbPlayers]; fillWeights(stacks, nbPlayers, weights); double contrib[nbPlayers]; // Prepare each trial ranking contribution to the total  for (int i = 0; i \u003c nbPlayers; i++) { contrib[i] = payouts[i] / (double) trials; } const Sorter sorter = chooseSorter(payouts, nbPlayers); for (long i = 0; i \u003c trials; i++) { monteCarloIcmTrial(results, contrib, weights, permutation, nbPlayers, rng, sorter); } } /** * Monte-Carlo ICM Ranking algorithm with stopping rule. * * @param stacks the stacks * @param payouts the payouts * @param nbPlayers the number of players * @param results destination array for ICM EV * @param stoppingAlphaProbability the confidence probability * @param stoppingConfidenceIntervalLength confidence interval length (root mean square) * @param stoppingEvalLag the number of trials that are performed before each evaluation of the stopping rule */ long long monteCarloIcmWithStoppingRule(const double *stacks, const double *payouts, const int nbPlayers, double *results, const double stoppingAlphaProbability, const double stoppingConfidenceIntervalLength, long long stoppingEvalLag) { // Algorithm : https://forumserver.twoplustwo.com/15/poker-theory/new-algorithm-calculate-icm-large-tournaments-1098489/  // Stopping rule : http://www.lib.ncsu.edu/resolver/1840.4/5244 (first method for independent samples)  RNG rng = defaultRng(); int permutation[nbPlayers]; double weights[nbPlayers]; fillWeights(stacks, nbPlayers, weights); // For each trial we'll contribute the real payouts because we want to use them for the stopping rule  // computation  const Sorter sorter = chooseSorter(payouts, nbPlayers); vector\u003cdouble *\u003e samples; vector\u003cdouble *\u003e allocated; long long count = 0; while (true) { // While we don't stop according to the stopping rule, we create a batch of samples  auto *memory = (double *) calloc(nbPlayers * stoppingEvalLag, sizeof(double)); // Store the allocated memory area pointer  allocated.push_back(memory); for (long i = 0; i \u003c stoppingEvalLag; i++) { double *sampleMemory = memory + i * nbPlayers; monteCarloIcmTrial(sampleMemory, const_cast\u003cdouble *\u003e(payouts), weights, permutation, nbPlayers, rng, sorter); // Store the pointer to the sample  samples.push_back(sampleMemory); } count += stoppingEvalLag; // Break if the stopping rule says it's enough  if (canStop(stoppingAlphaProbability, stoppingConfidenceIntervalLength, samples, nbPlayers)) { break; } } // Sum the samples  for (double *sample : samples) { for (int i = 0; i \u003c nbPlayers; i++) { results[i] += sample[i]; } } // Divide the sum to get the mean  for (int i = 0; i \u003c nbPlayers; i++) { results[i] /= (double) count; } // Free the allocated memory areas  for (double *memory : allocated) { free(memory); } // Return the number of samples that were generated  return count; } } monte-carlo-icm.hpp Déclarez les fonctions qu’il vous intéresse d’exposer !\n  A Brief Survey of Stopping Rules in Monte Carlo Simulations, 1968, Gilman - https://repository.lib.ncsu.edu/handle/1840.4/5244 ↩︎\n   ","description":"Un Monaco-Picon s’il vous plaît. En pinte.","tags":["Poker","AI","ICM","MTT","Game Theory","Monte Carlo"],"title":"Poker : MTT et ICM - Méthode de Monte-Carlo","uri":"/posts/poker_mtt_icm_montecarlo/"},{"categories":["Game Theory"],"content":"Dans mon précédent billet, je vous parlais des fonctions d’évaluation en théorie des jeux, plus particulièrement dans les tournois de poker No-Limit Hold’Em (NLHE), et spécifiquement de l’Independent Chip Model (ICM).\nPour rappel une fonction d’évaluation donne une estimation probabiliste des gains de chaque joueur en fonction de l’état du jeu. L’ICM utilise la taille des stacks des joueurs pour évaluer leurs chances d’atteindre chaque rang dans le classement final du tournoi. Ces probabilités multipliées par les prix de chaque rangs donnent une espérance de gain en monnaie sonnante et trébuchante qui permettra aux joueurs de prendre des décisions selon les issues possibles de ses actions.\nCalcul de l’ICM L’ICM suppose que la probabilité pour chaque joueur d’accéder à la première place est égale à la proportion représentée par son stack sur la totalité des jetons en jeu (la somme des stacks). Récursivement la probabilité pour un joueur A d’accéder à la seconde place va être une somme pour chaque autre joueur B en première place.\nSA = stack du joueur A SB = stack du joueur B P2A = probabilité du joueur A d'accéder à la seconde place, initialisé à 0 Pour chaque autre joueur B: P1B = probabilité du joueur B d'être premier = SB / Somme des stacks P2A_sachant_1B = probabilité du joueur considéré d'accéder à la seconde place quand le joueur B accède à la première place P2A_sachant_1B = SA / (Somme des stacks - SB) P2A = P2A + P1B x P2A_sachant_1B Pour calculer le tableau de valeurs de l’ICM en fonction des stacks et des prix (payouts) on pourrait écrire un algorithme de ce type :\npayouts = [Q1, Q2, Q3, ...] : prix pour la première, deuxième, troisième.. place. résultat = [RA, RB, RC, ...] : tableau des résultats, avec chaque valeur initialisée à 0 pour tout classement possible des joueurs : (prenons le classement (A, B, C...) pour l'exemple) p = probabilité de ce classement = P1A x P2B_sachant_1A x P3C_sachant_1A_et_2B x ... RA = RA + p x Q1 RB = RB + p x Q2 RC = RC + p x Q3 ... Voici un bout de code python naïf qui fait ça :\nfrom itertools import permutations import numpy as np def icm_proba(permutation, stacks: np.ndarray, stacks_sum: int): result = 1 for rank, player in enumerate(permutation): stack = stacks[player] result *= stack / stacks_sum stacks_sum -= stack return result def icm(stacks: np.ndarray, payouts: np.ndarray) -\u003e np.ndarray: if len(stacks) == 0: return np.array([]) nb_stacks = len(stacks) stacks_sum = sum(stacks) result = np.zeros((nb_stacks,)) for permutation in permutations(range(nb_stacks)): probability = icm_proba(permutation, stacks, stacks_sum) for rank, player in enumerate(permutation): result[player] += probability * payouts[rank] return result if __name__ == '__main__': val = icm(np.array([500, 300, 200]), np.array([600, 400, 0])) print(val) Output :\n[435.71428571 330. 234.28571429] On note la finesse du formattage\nComplexité Prendre tout classement possible de N joueurs, c’est ce qu’on appelle une permutation ou encore un arrangement. Et on calcule très facilement combien il existe d’arrangement pour un nombre donné de joueurs :\n1 : 1 (ben oui) 2 : 2 x 1 = 2 (juré ça change après) 3 : 3 x 2 x 1 = 6 4 : 4 x 3 x 2 x 1 = 24 5 : 5 x 4 x 3 x 2 x 1 = 120 C’est la factorielle, et on peut voir que ça croit très rapidement (plus vite qu’une exponentielle). Si on code ça comme ça on obtient une complexité tellement violente qu’il est difficile de calculer l’ICM au delà de 10 joueurs dans un temps raisonnable.\nPar exemple avec le code ci-dessus j’ai obtenu ces temps :\n3.695487976074219e-05 seconds for 2 players 2.8848648071289062e-05 seconds for 3 players 8.177757263183594e-05 seconds for 4 players 0.0006070137023925781 seconds for 5 players 0.0037360191345214844 seconds for 6 players 0.027889013290405273 seconds for 7 players 0.24523401260375977 seconds for 8 players 2.2415449619293213 seconds for 9 players 23.641671180725098 seconds for 10 players Je vous rappelle qu’à l’origine, je m’intéresse à l’ICM en tournoi multi-table. C’est à dire dans des tournois où le nombre de joueur est entre dix et… quelques milliers.\nDe plus, quand je regarde par exemple sur HoldemRessources, leur calculateur me répond en environ 200ms pour une vingtaine de joueurs. Même si ils ont mis un serveur très performant, on est dans des ordres de grandeur très lointains. On peut faire beaucoup mieux.\nPremière optimisation : passer en récursif et en C++ Eh oui car le Python n’est rapide que quand il appelle des bibliothèques compilées. Faisons-donc la notre ! Et j’en profite pour faire une version récursive de l’algorithme qui va nous économiser pas mal de multiplications pour le calcul de probabilité. En effet, on regroupe toutes les permutations pour lesquelles le premier joueur dans le classement est le joueur d’index 0 dans les stacks par exemple, mais voyez plutôt ci-dessous.\nAu premier appel, la fonction recursiveNaiveIcm va énumérer tous les joueurs possibles en première place. Pour chacun, elle va s’appeler elle-même pour la seconde place, etc.\nvoid recursiveNaiveIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts, vector\u003cdouble\u003e \u0026result, vector\u003cbool\u003e \u0026usedPlayers, const int rank, const int size, const double factor, const double stacksSum) { if (rank == size) { // No player to rank left  return; } for (int i = 0; i \u003c size; i++) { if (usedPlayers[i]) { continue; } // ith player has already been considered  // The probability to have this ith player at this rank knowing the previous ranking is stacks[i] / stacksSum  // The total probability of this ranking chain is thus :  const double newFactor = factor * stacks[i] / stacksSum; // Let's remember this player is ranked  usedPlayers[i] = true; // Add his pondered payout to the result  result[i] += newFactor * payouts[rank]; // Rank all possible next players  recursiveNaiveIcm(stacks, payouts, result, usedPlayers, rank + 1, size, newFactor, stacksSum - stacks[i]); // Reset the flag  usedPlayers[i] = false; } } // Entry point vector\u003cdouble\u003e naiveIcm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts) { // Number of players  const int size = stacks.size(); vector\u003cdouble\u003e result(size); // Flags to note down players that were already considered  vector\u003cbool\u003e usedPlayers(size); double stacksSum = accumulate(stacks.begin(), stacks.end(), 0.); recursiveNaiveIcm(stacks, payouts, result, usedPlayers, 0, size, 1, stacksSum); return result; } Je n’avais pas fait de C++ depuis plus de 10 ans alors on ne se moque pas. De mon temps on codait en C++98, on avait une orange à Noël, et on était content !\nVoyons ce qu’on gagne en temps d’exécution :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 2ms for 8 players Duration 18ms for 9 players Duration 177ms for 10 players Duration 2087ms for 11 players Duration 25924ms for 12 players Pas mal, on peut ajouter un onzième et un douzième joueurs pour presque le même temps de calcul. En gros, on a une accélération de 11 x 12, donc de l’ordre de la centaine !\nMais ça ne nous emmène pas si loin. Continuons de gratter !\nDeuxième optimisation : cache et C-moins-moins Supposons que nous avons n joueurs. À un moment du calcul où on a défini les rangs des k premiers joueurs, il reste n - k joueurs dont on va énumérer les différentes classements possibles.\nSi on prend ces mêmes k premiers joueurs mais dans un autre ordre, l’énumération des différents classements des n - k joueurs restants va être presque identique :\n size, stacks et payouts ne bougent pas result est la destination, ce n’est pas un paramètre du calcul usedPlayers a les mêmes indexes à true (correspondant aux k joueurs classés) rank = k, c’est le même stacksSum correspond à la somme des stacks des n - k joueurs restants et a la même valeur  En fait, seul le paramètre factor varie, car la probabilité d’avoir les k premiers joueurs classés dans un ordre ou un autre n’est pas la même.\nCependant, ce facteur est finalement appliqué à toutes les contributions des appels imbriqués. Mais on peut donc l’extraire et l’appliquer a posteriori.\nCe-faisant, on va calculer une seule fois cette sous-partie pour n - k joueurs au lieu de la calculer pour chaque classement des mêmes k premiers joueurs.\nSi en plus on applique ça pour tous les k entre 0 et n - 1, on n’a en fait à calculer la sous partie que pour toutes les combinaisons (de taille 1 à n) de joueurs.\nHors on sait très bien dénombrer également le nombre de combinaisons possible de joueurs parmis n, et c’est 2n. J’évoquais tout à l’heure la complexité factorielle de l’algorithme naïf, la réduire à une complexité exponentielle semble prometteur !\nOn va indexer les sous-calculs à mettre en cache selon la liste non-ordonnée des joueurs déjà classés, qui implicitement définit le rang actuel et la somme des stacks restants. Pour ce faire, on va choisir un vecteur de bits représenté par un entier, avec à 1 les bits des joueurs déjà classés, et on a une indexation parfaite (et on retombe d’ailleurs sur la complexité en 2n). En bonus, on peut se servir de ce bitmask pour remplacer l’ancien tableau de booléens, ce qui va nous économiser quelques cycles de CPU.\nPour ajouter encore un peu de perf, je vous mets avec ça des pointeurs old-sChool plutôt que des vectors, car oui, ça fait une vraie différence.\nEntendons-nous bien, le niveau d’optimisation dépend fortement de la nature du problème. Si on bosse sur une app de TODO list, le nombre d’opérations est tellement faible qu’il n’y a en général1 aucune raison de chercher à économiser des cycles de CPU. Mais quand on multiplie un nombre d’opérations par 220 c’est à dire environ un million, on s’approche dangereusement de la seconde d’exécution.\net voici ce que ça donne :\nvoid recursiveIcm(const double *stacks, const double *payouts, double *result, long long usedPlayers, int rank, int size, double factor, double stacksSum, double *cacheValues, bool *cacheFlags) { if (rank == size || payouts[rank] == 0) { return; } // Point subResult to the cache entry  double *subResult = cacheValues + usedPlayers * size; // If the subResult wasn't computed previously, let's do it  if (!*(cacheFlags + usedPlayers)) { for (int i = 0; i \u003c size; i++) { const long long iMask = 0x1ll \u003c\u003c i; if (usedPlayers \u0026 iMask) { continue; } // Probability of ith player to have this rank *among remaining players*  // (ignoring previously ranked ones)  const double newFactor = stacks[i] / stacksSum; // Fill the EV of this subresult for this player  subResult[i] += newFactor * payouts[rank]; recursiveIcm(stacks, payouts, subResult, usedPlayers | iMask, rank + 1, size, newFactor, stacksSum - stacks[i], cacheValues, cacheFlags); } // Mark the cache entry as filled  *(cacheFlags + usedPlayers) = true; } // Apply the factor accounting for previously ranked players and add to the destination array  for (int i = 0; i \u003c size; ++i) { result[i] += factor * subResult[i]; } } vector\u003cdouble\u003e icm(const vector\u003cdouble\u003e \u0026stacks, const vector\u003cdouble\u003e \u0026payouts) { const int size = stacks.size(); // Prepare the array that will receive the results from the recursive function  double result[size]; fill_n(result, size, 0); // Just translate vectors to C arrays  double stacksArray[size]; double payoutsArray[size]; for (int i = 0; i \u003c size; ++i) { stacksArray[i] = stacks[i]; payoutsArray[i] = payouts[i]; } // Compute the total stack sum  const double stacksSum = accumulate(stacks.begin(), stacks.end(), 0.); // ## Cache ##  const auto cacheEntrySize = size * sizeof(double); // One double for each player  // We'll store all cached subresult in this memory area.  auto cacheValues = (double *) calloc(pow(2, size), cacheEntrySize); // And we'll store the information of whether each one is filled or not.  auto cacheFlags = (bool *) calloc(pow(2, size), sizeof(bool)); // Ok let's go  recursiveIcm(stacksArray, payoutsArray, result, 0, 0, size, 1, stacksSum, cacheValues, cacheFlags); // Just translate back to vector  vector\u003cdouble\u003e toReturn(size); for (int i = 0; i \u003c size; ++i) { toReturn[i] = result[i]; } // And free the allocated memory  free(cacheValues); free(cacheFlags); return toReturn; } Mais surtout le résultat en termes de performance :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 0ms for 8 players Duration 0ms for 9 players Duration 0ms for 10 players Duration 0ms for 11 players Duration 1ms for 12 players Duration 1ms for 13 players Duration 3ms for 14 players Duration 7ms for 15 players Duration 19ms for 16 players Duration 51ms for 17 players Duration 130ms for 18 players Duration 321ms for 19 players Duration 737ms for 20 players Vous aurez peut-être remarqué une optimisation supplémentaire : si le prix du rang concerné est nul on sort immédiatement. Sous l’hypothèse fort raisonnable que les prix sont décroissants, les calculs subséquents auraient en effet un effet nul. C’n’est peut-être qu’un détail pour vous mais c’est loin d’être anodin. On va ainsi réduire les combinaisons de joueurs à un classement uniquement pour les kclasses payées, ce qui nous donne en complexité une combinaison potentiellement réduite à Ckn après application du cache.\nLes chiffres ci-dessus valent lorsqu’aucun prix n’est nul, voici l’effet quand la moitié des places sont payées :\nDuration 0ms for 2 players Duration 0ms for 3 players Duration 0ms for 4 players Duration 0ms for 5 players Duration 0ms for 6 players Duration 0ms for 7 players Duration 0ms for 8 players Duration 0ms for 9 players Duration 0ms for 10 players Duration 0ms for 11 players Duration 0ms for 12 players Duration 1ms for 13 players Duration 1ms for 14 players Duration 4ms for 15 players Duration 9ms for 16 players Duration 17ms for 17 players Duration 47ms for 18 players Duration 90ms for 19 players Duration 276ms for 20 players On a donc deux facteurs qui vont déterminer le temps d’exécution :\n le nombre de joueurs le nombre de places payées  Chemin d’optimisation Je vous passe bien sûr le cheminement détaillé, car j’ai pris le temps d’appréhender tout ce que j’avais raté ou oublié en termes de gestion de mémoire et des bibliothèques standards en C++20. En bref, disons que je suis passé par des versions bien plus moderne et haut niveau de cet algorithme avec notamment une std::map puis std::unordered_map puis robinhood::unordered_map pour le cache, des std::vector (qui se copiaient à chaque affectation ofc) puis des std::vector\u0026 et ensuite des std::shared_ptr\u003cstd::vector\u003e super hype pour finalement revenir à des pointeurs et calloc pour des questions de performance évidentes.\nComme disait Sam Waters : “Le profiling, c’est ma vie”.\nConclusion et quoi-est-après J’ai toujours en tête de comparer et de titiller les fonctions d’évaluation en MTT. J’ai maintenant une bibliothèque de calcul de l’ICM de qualité professionnelle, qui m’autorise des simulations de tournois pour un petit nombre de joueur. Ça peut être suffisant pour faire des tests qualitatifs sur quelques joueurs, mais j’ai envie de voir si je peux aller plus loin.\nComment calculer efficacement l’ICM pour 50 joueurs ? Ce sera très probablement le sujet de mon prochain billet !\n  Il-y-a pas mal d’écoles différentes sur ce sujet bien sûr, et cette question prend de plus en plus d’importance avec la montée en puissance de l’éco-conception. D’un côté on risque de produire du code plus complexe, moins maintenable et moins fiable en cherchant l’optimisation, ce qu’on traduit par l’injonction “early optimization is the root of all evil” qui nous somme de garder le code simple à moins qu’il ne soit constaté nécessaire de l’optimiser -, de l’autre on assiste facilement à un phénomène d’encrassement à mesure que le code grossit : si des opérations suboptimales sont disséminées partout, l’optimisation consiste alors à tout réécrire et on regrette de ne pas avoir anticipé. Comme disait Bouddha : “La voie du milieu c’est bien, enfin rarement en voiture quand même”. ↩︎\n   ","description":"Où on calcule avec brutalité les espérances des joueurs selon un modèle indépendantiste.","tags":["Poker","AI","ICM","MTT","Game Theory"],"title":"Poker : MTT et ICM - Le Calcul Brutal","uri":"/posts/poker_mtt_icm_calcul/"},{"categories":["Game Theory"],"content":"Comme beaucoup, j’ai eu ma période “poker”. Elle s’est très vite traduite chez moi par la conception d’outils divers d’aide et d’analyse de jeu (parce que je suis trop mauvais), et a donné naissance à cette petite bibliothèque Java. J’ai tiré beaucoup de cette expérience, que ce soit en théorie des jeux, en algorithmique théorique et pratique, en intelligence artificielle ou même en architecture logicielle. Alors bon, je n’assume pas tout à fait cette vieille lib, “si je devais la recoder je le ferais différemment”™ - pas en Java notamment - mais ça fait partie de ces projets tentaculaires qui vous portent pendant des années et vous font monter en compétence sur un large front dans l’allégresse.\nÇa me titillait depuis longtemps de trouver un sujet dans le domaine et de bonnes raisons de m’y recoller. Quand soudain, je tombai sur le paradoxe de Saint-Pétersbourg qui relança avec un ami une vieille conversation sur l’évaluation de l’EV (expected value) en MTT (multi-table tournament).\nIl se trouve que la question “Faut-il jouer toutes les mains EV+ ICM en tournoi?” impliquait un long périple avec dedans du machine-learning, des simulations de jeu et des modélisations intéressantes - tout ce que j’adore.\nMais revenons au début, je vais commencer dans ce billet par tenter de vous expliquer la question.\nThéorie des jeux Au poker, on cherche souvent à jouer GTO (Game Theory Optimal). Derrière ce terme, beaucoup d’implicite. La théorie des jeux étudie les interactions stratégiques d’agents à cheval entre les mathématiques et les sciences sociales, avec de très intéressantes questions qu’on va oublier bien vite : Comment définit-on la rationalité des agents ? Est-elle normative ou prescriptive ? Quelles qualités descriptives a-t-elle ?\nVoilà, on oublie, et maintenant on constate que dans la plupart des cas, tout le monde cherche à trouver la meilleure manière de jouer pour gagner - que ce soit aux échecs, au poker, au go ou à Starcraft1.\nDans des jeux comme les échecs, les algorithmes n’explorent pas l’ensemble de l’arbre de jeu mais évaluent un certain nombre de coups à l’avance. Si je regarde les 5 prochains coups possibles et que sur cette base je dois faire un choix, il me faut évaluer la valeur de chaque situation future résultant de chaque combinaison possible de 5 actions. On appelle fonction d’évaluation cette estimation de la valeur d’une situation qui n’est pas une situation finale. Dans des jeux faisant intervenir la chance (l’aléatoire), on la confond souvent avec la valeur statistique d’espérance (EV, Expected Value : l’espérance), car on va prendre les décisions en fonction de l’EV calculé grâce la fonction d’évaluation. EV+ signifie ainsi “d’espérance positive”.\nPoker Le poker est un jeu de taille considérable du fait du nombre de combinaisons de cartes multiplié par le nombre de séquences d’action (mises) de jeu possibles. Je parle ici uniquement du No-Limit Hold’Em (NLHE) qui est la variante la plus commune.\nDans le cas du cash-game où les jetons misés valent une somme déterminée d’argent, le problème de l’optimisation de la stratégie est circonscrit à une main. Cela reste énorme en complexité mais permet aux explorations algorithmiques de ne pas recourir à des fonctions d’évaluation intermédiaire, et d’interpréter directement les gains et pertes futurs résultant des actions en terme d’argent.\nEn effet, lorsqu’on va chercher à évaluer si telle action est préférable à telle autre, on va faire ce genre de calcul :\n Si je me couche, à la fin de la main j’ai un stack (un tapis) de 900 jetons. Si je suis la mise, selon les cartes qui vont être révélées :  j’ai 40% de chances de finir avec un stack de 1300 jetons j’ai 60% de chances de finir avec un stack de 500 jetons    Je peux donc calculer mon espérance :\n Me coucher : 900 jetons Suivre : 0,4 x 1300 + 0,6 x 500 = 820 jetons  Ok, je dois donc rationnellement me coucher, car plus (+) de jetons, c’est mieux.\nTournoi Dans un tournoi cependant, les prix sont attribuées selon la place finale d’un joueur. Prenons le cas de trois joueurs qui doivent partager 1000€ de prix et disposent en tout de 1000 jetons. Nous ne connaissons rien des joueurs, si bien qu’on les considère aveuglément à égalité stratégique.\nSi seul le premier joueur remporte les 1000€ il paraît raisonnable d’estimer leurs chances de gagner proportionnellement à leurs stacks. On peut d’ailleurs vérifier ça très facilement en leur faisant échanger des jetons aléatoirement (ce qui simule bien l’égalité stratégique). Si les stacks sont 500, 300 et 200, alors en moyenne le premier joueur remportera la mise 50% du temps, le second 30% et le dernier 20%. Leurs espérances de gain sont donc 500€, 300€ et 200€ respectivement.\nPetite simulation pour vérifier ça :\nimport numpy as np import random nb_simulations = 100000 players_stacks = [5, 3, 2] # We'll exchange chips one by one, so let's speed-up by setting smaller stacks payouts = [1000, 0, 0] nb_players = len(players_stacks) podiums = [] for i in range(nb_simulations): game_stacks = players_stacks.copy() podium = [] while True: in_game_players = [i for i, stack in enumerate(game_stacks) if stack \u003e 0] if len(in_game_players) == 1: # We have a winner podium = in_game_players + podium break # Exchange chips until one player is broke while True: # Randomly select two players random.shuffle(in_game_players) p1 = in_game_players[0] p2 = in_game_players[1] # And make them exchange one chip game_stacks[p1] += 1 game_stacks[p2] -= 1 # Is the losing player broke ? if game_stacks[p2] == 0: podium = [p2] + podium break # Recompute in_game_players podiums.append(podium) result = [0.0] * nb_players for podium in podiums: for i in range(nb_players): player = podium[i] result[player] += payouts[i] result = np.divide(result, nb_simulations) print(result) Output :\n\u003e [499.611 299.829 200.56 ] Ce qui m’a bien l’air de converger vers le résultat attendu.\nPetite note sur la taille des stacks allègrement divisée par 100 : il se trouve que ça n’a aucune influence, je l’ai vérifié expérimentalement. Cependant comme j’aimerais bien savoir pourquoi et que je n’ai pas le temps de creuser, j’ai posé la question à l’Internet.\n[EDIT] Au temps pour moi, la proportionalité n’est pas la seule à compter. La taille des stacks a bien une influence dans le cas suivant où le second joueur a un prix ! Ceci-dit, même si mes chiffres sont légèrement biaisés ça n’invalide en rien le propos.\nMaintenant, si le premier joueur remporte 600€ et le second 400€, a-t-on les mêmes espérances de gain ? Faisons donc tourner cette simulation avec ces payouts :\npayouts = [600, 400, 0] Output :\n\u003e [445.71 330.83 223.46] Il est tout de suite moins intuitif d’estimer ça à vue de nez.\nICM Le jeu simulé ci-dessus est le Gambler’s Ruin (qui est en soi plus un problème théorique qu’un jeu).\nLa performance de cette simulation est très faible pour de nombreux joueurs avec de nombreux jetons. Il existe des techniques de calcul avancées que je n’ai pas encore explorées, car en pratique les joueurs de poker préfèrent modéliser leur espérance de classement grâce à l’Independent Chip Model (ICM) dont le calcul est bien plus simple.\nL’ICM est un modèle qui statue que la contribution à l’accès à la première place du tournoi est la même pour chaque jeton, puis récursivement pour les places suivantes. On retrouve donc la proportionnalité entre les jetons et l’espérance lorsque seul le premier joueur remporte le prix.\nAttention cependant, l’ICM n’est pas une solution du classement du problème du N-players Gambler’s Ruin. C’est par contre une approximation commune.\nPour la situation ci-dessus, l’ICM nous donnera donc avec les stacks [500, 300, 200]:\nEn notant X_Y = le joueur X finit en Yième position.\nP1_1 = 500 / 1000 = 0.5 P2_1 = 300 / 1000 = 0.3 P3_1 = 200 / 1000 = 0.2 Puis récursivement, en appliquant la formule des probabilités totales, on calcule la probabilité que le joueur 1 soit deuxième :\nP1_2 = P2_1 * P(1_2 | 2_1) + P3_1 * P(1_3 | 3_1) P1_2 = 0.3 * (500 / 700) + 0.2 * (500 / 800) = 0,339 De même pour les autres joueurs et ainsi de suite pour la troisième place. Pour vous éviter les calculs à la main, il existe des calculateurs en ligne. Celui d’HoldemResources et celui d’ICMIzer.\nPour notre situation, l’ICM nous donne les valeurs :\n\u003e [435.71 330.00 234.29] Pour comparer les résultats, la simulation de Gambler’s Ruin nous donnait :\n\u003e [445.71 330.83 223.46] On retrouve un biais classique de l’ICM qui est de sous-estimer la valeur des plus gros stack et de surestimer les plus petits, tout en restant très correct pour les autres.\nRécapitulatif Prenons un tout petit peu de recul. Pourquoi a-t-on besoin de cet ICM déjà ?\nParce que lorsqu’on cherche une stratégie optimale, on doit estimer la valeur des situations vers lesquelles nous mènent nos actions potentielles. Dans le cas du cash-game, la valeur est immédiatement disponible en fin de main car elle est directement proportionnelle à la quantité de jetons. Mais pour un tournoi, il faudrait aller jusqu’à la résolution du tournoi entier pour observer le gain obtenu. Et autant dire que lorsqu’on doit dérouler toutes les possibilités de tirages et d’actions futures, on préfère circonscrire le problème à la main en cours pour avoir un résultat avant la fin des temps dans le cas d’un calcul informatique.\nOn préfèrerait savoir calculer les espérances de classement selon le modèle du Gambler’s Ruin, hélas il est beaucoup plus compliqué d’avoir une performance correcte dans ce calcul (ceci dit à ce sujet, j’ai dans ma pile de lectures quelques papiers que j’explorerai je l’espère un de ces jours2).\nLa fonction d’évaluation est un outil sur lequel on va soit entrainer des IA, soit faire des analyses stratégiques avec des joueurs réels, mais elle ne représente pas l’espérance concrète des joueurs la plupart du temps. Et c’est d’ailleurs en général ce qu’on souhaite, car essayer de se rapprocher des valeurs concrète c’est essayer de revenir à la résolution du tournoi entier en utilisant stratégies calculées sur la base de la fonction d’évaluation… Et c’est l’Ouroboros.\nPourtant on pourrait faire tendre vers plus de réalisme. Si on sait par exemple qu’un tournoi typique regroupe des joueurs de différents niveaux distribués d’une manière assez régulière, modéliser ce fait statistique peut produire une fonction d’évaluation plus adaptée à l’entraînement pour ce contexte de jeu. Car pour une IA, le jeu sur laquelle on l’entraîne inclut la fonction d’évaluation. Sa confrontation au jeu réel sera lourdement affectée par le choix de cette fonction. On peut d’ailleurs arbitrairement considérer que le niveau des joueurs fait partie des données d’entrée de la fonction. Cependant on préfère reporter ce genre de données contextuelles vers les algorithmes stratégiques pour garder une fonction d’évaluation générique et stable : l’appréciation du niveau des joueurs est une donnée stratégique et contextuelle, elle sera donc intégrée comme une donnée d’entrée des mécanismes stratégiques.\nConclusion La question “Faut-il jouer toutes les mains EV+ ICM en tournoi?” prise littéralement a une réponse immédiate : non, il-y-a même des ajustements que l’on sait bénéfiques. Tout d’abord il est fort probable qu’une meilleure approximation du classement du Gambler’s Ruin donnerait de meilleurs résultats, ensuite s’il était possible de calculer une fonction d’évaluation prenant en compte les asymétries du poker (tables de jeu et tours de parole) on augmenterait certainement encore la fiabilité de l’évaluation.\nMais après cette question vient la suivante : peut-on trouver un meilleur modèle que l’ICM calculable efficacement ? Expérimentalement par exemple, pourrait on appliquer des techniques modernes de machine learning pour trouver une fonction d’évaluation qui surpasse l’ICM ? Et comment faire tout ça en pratique et pour un grand nombre de joueurs sachant que le calcul de l’ICM a une complexité factorielle ?\nDes débuts de réponses dans un prochain billet !\n PS: dans ce billet, j’essaye de ne pas trop rentrer dans les détails ce qui vaut des imprécisions et des raccourcis volontaires. N’hésitez cependant pas à m’écrire si vous trouvez à redire, ou s’il-y-a des manques criants !\nPS bis: en cadeau, un petit papier sympa qui montre deux théorèmes contre-intuitifs.\n Theorem 1. Suppose a tournament has prize money for nth place which is at least that for (n + 1)st place and that at least one player still in the tournament will not earn as much as second place prize money. Under the Independent Chip Model, any fair bet in which only one other player can gain or lose chips in the hand being played will lower the player’s expected prize money.\n  Theorem 2. Suppose a tournament has prize money for nth place which is at least that for (n + 1)st place and that at least one player still in the tournament will not earn as much as second place prize money. Under the Independent Chip Model, the expected prize money of any player not involved in a fair bet between two players will increase*\n Traduit à la pelle par :\n Si t’es en duel avec une équité de 50% contre un seul adversaire au sein d’un tournoi avec des prix croissants, tu es perdant selon l’ICM. Si deux joueurs sont en duel dans ces mêmes circonstances, tous les autres joueurs sont gagnants en ICM.    Ces jeux sont de natures très variées. C’est ce qui fait d’ailleurs qu’à l’heure actuelle, les meilleures IA de poker sont basées sur des techniques très différentes de l’impressionnant MuZero de DeepMind (j’espère avoir le temps de faire un petit papier “CFR vs Reinforcement Learning pour les nuls” tiens). ↩︎\n les papiers en question : Swan, Y., \u0026 Bruss, F. (2006). A matrix-analytic approach to the N-player ruin problem. Journal of Applied Probability, 43(3), 755-766. doi:10.1239/jap/1158784944, et Gambler’s Ruin and the ICM - arXiv:2011.07610v2. Et bien sûr toutes leurs références 🙃 ↩︎\n   ","description":"Où il est question des fonctions d’évaluation en théorie des jeux, du Gambler’s Ruin et de l’ICM.","tags":["Poker","AI","ICM","MTT","Gambler's Ruin","Game Theory"],"title":"Poker : MTT et ICM - La Question","uri":"/posts/poker_mtt_icm_question/"},{"categories":null,"content":"Je suis architecte logiciel généraliste et algorithmicien polyglotte.\nDe l’idée à la ligne de code, les choix sont innombrables et variés. Distinguer les décisions qui importent et les qualifier efficacement est aussi déterminant que l’expertise technique.\nToujours motivé par la recherche de la solution la plus pertinente dans les contextes des plus communs aux plus complexes mais aussi par sa réalisation de bout en bout, contactez-moi pour me parler de vos projets :\n par email pitt@pittscraft.com par téléphone (ou Signal, Whatsapp, Telegram) au +33 (0)6 62 98 24 38  Pierre Mardon (Pitt)\n","description":"","tags":null,"title":"À propos","uri":"/about/"},{"categories":["Application mobile"],"content":"J’avais déjà croisé un exemple d’implémentation de property wrapper et devant leur simplicité, je m’étais mis en tête de créer un property wrapper accélérant le stockage de valeurs dans les UserDefaults.\nIl se trouve que dans mes expérimentations autour de Combine j’avais bien envie de créer un wrapper publiant les nouvelles valeurs seulement après les avoirs stockées (voir ici).\nEt puis j’ai finalement voulu faire tout en même temps !\nQu’est-ce donc qu’un property wrapper ? Un property wrapper très simple s’écrit de cette manière :\n@propertyWrapper public class Print\u003cValue\u003e {ss private var val: Value public init(wrappedValue value: Value) { val = value } public var wrappedValue: Value { set { print(\"Setting '\\(val)'\") val = newValue } get { print(\"Returning '\\(val)'\") return val } } } et s’utilise ensuite ainsi :\nclass SomeClass { @Print var myString: String = \"Coucou copaing !\" func doThings() { myString = \"Bye friend\" var something = myString } } SomeClass().doThings() ce qui imprimera\n\u003e Setting 'Bye friend' \u003e Getting 'Bye friend' ce qui est plutôt nul.\nCeci-dit, si on décidait de faire des choses plus intéressantes que des print, on pourrait bien se faciliter la vie !\nGot UserDefaults ? Stocker des propriétés dans les UserDefaults Voilà un usage fréquent et intéressant.\n@propertyWrapper public struct UserDefaultsBacked\u003cValue\u003e { private let key: String private let defaultValue: Value private let storage: UserDefaults public init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) { defaultValue = value self.key = key self.storage = storage } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Et une implémentation un peu naïve comme celle ci-dessus peut faire l’affaire.\nUn petit warning quand même, on n’oublie pas que chaque setValue sur une clé de UserDefaults réécrit le dictionnaire complet. On utilisera donc tout ça en connaissance de cause, et n’oublions pas qu’on peut aussi réduire leur taille en n’utilisant pas systématiquement le .standard.\nOn peut noter la présence de nouveaux arguments du constructeur, la key et le storage. Ils peuvent être fournis via la déclaration de l’annotation, ou doivent l’être pour ceux qui n’ont pas de valeur par défaut comme la key.\n@UserDefaultsBacked(\"int-key\") // Smells like Java var someInt = 8 @UserDefaultsBacked(\"my-data\", storage: UserDefaults(\"DBName\")) var someData: Data? = nil struct SomeStruct { var prop = \"Yup\" } @UserDefaultsBacked(\"my-struct\") var myStruct = SomeStruct() // Wait... What ? Stocker uniquement les types compatibles Ce wrapper fonctionnera très bien avec tous les types supportés par les UserDefaults mais attendez-vous à de bons crashes pour tous les autres cas, comme SomeStruct.\nRestreignons-donc déjà l’usage aux bonnes valeurs grâce à un flag protocol :\npublic protocol UserDefaultsStorable {} extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} @propertyWrapper public struct UserDefaultsBacked\u003cValue\u003e { private let key: String private let defaultValue: Value private let storage: UserDefaults public init(wrappedValue value: Value, key: String, storage: UserDefaults = .standard) where Value: UserDefaultsStorable { defaultValue = value self.key = key self.storage = storage } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Ok, on a maintenant un property wrapper sélectif et une belle erreur de compilation dans le cas où le type ne se conforme pas à UserDefaultsStorable.\n@UserDefaultsBacked(\"my-struct\") var myStruct = SomeStruct() // Error: Initializer 'init(wrappedValue:_:storage)' requires that 'SomeStruct' conform to 'UserDefaultsStorable' Stocker les Codables Bien mais SomeStruct n’est pas bien mystérieux, ce serait bien sympa de pouvoir le stocker aussi. En fait, tout codable est a priori stockable puisque Data l’est. Seulement pour éviter de se faire la conversion à chaque accès, profitons donc de notre wrapper.\nGénéralisons : on peut avoir à mapper les données dans un sens et dans l’autre pour pouvoir les stocker. L’interface de UserDefaults utilise le très générique Any?, on va donc définir les mappers :\ntypealias StoringMapper\u003cValue\u003e = (Value) -\u003e Any? typealias StoreReadingMapper\u003cValue\u003e = (Any?) -\u003e Value? Puis:\n définir des propriétés de ce type dans notre wrapper. définir un constructeur privé aveugle qui prend de bonne fois n’importe quel type de propriété avec des mappers définir des constructeurs publics stricts sur le type qui vont fournir des mappers au constructeur privé  @propertyWrapper public class UserDefaultsBacked\u003cValue\u003e { private let key: String private let storage: UserDefaults private let defaultValue: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String , storage: UserDefaults, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { var initValue = value if let storedValue = storeReadingMapper(storage.object(forKey: key)) { initValue = storedValue } defaultValue = initValue self.key = key self.storage = storage self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Mais pour mes Codables les mappers ne sont pas si évidents.\npublic extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } Ci-dessus la fonction d’encodage, avec absolument pas de check sur le cas où l’objet est également stockable nativement, car la discrimination s’effectuera en amont. Bon, c’est l’équivalent de try? JSONEncoder().encode(self) mais avec une trace pour ne pas être complètement dans le brouillard en cas de problème. Evidemment on préfèrera certainement donner de meilleures options de traçage, et certains se sentent mal (à raison) de ne pas throw quoi que ce soit, mais ce n’est pas le débat ici. Et puis comme on dit parfois : “Quand tout va bien, tout va bien !”.\n/// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } Joyeusement pompé de ce post SO\nTiens je parlais dans mon poste précédent de type erasure, mais saviez vous que l’inverse est le type opening ? Eh bien pareil, je me suis couché moins bête. Et pour tous ceux qui ont déjà joué avec un JSONDecoder dans des contextes génériques un peu poussés, la feinte ci-dessus est plutôt cool à retenir : une fonction statique a toujours accès au type concret, ce qui satisfait le compilo.\npublic extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to ignore thrown errors return nil } } } Et voilà, sur tout type se conformant à Decodable on a désormais cette fonction mapOutOfStorage.\nJe rappelle que typealias Codable = Decodable \u0026 Encodable, donc pour tout type Codable on a nos deux mappers \\o/\nRajoutons donc ce petit constructeur à notre property wrapper UserDefaultsBacked :\nconvenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, storingMapper: Value.mapForStorage, storeReadingMapper: Value.mapOutOfStorage) } Nice, et maintenant qu’est ce qui se passe si je déclare quelque chose comme :\n@UserDefaultsBacked(\"myKey\") var myInt = 0 // Error: Ambiguous use of 'init(wrappedValue:_:storage:sendAfterStore:)' Eh bien les Int étant Codable mais aussi UserDefaultsStorable, le compilateur ne saura quel constructeur choisir. Deux solutions : enlever l’ambiguité en changeant la signature d’un des constructeurs (ce qui est un peu minable, même simplement d’y avoir pensé), ou donner un constructeur qui match encore mieux, avec where Value : Codable \u0026 UserDefaultsStorable. Encore un bon trick, vous êtes bienvenus.\nCheckpoint Voici un petit bilan :\n/// Any type implementing this protocol can be stored natively in UserDefaults public protocol UserDefaultsStorable {} /** Declare proper flag protocol conformance for all types natively compatible with UserDefaults storage */ extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} /// `Encodable` mapping for storage public extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } /// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { // Useful trick from https://stackoverflow.com/questions/54963038/codable-conformance-with-erased-types static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } /// `Decodable` mapping for reading from storage public extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to almost ignore thrown errors return nil } } } @propertyWrapper public class UserDefaultsBacked\u003cValue\u003e { private let key: String private let storage: UserDefaults private let defaultValue: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String, storage: UserDefaults, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { defaultValue = value self.key = key self.storage = storage self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, storingMapper: Value.mapForStorage, storeReadingMapper: Value.mapOutOfStorage) } public convenience init(wrappedValue value: Value, _ key: String, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable \u0026 UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, storingMapper: {$0}, storeReadingMapper: {$0 as? Value}) } public var wrappedValue: Value { get { storage.value(forKey: key) as? Value ?? defaultValue} set { storage.setValue(newValue, forKey: key) } } } Fun fact : j’ai retrouvé le même flag protocol sur un post (je l’ai plus sous la main là), puis vu des implémentations proches pour les Codable, mais tout ça bien sûr après avoir réinventé la roue. Et même si on dit souvent ça péjorativement, dans une démarche d’apprentissage ça a tout son sens de regarder les solutions seulement ensuite. Et en plus c’était vachement moins bien fait, genre là pas de type checking, aucune cohabitation entre les Codable et les types natifs… Nan mais jvous jure…\nEt puis de toute façon je voulais aussi m’occuper de faire …\nUn publisher un peu custom Lorsqu’on utilise SwiftUI et Combine simplement, on va naturellement devoir taper des expression comme $myState ou $myObject.prop. Une fois passée mon aversion forte pour le PHP, j’ai creusé rapidement pour constater que ce n’était qu’une syntaxe un peu flippante pour accéder à la valeur projetée d’une wrapped property.\nProjected value ? En bref, n’importe quel property wrapper peut déclarer une var projectedValue: SomeType {...} dont le type n’est pas nécessairement le même que celui de sa wrappedValue. Et cette projectedValue est accessible grâce au dollar américain (comme tellement de choses).\n@propertyWrapper public class Print\u003cValue\u003e { private var val: Value public init(wrappedValue value: Value) { val = value } public var wrappedValue: Value { set { print(\"Setting '\\(val)'\") val = newValue } get { print(\"Returning '\\(val)'\") return val } } public var projectedValue: Int { print(\"42\") return 8 } } @Print var myString: String = \"5\" myString = \"40\" print(\"Coucou \\($myString)\") printera donc\n\u003e Setting '40' \u003e 42 \u003e Coucou 8 Aaah, je pense que j’ai fait le pire exemple qui soit, “service !” comme on dit dans l’est.\nBref, ce $ n’a en théorie pas forcément grand chose à voir avec Combine excepté qu’on l’y utilise en permanence.\nQuelques notions de Combine Typiquement, le property wrapper Published a pour type projeté la struct Published\u003cValue\u003e.Publisher (doc) qui respecte notamment le protocole Publisher (et bien plus, doc), et peut donc envoyer des Value à des Subscriber.\nDonc quand j’accède à un @Published var myString: String via $myString j’obtiens en gros une propriété dont je peux écouter les valeurs successives.\nEt quand je fais du SwiftUI ainsi : .sheet(isPresented: $vm.router.showSheet, ...), je passe donc un Publisher à la fonction sheet qui se fera un plaisir d’écouter si on doit où non présenter cette sheet.\nRappel : lorsqu’on utilise sink pour écouter les valeurs d’une var @Published via son Publisher, on reçoit la nouvelle valeur alors que la wrappedValue est encore l’ancienne valeur. Et je voudrais contourner ça dans certains cas (voir mon post précédent).\nMaintenant, ce qui m’intéresserait ce serait d’avoir ça, un Publisher que je pourrais contrôler finement pour lui envoyer des valeurs. Eh bien Combine nous fournit gracieusement le protocole Subject qui hérite de Publisher et qui présente de surcroit une fonction send(_:) permettant d’envoyer des valeurs à publier. Ses implémentations sont :\n CurrentValueSubject qui détient une valeur courante PassthroughSubject qui au contraire ne retient rien  On devrait s’en sortir avec ça !\nDidSet Publisher property wrapper Pour reproduire le comportement de @Published on pourrait écrire comme ça comme ça.\n@propertyWrapper public class BasicPublished\u003cValue\u003e { private let subject: CurrentValueSubject\u003cValue, Never\u003e public init(wrappedValue value: Value) { subject = CurrentValueSubject(value) wrappedValue = value } public var wrappedValue: Value { set { subject.send(newValue) } get { subject.value } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } Le problème étant que lorsque le send va provoquer l’exécution de toutes les closures des subscribers, subject.value aura toujours l’ancienne valeur.\nAssez simple du coup d’y remédier :\n@propertyWrapper public class DidSetPublished\u003cValue\u003e { private var val: Value private let subject: CurrentValueSubject\u003cValue, Never\u003e public init(wrappedValue value: Value) { val = value subject = CurrentValueSubject(value) wrappedValue = value } public var wrappedValue: Value { set { val = newValue subject.send(val) } get { subject.value } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } (je crois que cette implémentation vient de là, et je crois aussi qu’il serait plus pertinent d’utiliser PassthroughSubject a priori)\nTout ensemble Vous le saviez, mon but ultime était ~la conquête de la Suède en lama~ de combiner tout ça. Pas juste pour le fun, mais parce que dans mon archi, à un moment, j’avais besoin d’une propriété Codable (un enum) stockée dans les UserDefaults et qui ne publierait son changement de valeur qu’après l’avoir affecté à sa wrappedValue.\nEt puis d’autres besoins avec des variations : pas de stockage mais publication après affectation, stockage natif mais publication avant affectation…\nJ’aurais bien pu contourner tout ça, ou encore essayer de faire fonctionner des wrappers imbriqués, mais je voulais me frotter à cette implémentation spécifique.\nEt voilà, je vous colle juste l’ensemble là dessous, chaque détail étant expliqué dans les parties précédente (enfin faut savoir quelques trucs en amont quand même, oui).\nN’oubliez pas que la perf n’est pas l’objectif de ce wrapper (du tout).\nJe vous suggère d’ailleurs de jeter un oeil à l’implémentation de Published chez OpenCombine, qui est particulièrement élégante (ya un enum \u003c3).\n// // SmartPublished.swift // attestation // // Created by Pierre Mardon on 01/01/1970. Trust me. // import Foundation import Combine /// We need functions to map values before storing them to user defaults fileprivate typealias StoringMapper\u003cValue\u003e = (Value) -\u003e Any? /// We need functions to map values read from user defaults storage to an expected type fileprivate typealias StoreReadingMapper\u003cValue\u003e = (Any?) -\u003e Value? /// Any type implementing this protocol can be stored natively in UserDefaults public protocol UserDefaultsStorable {} /** Declare proper flag protocol conformance for all types natively compatible with UserDefaults storage */ extension String : UserDefaultsStorable {} extension Int: UserDefaultsStorable {} extension Double: UserDefaultsStorable {} extension Float: UserDefaultsStorable {} extension Date: UserDefaultsStorable {} extension Data: UserDefaultsStorable {} extension Array: UserDefaultsStorable where Element: UserDefaultsStorable {} extension Dictionary: UserDefaultsStorable where Key == String, Value: UserDefaultsStorable {} /// `Encodable` mapping for storage public extension Encodable { func mapForStorage() -\u003e Any? { do { return try JSONEncoder().encode(self) } catch { print(\"Couldn't encode \\(self)\", error) return nil } } } /// Simple type opening using a static function to allow JSON decoding with erased types conforming to `Decodable` protocol fileprivate extension Decodable { // Useful trick from https://stackoverflow.com/questions/54963038/codable-conformance-with-erased-types static func openedJSONDecode(using decoder: JSONDecoder, from data: Data) throws -\u003e Self { return try decoder.decode(self, from: data) } } /// `Decodable` mapping for reading from storage public extension Decodable { static func mapOutOfStorage(_ value: Any?) -\u003e Self? { guard let data = value as? Data else { return nil } do { return try Self.openedJSONDecode(using: JSONDecoder(), from: data) } catch { print(\"Couldn't decode \\(String(describing: value))\", error) // Very opinionated choice to almost ignore thrown errors return nil } } } /** Property wrapper that provides some common use cases options. Do NOT use for heavy performance demanding components. - `UserDefaults` storage is activated when a `key` is provided for all natively handled types and `Codable` ones - option `sendAfterStore` makes the subject send the value only after it has effectively been affected to the property itself: WARNING this is not recommended for UI bindings. Disabled by default. Usage: \\``` @SmartPublished(\"someKey\") var myProp = \"Bonjoir !\" \\``` The string property will be backed in UserDefaults.standard for the key \"someKey\". It will be effectively stored only if the value of the var is affected after its initialization, until then UserDefaults entry will stay untouched. The initial value of the property will be `\"Bonjoir !\"` if there's not value in the store. \\``` @SmartPublished(\"myCodableValueUserDefaultsKey\") var myProp = someValueOfCodableType \\``` The codables are stored the same way except they are JSON encoded if they're not natively handled by UserDefaults. \\``` @SmartPublished(sendAfterStore = true) var myProp = 8 $myProp.sink { print(\"property: \\(myProp), received: \\($0)\") } myProp = 1 \\``` Will print `property: 1, received: 1`, while with `@Published` or `sendAfterStore = false` it would be `property: 8, received: 1`. It is not recommended to use this `sendAfterStore = true` for UI-bound properties. \\``` @SmartPublished \\``` Why would you do that, just use `@Published` then! */ @propertyWrapper public class SmartPublished\u003cValue\u003e { private let key: String? private let storage: UserDefaults private let sendAfterStore: Bool private let subject: CurrentValueSubject\u003cValue, Never\u003e private var val: Value private var storingMapper: (Value) -\u003e Any? private var storeReadingMapper: (Any?) -\u003e Value? private init(wrappedValue value: Value, _ key: String? , storage: UserDefaults, sendAfterStore: Bool, storingMapper: @escaping StoringMapper\u003cValue\u003e, storeReadingMapper: @escaping StoreReadingMapper\u003cValue\u003e) { var initValue = value if let key = key, let storedValue = storeReadingMapper(storage.object(forKey: key)) { initValue = storedValue } val = initValue subject = CurrentValueSubject(initValue) self.key = key self.storage = storage self.sendAfterStore = sendAfterStore self.storingMapper = storingMapper self.storeReadingMapper = storeReadingMapper subject.send(val) } public convenience init(wrappedValue value: Value, _ key: String? = nil, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value: UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, _ key: String?, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0.mapForStorage()}, storeReadingMapper: Value.mapOutOfStorage) } public convenience init(wrappedValue value: Value, _ key: String?, storage: UserDefaults = .standard, sendAfterStore: Bool = false) where Value : Codable \u0026 UserDefaultsStorable { self.init(wrappedValue: value, key, storage: storage, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: { $0 as? Value}) } public convenience init(wrappedValue value: Value, sendAfterStore: Bool = false) { self.init(wrappedValue: value, nil, storage: .standard, sendAfterStore: sendAfterStore, storingMapper: {$0}, storeReadingMapper: {$0 as? Value}) } public var wrappedValue: Value { set { if sendAfterStore { subject.send(newValue) } if let key = self.key { storage.setValue(storingMapper(newValue), forKey: key) } else { val = newValue } if !sendAfterStore { subject.send(newValue) } } get { if let key = self.key { return storeReadingMapper(storage.value(forKey: key)) ?? val } return val } } public var projectedValue: CurrentValueSubject\u003cValue, Never\u003e { get { subject } } } N’hésitez pas à me contacter pour toute remarque, insulte ou éloge, mon email est dans le footer ;)\n","description":"","tags":["iOS","Combine","SwiftUI"],"title":"SwiftUI \u0026 Combine Feedback #2 : property wrapper pour UserDefaults et @Published","uri":"/posts/swiftui_combine2/"},{"categories":["Application mobile"],"content":"Après mon premier petit TP autour de SwiftUI et Combine pour générer mes attestations de déplacement ~à la barbe de la maréchaussée~ à la volée voire en retard, j’ai profité de l’adaptation au second format d’attestation pour faire des explorations un peu plus poussées de mon architecture autour de Combine.\nJ’en sors une petite liste de considérations techniques que j’espère d’intérêt, et voici les premières !\nArchitecture: MVVM+ Pour une petite app comme celle-ci, je m’autorise des entorses à nombre de principes stricts overkill que je n’estime pas pertinents ici, avec des gains principalement en concision et lisibilité. Le MVVM est tout à fait indiqué pour un cloisonnement minimal, et en l’occurence ça ressemblait à ça\nAvec des injection par construction et donc cette instanciation initiale :\nlet store = Store(context: moContext) let model = MainViewModel(store: store, router: Router()) return MainView(model: model) On peut remarquer le petit Router qui s’est avéré fort utile pour éviter trop de plomberie. Son rôle est juste de publier des propriétés destinées à contrôler et rendre compte de la navigation. Il ne fait donc clairement pas partie du modèle ni des vues, et j’ai du mal à le considérer comme un modèle de vue étant donnée sa nature transverse.\nTant qu’il ne dépasse pas ce rôle de navigation, ne stocke qu’un minimum de données transitoires au besoin (immuables de préférence, la struct d’une personne à éditer par exemple), ça reste très lisible et on évite les chaînages de @Published orthodoxes.\nenum ActiveSheet { case attestationPresentation(person: PersonStruct), addPerson, edit(person: PersonStruct) } enum ActiveAlert { case confirmAttestation, detail(reason: Reason) } class Router: ObservableObject { @Published var showSheet = false @Published var showAlert = false private(set) var activeSheet = ActiveSheet.addPerson private(set) var activeAlert = ActiveAlert.confirmAttestation func showAttestationCreationAlert() { activeAlert = .confirmAttestation showAlert = true } func startAddPerson() { activeSheet = .addPerson showSheet = true } func startEdit(person: PersonStruct) { activeSheet = .edit(person: person) showSheet = true } func showReasonDetail(_ reason: Reason) { activeAlert = .detail(reason: reason) showAlert = true } func showAttestationView(person: PersonStruct) { activeSheet = .attestationPresentation(person: person) showSheet = true } func closeSheet() { showSheet = false } } Plutôt concis, ça vaut clairement le coup plutôt que de perdre ces quelques variables dans des chemins trop tortueux.\nTous mes proches le savent, les enums Swift c’est ma grande passion. Et ceux du petit routeur ci-dessus me permettent de faire des fonctions SwiftUI bien compactes :\nfunc alert() -\u003e Alert { switch vm.router.activeAlert { case .confirmAttestation: return Alert(title: coldFeetTitle, message: coldFeetMessage, primaryButton: .default(Text(\"Je certifie\")) { vm.generateNewAttestation() }, secondaryButton: .cancel(Text(\"Annuler\"))) case .detail(reason: let reason): return Alert(title: Text(reason.niceString), message: Text(reason.detail), dismissButton: .default(Text(\"Ok\"))) } } func sheet() -\u003e AnyView { switch vm.router.activeSheet { case .attestationPresentation(let person): return AnyView(AttestationView(vm: vm.attestationViewModel(person: person))) case .addPerson: return AnyView(AddOrEditPersonSheet(vm: vm.addPersonViewModel)) case .edit(let person): return AnyView(AddOrEditPersonSheet(vm: vm.editPersonViewModel(person: person))) } } Et enfin, le body de ma View principale sera très concis :\nvar body: some View { NavigationView { VStack(alignment: .center, spacing: 5) { MainListsView(model: vm.mainListsViewModel).environment(\\.editMode, $editMode) BottomMenu(model: vm.bottomMenuViewModel) } .sheet(isPresented: $vm.router.showSheet, onDismiss: { vm.checkShouldShowPinnedAttestation() }, content: sheet) .navigationBarTitle(\"\", displayMode: .inline) .navigationBarItems(leading: navigationBarLeadingItem, trailing: EditButton(editMode: $editMode)) } .alert(isPresented: $vm.router.showAlert, content: alert) } (on peut comprendre d’ailleurs pourquoi je sépare le showSheet et showAlert des enums, au lieu de déclarer des .none)\nLa vue principale est la principale consommatrice du routeur, cependant de multiples vues viennent agir dessus.\nEvidemment, cette architecture est adaptée à ce projet particulier, ne cherchez pas à reproduire ça à la maison.\nLes petits trucs pénibles Type erasure Ci-dessus, vous pouvez voir que j’utilise AnyView(...) pour renvoyer un type consistant de View. Pour tous ceux qui ont joué un peu en profondeur avec les protocoles et génériques en Swift, on atteint vite des obstacles mystérieux particulièrement brainboiling.\nHeureusement on observe un effort de type erasure dans les bibliothèques système avec ces AnyView, AnyCancellable…\nAinsi que de nouveaux mots clé mystérieux comme some qui est la réponse directe à la sentence :\n Protocols ‘WouldBeSoNice’ can only be used as a generic constraint because it has Self or associated type requirements\n Si ça vous intéresse je vous conseille ce petit article.\nCeci-dit, même si ça disparaît vite, je pense que c’est un frein assez considérable notamment pour des débutants.\nObserver des objets imbriqués Un ViewModel en mode Combine doit avoir cette allure :\nclass MyViewModel : ObservableObject { @Published var someProperty = \"Coucou copaing !\" } Le wrapper @Published est tout à fait adaptée aux structs puisque toute mutation d’une struct est un changement de valeur. Mais les classes si elles sont faites pour être mutées ne remonteront point l’évènement au wrapper.\nOr pour observer une propriété imbriquée au deuxième niveau dans SwiftUI, comme .sheet(isPresented: $vm.router.showSheet) {…}, on peut essayer :\n d’observer le routeur qui serait une struct et de prendre sa valeur showSheet avec le routeur en ObservableObject, observer directement showSheet  Eh bien aucune des deux options ne fonctionne directement depuis une vue SwiftUI. Ce petit $ qui désigne la projectedValue d’une propriété encapsulée par un @Published ou un @State n’est pas magique, et ça ne fonctionne qu’au premier niveau, c’est à dire un @Published propriété d’un ObservableObject.\nEt la feinte officielle n’est pas bien glorieuse :\nclass MyViewModel : ObservableObject { @Published var router = Router private var cancellables = Set\u003cAnyCancellable\u003e() init(router: Router) { self.router = router router.objectWillChange.sink { [weak self] _ in self?.objectWillChange.send() }.store(in: \u0026cancellables) } deinit { cancellables.forEach({ $0.cancel() }) } } Il-y-a des variantes plus concises au prix de sacrifices discutables, mais voilà le principe. A chaque fois que le routeur va changer, on va propager l’évènement pour indiquer à l’UI de se rafraîchir. C’est un peu large, un peu “Mario fait du Combine”, mais ne soyons pas obtus, si ça roule après tout…\nUne bonne alternative est de mettre tout ça à plat dans la vue :\nstruct MyView: View { @ObservedObject private var vm: MainViewModel var body: some View {...} } deviendrait\nstruct MyView: View { @ObservedObject private var vm: MyViewModel @ObservedObject private var router: Router var body: some View {...} } C’est plus élégant je trouve, mais imaginons que j’ai 8 entités un peu complexes à embarquer dans mon VM, ça commence alors à foisonner plus que de raison.\nAutre point en passant, impossible de sécuriser l’instance embarquée du routeur dans le view-model avec un private(set) modifier dans la première version. C’est de l’ordre du TOC - c’est bien d’en être conscient - mais ça me gène 😅\nPropager des @Published, Model -\u003e VM -\u003e View class Store : ObservableObject { @Published private(set) var someUrl: URL? } class MyViewModel : ObservableObject { @Published private(set) var someUrl: URL? init(store: Store) { store.$someUrl.assign(to: \u0026$someUrl) } } Mais c’est très raisonnable, super ! Oui mais iOS14+ seulement.\nEt voici la version iOS 13 :\nclass Store : ObservableObject { @Published private(set) var someUrl: URL? } class MyViewModel : ObservableObject { @Published private(set) var someUrl: URL? private var cancellables = Set\u003cAnyCancellable\u003e() init(store: Store) { store.$someUrl.sink { [weak self] url in self?.someUrl = url }.store(in: \u0026cancellables) } deinit { cancellables.forEach({ $0.cancel() }) } } * whip sound *\nPas mal hein ?\n* whip sound *\nSink twice silence génant\nQuand on observe un sujet avec sink, sachez que la valeur qui vous est passée en closure est celle qui va être attribuée, comme lorsqu’on utilise willSet sur une propriété (quelques détails ici).\nPas de problème pour l’update d’UI, c’est fait pour. Mais pour les autres besoins, comme par exemple quand on a des mécanismes complexes intermédiaires qui ne se résument pas à fusionner deux valeurs publiées, la meilleure chose à faire est encore de créer son publisher.\nEt même si j’aurais encore beaucoup à dire autour de ce sujet, je réserve à un futur article une petite contribution autour de ce sujet, des property wrappers et consorts.\nN’hésitez pas à m’écrire si vous avez un avis quelconque sur ce que j’ai écrit, mon email est (?) dans le footer ;)\n","description":"","tags":["iOS","Combine","SwiftUI"],"title":"SwiftUI \u0026 Combine Feedback #1 : architecture et grains de sable","uri":"/posts/swiftui_combine1/"},{"categories":["Application mobile"],"content":"Il m’est arrivé plusieurs fois d’oublier mon attestation de sortie (c’est mal), de la générer au volant en panique (c’est très mal), de prendre du retard en tapant le formulaire avant de partir… Loin de moi l’idée de débattre du bien-fondé du confinement et de ses modalités, cependant j’étais confronté à un inconfort mineur. Et comme tout bon ingé, j’ai cherché et évalué des solutions complètement superflues - toutefois avec un indiscutable sérieux et un professionnalisme inébranlable.\nLa voie des anciens Imprimer des attestations préremplies et ne laisser que le motif, la date, l’heure et la signature à remplir.\nOui ça marche, mais la matérialisation est une contrainte forte. Si on oublie de remplir son attestation (c’est mal) et qu’on prend la voiture on n’a pas de moyen de gérer la situation sans un 180° bien crissant (ce qui est certes classe mais dangereux).\nOn me dit dans l’oreillette qu’on peut tout à fait écrire une attestation à la main sur papier libre… Oui mais bon, change pas de sujet, j’ai pas de stylo ni de papier sur moi, voilà, et puis niveau ergonomie, c’est so les millénaires passés l’écriture…\nLa voie officielle #1 (web) J’ai essayé de faire avec la page web gouvernementale. Et franchement, c’est correct sur ordinateur avec le bon équipement logiciel. J’utilise personnellement un navigateur Chromium avec le plugin de mon gestionnaire de mots de passe Dashlane. Le seul inconfort évident est la lecture des motifs du déplacement. J’ai commencé à faire un petit plugin Chrome pour retravailler ça avant de me raviser rapidement : les plugins ne fonctionnent pas sur les navigateurs Chromium iOS et la génération sur portable est bien plus pratique.\nLa voie officielle #2 (TousAntiCovid) On monte en qualité avec le générateur intégré à l’application TousAntiCovid. Il est possible de faire retenir mes coordonnées par l’appli et les motifs ont un titre en gras qui permet d’y voir un peu plus clair. Cependant je ne suis pas intéressé par la fonctionnalité de traçage de cette application. Donc je n’ai pas apprécié quand j’ai dû impérativement autoriser l’app à utiliser le bluetooth à la première ouverture. Et puis en regardant ça, je commençais à avoir ma petite idée de l’appli idéale donc toutes les petites frictions du parcours pour générer mon autorisation me faisaient tiquer. Ca fait quand même pas mal d’étapes après ouverture de l’application :\n scroll tout en bas tap sur Attestation de déplacement tap sur Nouvelle attestation entrer mes données - ok ça s’enregistre on ne le compte pas tap (optionnel) sur l’heure pour régler l’heure de ma sortie - je n’ai jamais touché à la date jusque là tap pour choisir le motif de déplacement (qui ne s’enregistre pas) sur mon iPhone, il faut 3 hauteurs d’écran pour lire intégralement la liste des motifs, on ajoute donc souvent un scroll ou deux tap sur le motif tap sur Générer alerte de confirmation : tap sur Je certifie  Donc dans le cas idéal (je pars maintenant, c’est bien moi qui gènère l’attestation et je suis la dernière personne à avoir utilisé le générateur sur cet appareil, et mon motif est mon caractère laborieux) j’ai donc 7 actions avant d’obtenir le QR Code tant convoité. C’est beaucoup.\nLa voie des ptits malins (app iOS Raccourcis) Certaines boîtes comme Luko ou Newzik vous proposent de générer un lien qui contient vos données, et qui mène à un générateur automatique qui affiche l’attestation générée avec l’heure de sortie actuelle.\nL’idée est notamment d’utiliser un raccourci déclenché par Siri par exemple pour commander son attestation à la voix ou encore la faire ouvrir automatiquement dès qu’on quitte son domicile. On n’est pas loin de la solution idéale, seulement je ne peux pas générer une attestation à la bourre.\nCeci-dit, ce lien est un bon exemple de ce qu’on peut faire rapidement pour se faciliter la vie. Quelques bookmarks, un peu de configuration et pour les gens pas trop technophobes on s’en sort.\nL’app de mes rêves Cahier des charges L’app de mes rêves\n dans le meilleur des cas, nécessite une seule action pour générer une attestation si le motif change, une à deux actions supplémentaires sont tolérables. demande le plus rarement possible des actions supplémentaires. permet à ma compagne de faire son attestation sur mon téléphone sans effacer mes données préremplies gère très efficacement mon cas pathologique d’oubli. Elle doit donc me permettre de générer mon attestation lorsque je me rends compte après 20 minutes de trajet que j’ai oublié mon attestation : pour être dans les clous, mon heure de sortie doit alors être 20 minutes dans le passé n’embarque aucune autre fonctionnalité non souhaitée n’envoie aucune donnée à qui que ce soit (pas de tracking publicitaire ou autre) n’utilise aucune bibliothèque tierce non maîtrisée à 100%  Je me suis auto-défié, et au bout d’une petite journée de développement j’avais un prototype fonctionnel, ce qui m’a encouragé à continuer. Au bout de trois jours de développement j’avais une app présentable, les aspects légaux étaient confirmés, et la plupart des raffinements majeurs étaient implémentés.\nRéalisation ! Je suis bien content d’annoncer que j’ai respecté *presque* tous les points de l’app de mes rêves. Seule entorse, comme il faut quand même être un peu sérieux, j’ai ajouté une confirmation de véracité des données à la génération de l’attestation, on a donc deux actions pour générer l’attestation.\nTout comme pour la solution de génération par liens, j’ai récupéré le code publié par le ministère de l’intérieur pour générer les PDFs en inspectant son intégralité, en extrayant uniquement les parties nécessaires, puis en le modifiant pour son intégration dans l’app.\nJe ne vais pas vous cacher que je n’aurais pas fait cette application juste pour me faciliter les sorties. Je voulais également expérimenter SwiftUI, la bibliothèque déclarative d’interface utilisateur d’Apple qui me tend les bras depuis plusieurs années, et c’était une bonne occasion.\nEt voici le résultat :\nVue principale Ici on peut :\n ajouter / supprimer / réordonner les personnes sélectionner un ou plusieurs motifs de sortie sélectionner la date de sortie en temps relatif par rapport à l’heure actuelle : les boutons du Stepper (+ / -) ajoutent ou retirent 10 minutes et surtout aller vers l’attestation !  Vue d’édition de personne Un simple formulaire tout bête :)\nPrésentation de l’attestation Très simple, on peut juste :\n partager le PDF épingler l’attestation : dans ce cas la présentation en carte ne se laisse pas fermer comme d’habitude par swipe vertical, la croix de fermeture disparaît, et au cas où l’utilisateur ferme l’app, l’attestation sera restaurée à la réouverture  Temps de génération de l’attestation : 3s Dans mon usage quotidien, avec ma (vraie) identité de remplie, je mets environ 3s à remplir mon attestation entre l’ouverture de l’app, le choix ou la vérification du motif et le réglage ou la vérification de l’heure. Oui je suis lent, mais mon objectif est atteint, je peux sans risque générer mon attestation dans des situation d’urgence et d’oubli \\o/\nApp Store ? Eh bien malgré ma gestion paranoïaque des données utilisateur, il semble que ce ne soit pas suffisant pour Apple qui (je pense) n’autorise simplement aucune app avec cette fonctionnalité sauf celle du gouvernement.\n We found in our review that your app provides services or requires sensitive user information related to the COVID-19 pandemic. Since the COVID-19 pandemic is a public health crisis, services and information related to it are considered to be part of the healthcare industry. In addition, the seller and company names associated with your app are not from a recognized institution, such as a governmental entity, hospital, insurance company, non-governmental organization, or university.\nPer section 5.1.1 (ix) of the App Store Review Guidelines, apps that provide services or collect sensitive user information in highly-regulated fields, such as healthcare, should be submitted by a legal entity that provides these services, and not by an individual developer.\n J’ai évidemment fait appel mais je ne pense pas qu’ils cèderont, tant pis, je ne partagerai donc mon app qu’avec mes proches (du moins ceux qui possèdent un iPhone) !\nDéveloppement : retour d’XP SwiftUI + Combine Tout d’abord SwiftUI est très agréable à utiliser. On a évidemment les traditionnelles errances de XCode 12, que ce soit niveau compilation, complétion, aperçu de l’UI… Mais il convient de saluer la prouesse qu’est l’implémentation de ce framework, un très bon exemple de DSL sur Swift, qui s’y prête particulièrement bien.\n1struct AddEditPersonSheet: View { 2 3\t// Local state 4 @State 5 private var tappedOkButton = false 6\t7\t// The ViewModel data and callbacks / Yeah I should have created a struct for this 8 @Binding 9 var editingPerson: EditingPerson 10 let isCreation: Bool 11 var cancelAddPerson: () -\u003e Void 12 var endAddOrEditPerson: () -\u003e Void 13 14\t// No constructor (structs are cool) 15\t16 private var title: String { 17 isCreation ? \"Créer\" : \"Modifier\" 18 } 19 20 private func isEmpty(_ str: String) -\u003e Bool { 21 str.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty 22 } 23 24 var body: some View { 25 NavigationView { 26 Form {ss 27 Section(header: Text(\"Identité\")) { 28 if tappedOkButton \u0026\u0026 isEmpty(editingPerson.firstName) { 29 Text(\"Prénom manquant\").foregroundColor(.red) 30 } 31 TextField(\"Prénom\", text: $editingPerson.firstName).textContentType(.givenName) 32 if tappedOkButton \u0026\u0026 isEmpty(editingPerson.lastName) { 33 Text(\"Nom manquant\").foregroundColor(.red) 34 } 35 TextField(\"Nom\", text: $editingPerson.lastName).textContentType(.familyName) 36 } 37 // ... other sections 38 } 39 .navigationBarItems(leading: Button(action: cancelAddPerson) { 40 Text(\"Annuler\") 41 }, trailing: Button(action: { 42 withAnimation { 43 tappedOkButton = true 44 if (editingPerson.isValid) { 45 endAddOrEditPerson() 46 } 47 } 48 }) { 49 Text(\"Enregistrer\") 50 }.disabled(tappedOkButton \u0026\u0026 editingPerson.isValid)) 51 .navigationBarTitle(Text(title), displayMode: .inline) 52 } 53 } 54} Pas de critiques les puristes, j’ai fait du monolingue et du gros inline volontairement.\nDéveloppement rapide : Grâce à cette approche DSL, on se retrouve avec du code à l’imbrication proche de l’UI, facilement intelligible, avec de très bons comportements par défaut. Comme c’était mon premier test j’ai forcément un peu ramé, mais j’aurais pris bien plus de 3 jours de développement pour une petite app complète, fonctionnelle et propre si j’avais dû rapprendre UIKit ou pire : HTML + CSS.\nLe couplage avec Combine permet de s’engager sur le chemin des state-driven apps. Pour avoir pas mal joué avec React + Redux, je ne peux que vous inciter à adopter ce paradigme. Evidemment, quand on n’a jamais fait que de la programmation impérative, beaucoup de petites choses peuvent être frustrantes au premier abord. Mais ça dégraisse tellement ! Et pour ceux qui ont déjà eu des interrogations philosophiques sur les architectures logicielles en iOS - entre MVC = Massive View Controller par exemple) et le trop souvent overkill VIPER -, SwiftUI + Combine incitent très naturellement à dérouler le code en MVVM, apportant enfin une alternative moderne et structurante.\nRIP UIKit ? : Bien sûr que non, SwiftUI est principalement une surcouche d’UIKit qui a encore de beaux jours devant lui. On peut d’ailleurs palier assez facilement l’absence de nombreux composants essentiels de SwiftUI en encapsulant une UIView, comme j’ai dû le faire pour le lecteur PDF et la webview qui appelle le code de génération du document PDF.\nC’est tout, ce fut un bon petit défi sympa et enrichissant !\nJ’espère avoir l’occasion de récrire sur Swift qui reste un de mes langages préférés, mais pour le moment je replonge dans mes projets TypeScript qui se positionne franchement pas mal non plus et a l’avantage d’être largement adopté en dehors du petit monde Apple.\n","description":"","tags":["iOS","Combine","SwiftUI","confinement","covid"],"title":"Attestation 2s iOS","uri":"/posts/attestation-ios/"},{"categories":null,"content":"Merci de patienter un instant…\n","description":"","tags":null,"title":"Redirection vers la salle de réunion","uri":"/visio/"}]
